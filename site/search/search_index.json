{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Artificial Intelligence, Programming and Robotics Artificial intelligence (AI) and robotics are really interesting things that are now part of our daily lives. They are used in many tasks we do every day and are also connected to programming , which is like giving instructions to computers to do incredible things. These are very important things that are changing how we live. In the second half of the last century, there was a digital revolution that made the era of information possible. However, it wasn't until a few years later, when the Internet became more accessible and computers could automatically process large amounts of information, that we truly entered the information society, which is like the successor to the industrial era. Now, since the beginning of this century, computing (which means using computers) and its application in non-biological intelligent systems and robots are causing another significant change in how we live. This is like a new industrial revolution, marking a very important moment in the development of our society. In school, when we learn about artificial intelligence, programming, and robotics , we are using computational thinking , which is like learning to think like a computer. We learn to develop computer programs, use artificial intelligence techniques, and even program robots. We also discuss how these technologies impact society , and we talk about the scientific, ethical, and social aspects of all this. In summary, we are learning very interesting things that help us understand and be part of the modern world.","title":"Artificial Intelligence, Programming and Robotics"},{"location":"index.html#artificial-intelligence-programming-and-robotics","text":"Artificial intelligence (AI) and robotics are really interesting things that are now part of our daily lives. They are used in many tasks we do every day and are also connected to programming , which is like giving instructions to computers to do incredible things. These are very important things that are changing how we live. In the second half of the last century, there was a digital revolution that made the era of information possible. However, it wasn't until a few years later, when the Internet became more accessible and computers could automatically process large amounts of information, that we truly entered the information society, which is like the successor to the industrial era. Now, since the beginning of this century, computing (which means using computers) and its application in non-biological intelligent systems and robots are causing another significant change in how we live. This is like a new industrial revolution, marking a very important moment in the development of our society. In school, when we learn about artificial intelligence, programming, and robotics , we are using computational thinking , which is like learning to think like a computer. We learn to develop computer programs, use artificial intelligence techniques, and even program robots. We also discuss how these technologies impact society , and we talk about the scientific, ethical, and social aspects of all this. In summary, we are learning very interesting things that help us understand and be part of the modern world.","title":"Artificial Intelligence, Programming and Robotics"},{"location":"contents/criterios.html","text":"Criterios de evaluaci\u00f3n Bloque 1. Inteligencia Artificial. CE1 Los siguientes criterios de evaluaci\u00f3n contribuyen a la competencia espec\u00edfica CE1. CE1 . Identificar, investigar y emplear t\u00e9cnicas de inteligencia artificial y virtualizaci\u00f3n de la realidad en el abordaje y la b\u00fasqueda de soluciones a problemas b\u00e1sicos de la sociedad valorando los principios \u00e9ticos e inclusivos aplicados. Verbos utilizados: Identificar, investigar, valorar, emplear, buscar. Ref. Definici\u00f3n CE T1 T2 T3 1.1 Identificar los fundamentos y el funcionamiento de las t\u00e9cnicas b\u00e1sicas de IA CE1 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f 1.2 Investigar situaciones donde se aplican t\u00e9cnicas de IA. CE1 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f 1.3 Valorar las implicaciones \u00e9ticas y sociales de las t\u00e9cnicas basadas en IA. CE1 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f 1.4 Emplear funciones de IA en aplicaciones sencillas de forma guiada para buscar soluciones a problemas b\u00e1sicos. CE1 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Bloque 2. Programaci\u00f3n. CE2 CE2 . Aplicar el pensamiento computacional en el an\u00e1lisis y resoluci\u00f3n de problemas b\u00e1sicos y significativos para el alumnado mediante el desarrollo de software. Ref. Definici\u00f3n [CE] T1 T2 T3 2.1 Analizar problemas elementales significativos para el alumnado, mediante la abstracci\u00f3n y modelizaci\u00f3n de la realidad. CE2 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f 2.2 Analizar y validar aplicaciones inform\u00e1ticas existentes. CE2 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f 2.3 Resolver de forma guiada problemas elementales utilizando los algoritmos y las estructuras de datos necesarias. CE2 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f 2.4 Programar aplicaciones sencillas de forma guiada para resolver problemas elementales. CE2 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f 2.5 Describir y valorar los derechos de autor\u00eda y licencias de derechos y explotaci\u00f3n. CE2 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Bloque 3. Rob\u00f3tica. CE3 CE3 . Montar sistemas rob\u00f3ticos sencillos, analizando las respuestas que proporcionan en su interacci\u00f3n con el entorno y valorando la eficacia de estas frente a los retos planteados. Ref. Definici\u00f3n CE T1 T2 T3 3.1 Montar robots sencillos siguiendo una gu\u00eda, empleando los sensores, actuadores y otros operadores que se indiquen. CE3 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f 3.2 Conectar , transferir y ejecutar el programa de control seleccionado al robot. CE3 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f 3.3 Resolver desaf\u00edos modificando un robot disponible. CE3 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f 3.4 Analizar y validar el programa de control del robot que permite que interact\u00fae con el entorno. CE3 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f 3.5 Programar instrucciones sencillas de forma guiada para controlar un robot programable. CE3 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f Bloque 4: retos tecnol\u00f3gicos. CE4 CE4 Afrontar retos tecnol\u00f3gicos sencillos y proponer soluciones mediante la programaci\u00f3n, la inteligencia Artificial y la rob\u00f3tica, analizando las posibilidades y valorando cr\u00edticamente las implicaciones \u00e9ticas y ecosociales. Ref. Definici\u00f3n CE T1 T2 T3 4.1 Participar activamente en equipos de trabajo para desarrollar soluciones digitales y tecnol\u00f3gicas demostrando empat\u00eda y respetando los roles asignados y las aportaciones del resto de personas integrantes. CE4 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f 4.2 Analizar cr\u00edticamente las implicaciones que la programaci\u00f3n y las tecnolog\u00edas tienen en la transformaci\u00f3n de la sociedad valorando las repercusiones \u00e9ticas y ecosociales. CE4 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f 4.3 Describir y valorar la adecuaci\u00f3n de las tecnolog\u00edas, entornos de desarrollo, dispositivos y componentes para resolver los retos planteados, analizando sus caracter\u00edsticas y especificaciones. CE4 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f 4.4 Resolver problemas t\u00e9cnicos sencillos surgidos en el an\u00e1lisis, desarrollo y uso de software, m\u00f3dulos de inteligencia artificial y rob\u00f3tica reformulando el procedimiento utilizado en caso necesario. CE4 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f","title":"Criterios de evaluacio\u00f3"},{"location":"contents/criterios.html#criterios-de-evaluacion","text":"","title":"Criterios de evaluaci\u00f3n"},{"location":"contents/criterios.html#bloque-1-inteligencia-artificial-ce1","text":"Los siguientes criterios de evaluaci\u00f3n contribuyen a la competencia espec\u00edfica CE1. CE1 . Identificar, investigar y emplear t\u00e9cnicas de inteligencia artificial y virtualizaci\u00f3n de la realidad en el abordaje y la b\u00fasqueda de soluciones a problemas b\u00e1sicos de la sociedad valorando los principios \u00e9ticos e inclusivos aplicados. Verbos utilizados: Identificar, investigar, valorar, emplear, buscar. Ref. Definici\u00f3n CE T1 T2 T3 1.1 Identificar los fundamentos y el funcionamiento de las t\u00e9cnicas b\u00e1sicas de IA CE1 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f 1.2 Investigar situaciones donde se aplican t\u00e9cnicas de IA. CE1 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f 1.3 Valorar las implicaciones \u00e9ticas y sociales de las t\u00e9cnicas basadas en IA. CE1 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f 1.4 Emplear funciones de IA en aplicaciones sencillas de forma guiada para buscar soluciones a problemas b\u00e1sicos. CE1 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f","title":" Bloque 1. Inteligencia Artificial. CE1"},{"location":"contents/criterios.html#bloque-2-programacion-ce2","text":"CE2 . Aplicar el pensamiento computacional en el an\u00e1lisis y resoluci\u00f3n de problemas b\u00e1sicos y significativos para el alumnado mediante el desarrollo de software. Ref. Definici\u00f3n [CE] T1 T2 T3 2.1 Analizar problemas elementales significativos para el alumnado, mediante la abstracci\u00f3n y modelizaci\u00f3n de la realidad. CE2 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f 2.2 Analizar y validar aplicaciones inform\u00e1ticas existentes. CE2 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f 2.3 Resolver de forma guiada problemas elementales utilizando los algoritmos y las estructuras de datos necesarias. CE2 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f 2.4 Programar aplicaciones sencillas de forma guiada para resolver problemas elementales. CE2 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f 2.5 Describir y valorar los derechos de autor\u00eda y licencias de derechos y explotaci\u00f3n. CE2 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f","title":" Bloque 2. Programaci\u00f3n. CE2"},{"location":"contents/criterios.html#bloque-3-robotica-ce3","text":"CE3 . Montar sistemas rob\u00f3ticos sencillos, analizando las respuestas que proporcionan en su interacci\u00f3n con el entorno y valorando la eficacia de estas frente a los retos planteados. Ref. Definici\u00f3n CE T1 T2 T3 3.1 Montar robots sencillos siguiendo una gu\u00eda, empleando los sensores, actuadores y otros operadores que se indiquen. CE3 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f 3.2 Conectar , transferir y ejecutar el programa de control seleccionado al robot. CE3 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f 3.3 Resolver desaf\u00edos modificando un robot disponible. CE3 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f 3.4 Analizar y validar el programa de control del robot que permite que interact\u00fae con el entorno. CE3 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f 3.5 Programar instrucciones sencillas de forma guiada para controlar un robot programable. CE3 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f","title":" Bloque 3. Rob\u00f3tica. CE3"},{"location":"contents/criterios.html#bloque-4-retos-tecnologicos-ce4","text":"CE4 Afrontar retos tecnol\u00f3gicos sencillos y proponer soluciones mediante la programaci\u00f3n, la inteligencia Artificial y la rob\u00f3tica, analizando las posibilidades y valorando cr\u00edticamente las implicaciones \u00e9ticas y ecosociales. Ref. Definici\u00f3n CE T1 T2 T3 4.1 Participar activamente en equipos de trabajo para desarrollar soluciones digitales y tecnol\u00f3gicas demostrando empat\u00eda y respetando los roles asignados y las aportaciones del resto de personas integrantes. CE4 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f 4.2 Analizar cr\u00edticamente las implicaciones que la programaci\u00f3n y las tecnolog\u00edas tienen en la transformaci\u00f3n de la sociedad valorando las repercusiones \u00e9ticas y ecosociales. CE4 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f 4.3 Describir y valorar la adecuaci\u00f3n de las tecnolog\u00edas, entornos de desarrollo, dispositivos y componentes para resolver los retos planteados, analizando sus caracter\u00edsticas y especificaciones. CE4 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f 4.4 Resolver problemas t\u00e9cnicos sencillos surgidos en el an\u00e1lisis, desarrollo y uso de software, m\u00f3dulos de inteligencia artificial y rob\u00f3tica reformulando el procedimiento utilizado en caso necesario. CE4 \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f","title":"  Bloque 4: retos tecnol\u00f3gicos. CE4"},{"location":"contents/presentation.html","text":"Presentation","title":"Presentation"},{"location":"contents/presentation.html#presentation","text":"","title":"Presentation"},{"location":"contents/saberes.html","text":"Saberes b\u00e1sicos IAPR2 Bloque 1. Inteligencia Artificial. CE1 Id. Contenido 2.\u00ba 3.\u00ba T1 T2 T3 SB1.1 El aprendizaje en sistemas biol\u00f3gicos. Decisiones y libre albedr\u00edo. \u2022 T1 T2 T3 SB1.2 Sensores, tipolog\u00eda y aplicaciones. \u2022 \u2022 T1 T2 T3 SB1.3 Fundamentos de la IA. \u00c1rboles de decisi\u00f3n, big data y redes neuronales. \u2022 T1 T2 T3 SB1.4 T\u00e9cnicas iniciales de IA: sistemas expertos, redes neuronales y aprendizaje autom\u00e1tico. \u2022 \u2022 T1 T2 T3 SB1.5 Procesado autom\u00e1tico de la informaci\u00f3n. \u2022 \u2022 T1 T2 T3 SB1.6 Equidad e inclusi\u00f3n en sistemas de IA. Sesgos en IA. \u2022 \u2022 T1 T2 T3 SB1.7 Implicaciones sociales y \u00e9ticas de la inteligencia artificial. \u2022 \u2022 T1 T2 T3 SB1.8 T\u00e9cnicas de virtualizaci\u00f3n de la realidad. \u2022 T1 T2 T3 Bloque 2. Programaci\u00f3n. CE2 Id. Contenido 2.\u00ba 3.\u00ba T1 T2 T3 SB2.1 Habilidades del pensamiento computacional \u2022 - - - - SB2.2 Interpretaci\u00f3n de la realidad mediante modelado de problemas \u2022 \u2022 T1 T2 T3 SB2.3 Abstracci\u00f3n, secuenciaci\u00f3n, algor\u00edtmica y su representaci\u00f3n con lenguaje natural y diagramas de flujo \u2022 \u2022 T1 T2 T3 SB2.4 Detecci\u00f3n y reutilizaci\u00f3n de patrones. Generalizaci\u00f3n. \u2022 T1 T2 T3 SB2.5 Sostenibilidad e inclusi\u00f3n como requisitos del dise\u00f1o del software \u2022 T1 T2 T3 SB2.6 Estructuras de control del flujo del programa. \u2022 \u2022 T1 T2 T3 SB2.7 Variables, constantes, condiciones y operadores \u2022 \u2022 T1 T2 T3 SB2.8 Programaci\u00f3n por bloques: composici\u00f3n de las estructuras b\u00e1sicas y encaje de bloques \u2022 T1 T2 T3 SB2.9 Introducci\u00f3n a la programaci\u00f3n en lenguajes de alto nivel. Tipos de lenguajes. Sintaxis y sem\u00e1ntica \u2022 T1 T2 T3 SB2.10 Programaci\u00f3n de aplicaciones para dispositivos m\u00f3viles \u2022 T1 T2 T3 SB2.11 An\u00e1lisis y validaci\u00f3n de software \u2022 T1 T2 T3 SB2.12 Evaluaci\u00f3n y mantenimiento de software. \u2022 T1 T2 T3 SB2.13 Licencias de software. El software libre y el software propietario. \u2022 \u2022 T1 T2 T3 SB2.14 Simuladores de tarjetas controladoras \u2022 T1 T2 T3 SB2.15 Iniciativa, autoconfianza y metacognici\u00f3n en el proceso de aprendizaje del desarrollo de software. \u2022 \u2022 T1 T2 T3 Bloque 3. Rob\u00f3tica. CE3 Id. Contenido 2.\u00ba 3.\u00ba T1 T2 T3 SB3.1 Robots: tipos, grados de libertad y caracter\u00edsticas t\u00e9cnicas b\u00e1sicas \u2022 - - - SB3.2 Montaje de robots. \u2022 \u2022 T1 T2 T3 SB3.3 Control de sistemas robotizados. \u2022 \u2022 T1 T2 T3 SB3.4 Sensores, actuadores y controladores. \u2022 \u2022 T1 T2 T3 SB3.5 Carga y ejecuci\u00f3n de los algoritmos en robots. \u2022 \u2022 T1 T2 T3 SB3.6 Sistemas robotizados en la experimentaci\u00f3n con prototipos dise\u00f1ados \u2022 T1 T2 T3","title":"Saberes b\u00e1sicos IAPR2"},{"location":"contents/saberes.html#saberes-basicos-iapr2","text":"","title":"Saberes b\u00e1sicos IAPR2"},{"location":"contents/saberes.html#bloque-1-inteligencia-artificial-ce1","text":"Id. Contenido 2.\u00ba 3.\u00ba T1 T2 T3 SB1.1 El aprendizaje en sistemas biol\u00f3gicos. Decisiones y libre albedr\u00edo. \u2022 T1 T2 T3 SB1.2 Sensores, tipolog\u00eda y aplicaciones. \u2022 \u2022 T1 T2 T3 SB1.3 Fundamentos de la IA. \u00c1rboles de decisi\u00f3n, big data y redes neuronales. \u2022 T1 T2 T3 SB1.4 T\u00e9cnicas iniciales de IA: sistemas expertos, redes neuronales y aprendizaje autom\u00e1tico. \u2022 \u2022 T1 T2 T3 SB1.5 Procesado autom\u00e1tico de la informaci\u00f3n. \u2022 \u2022 T1 T2 T3 SB1.6 Equidad e inclusi\u00f3n en sistemas de IA. Sesgos en IA. \u2022 \u2022 T1 T2 T3 SB1.7 Implicaciones sociales y \u00e9ticas de la inteligencia artificial. \u2022 \u2022 T1 T2 T3 SB1.8 T\u00e9cnicas de virtualizaci\u00f3n de la realidad. \u2022 T1 T2 T3","title":" Bloque 1. Inteligencia Artificial. CE1"},{"location":"contents/saberes.html#bloque-2-programacion-ce2","text":"Id. Contenido 2.\u00ba 3.\u00ba T1 T2 T3 SB2.1 Habilidades del pensamiento computacional \u2022 - - - - SB2.2 Interpretaci\u00f3n de la realidad mediante modelado de problemas \u2022 \u2022 T1 T2 T3 SB2.3 Abstracci\u00f3n, secuenciaci\u00f3n, algor\u00edtmica y su representaci\u00f3n con lenguaje natural y diagramas de flujo \u2022 \u2022 T1 T2 T3 SB2.4 Detecci\u00f3n y reutilizaci\u00f3n de patrones. Generalizaci\u00f3n. \u2022 T1 T2 T3 SB2.5 Sostenibilidad e inclusi\u00f3n como requisitos del dise\u00f1o del software \u2022 T1 T2 T3 SB2.6 Estructuras de control del flujo del programa. \u2022 \u2022 T1 T2 T3 SB2.7 Variables, constantes, condiciones y operadores \u2022 \u2022 T1 T2 T3 SB2.8 Programaci\u00f3n por bloques: composici\u00f3n de las estructuras b\u00e1sicas y encaje de bloques \u2022 T1 T2 T3 SB2.9 Introducci\u00f3n a la programaci\u00f3n en lenguajes de alto nivel. Tipos de lenguajes. Sintaxis y sem\u00e1ntica \u2022 T1 T2 T3 SB2.10 Programaci\u00f3n de aplicaciones para dispositivos m\u00f3viles \u2022 T1 T2 T3 SB2.11 An\u00e1lisis y validaci\u00f3n de software \u2022 T1 T2 T3 SB2.12 Evaluaci\u00f3n y mantenimiento de software. \u2022 T1 T2 T3 SB2.13 Licencias de software. El software libre y el software propietario. \u2022 \u2022 T1 T2 T3 SB2.14 Simuladores de tarjetas controladoras \u2022 T1 T2 T3 SB2.15 Iniciativa, autoconfianza y metacognici\u00f3n en el proceso de aprendizaje del desarrollo de software. \u2022 \u2022 T1 T2 T3","title":" Bloque 2. Programaci\u00f3n. CE2"},{"location":"contents/saberes.html#bloque-3-robotica-ce3","text":"Id. Contenido 2.\u00ba 3.\u00ba T1 T2 T3 SB3.1 Robots: tipos, grados de libertad y caracter\u00edsticas t\u00e9cnicas b\u00e1sicas \u2022 - - - SB3.2 Montaje de robots. \u2022 \u2022 T1 T2 T3 SB3.3 Control de sistemas robotizados. \u2022 \u2022 T1 T2 T3 SB3.4 Sensores, actuadores y controladores. \u2022 \u2022 T1 T2 T3 SB3.5 Carga y ejecuci\u00f3n de los algoritmos en robots. \u2022 \u2022 T1 T2 T3 SB3.6 Sistemas robotizados en la experimentaci\u00f3n con prototipos dise\u00f1ados \u2022 T1 T2 T3","title":" Bloque 3. Rob\u00f3tica. CE3"},{"location":"contents/programming/abstraction.html","text":"Abstraction, Sequencing, Algorithmic Thinking, and Its Representation with Natural Language and Flow Diagrams Welcome to the exciting world of Artificial Intelligence, Programming, and Robotics! In this section, we will learn about four important concepts: abstraction, sequencing, algorithmic thinking, and how to represent these ideas using natural language and flow diagrams. These ideas are the building blocks for creating computer programs and robots. Abstraction Abstraction is a way to simplify something complicated by focusing on the main idea and ignoring the small details. It helps us to understand and solve problems more easily. Think about a car. Instead of thinking about every small part (like screws and wires), you can think about the main parts: the engine, the wheels, and the seats. This makes it easier to understand how a car works. In programming, abstraction helps us to focus on what a program should do without worrying about how it does it. Programming Example: When you use an app on your phone, you only care about what the app does, like sending a message. You don\u2019t need to know all the code that makes it work. Sequencing Sequencing is the order in which instructions are followed in a program. Just like steps in a recipe, the order is very important. If you are making a sandwich, you need to follow the steps in order: 1. Get two slices of bread. 2. Put butter on one slice. 3. Add cheese on top of the butter. 4. Place the other slice of bread on top. If you mix up the order, you won't get a proper sandwich. In programming, if you mix up the order of instructions, the program won\u2019t work correctly. Programming Example: If you are writing a program to turn on a light, you need to: 1. Check if the switch is flipped. 2. If the switch is flipped, turn on the light. If you do these steps in the wrong order, the light won't turn on correctly. Algorithmic Thinking Algorithmic thinking is about creating a step-by-step solution to a problem. An algorithm is a list of steps to solve a problem or complete a task. Example: Let\u2019s say you want to find the biggest number in a list of numbers: 1. Start with the first number as the biggest. 2. Compare it to the next number. 3. If the next number is bigger, remember it as the new biggest number. 4. Repeat steps 2 and 3 for all numbers in the list. 5. The number you remembered at the end is the biggest. Representation with Natural Language and Flow Diagrams Once we have an algorithm, we can write it in two ways: using natural language or flow diagrams. Natural Language Representation is writing the steps in everyday language. Example: Here\u2019s how to find the biggest number: 1. Start with the first number as the biggest. 2. Look at each number in the list. 3. If you find a bigger number, remember it. 4. The last number you remembered is the biggest. Flow Diagrams use shapes and arrows to show the steps of an algorithm. This helps us see the steps clearly. Example: To make a flow diagram for finding the biggest number: 1. Start: Draw an oval and write \"Start.\" 2. Initialize: Draw a rectangle and write \"Set first number as biggest.\" 3. Loop through list: Draw a rectangle and write \"Get next number.\" 4. Decision: Draw a diamond and write \"Is this number bigger?\" Draw arrows for \"Yes\" and \"No.\" 5. Update: If \"Yes,\" draw a rectangle and write \"Remember this number.\" 6. More numbers?: Draw a diamond and write \"More numbers?\" Draw arrows for \"Yes\" and \"No.\" 7. End: If \"No,\" draw an oval and write \"End.\" Putting It All Together By learning about abstraction, sequencing, and algorithmic thinking, and how to represent these with natural language and flow diagrams, you can solve problems step-by-step. Activity: Try writing an algorithm in natural language and drawing a flow diagram for a simple task, like brushing your teeth. List each step clearly and create shapes for the flow diagram. Understanding these concepts will make it easier to write and understand programs, design robots, and create AI systems. Practice these skills, and you\u2019ll be well on your way to becoming a proficient programmer and robotics engineer! Videos","title":"Abstraction, Sequencing, Algorithmic Thinking, and Its Representation with Natural Language and Flow Diagrams"},{"location":"contents/programming/abstraction.html#abstraction-sequencing-algorithmic-thinking-and-its-representation-with-natural-language-and-flow-diagrams","text":"Welcome to the exciting world of Artificial Intelligence, Programming, and Robotics! In this section, we will learn about four important concepts: abstraction, sequencing, algorithmic thinking, and how to represent these ideas using natural language and flow diagrams. These ideas are the building blocks for creating computer programs and robots.","title":"Abstraction, Sequencing, Algorithmic Thinking, and Its Representation with Natural Language and Flow Diagrams"},{"location":"contents/programming/abstraction.html#abstraction","text":"Abstraction is a way to simplify something complicated by focusing on the main idea and ignoring the small details. It helps us to understand and solve problems more easily. Think about a car. Instead of thinking about every small part (like screws and wires), you can think about the main parts: the engine, the wheels, and the seats. This makes it easier to understand how a car works. In programming, abstraction helps us to focus on what a program should do without worrying about how it does it. Programming Example: When you use an app on your phone, you only care about what the app does, like sending a message. You don\u2019t need to know all the code that makes it work.","title":"Abstraction"},{"location":"contents/programming/abstraction.html#sequencing","text":"Sequencing is the order in which instructions are followed in a program. Just like steps in a recipe, the order is very important. If you are making a sandwich, you need to follow the steps in order: 1. Get two slices of bread. 2. Put butter on one slice. 3. Add cheese on top of the butter. 4. Place the other slice of bread on top. If you mix up the order, you won't get a proper sandwich. In programming, if you mix up the order of instructions, the program won\u2019t work correctly. Programming Example: If you are writing a program to turn on a light, you need to: 1. Check if the switch is flipped. 2. If the switch is flipped, turn on the light. If you do these steps in the wrong order, the light won't turn on correctly.","title":"Sequencing"},{"location":"contents/programming/abstraction.html#algorithmic-thinking","text":"Algorithmic thinking is about creating a step-by-step solution to a problem. An algorithm is a list of steps to solve a problem or complete a task. Example: Let\u2019s say you want to find the biggest number in a list of numbers: 1. Start with the first number as the biggest. 2. Compare it to the next number. 3. If the next number is bigger, remember it as the new biggest number. 4. Repeat steps 2 and 3 for all numbers in the list. 5. The number you remembered at the end is the biggest.","title":"Algorithmic Thinking"},{"location":"contents/programming/abstraction.html#representation-with-natural-language-and-flow-diagrams","text":"Once we have an algorithm, we can write it in two ways: using natural language or flow diagrams. Natural Language Representation is writing the steps in everyday language. Example: Here\u2019s how to find the biggest number: 1. Start with the first number as the biggest. 2. Look at each number in the list. 3. If you find a bigger number, remember it. 4. The last number you remembered is the biggest. Flow Diagrams use shapes and arrows to show the steps of an algorithm. This helps us see the steps clearly. Example: To make a flow diagram for finding the biggest number: 1. Start: Draw an oval and write \"Start.\" 2. Initialize: Draw a rectangle and write \"Set first number as biggest.\" 3. Loop through list: Draw a rectangle and write \"Get next number.\" 4. Decision: Draw a diamond and write \"Is this number bigger?\" Draw arrows for \"Yes\" and \"No.\" 5. Update: If \"Yes,\" draw a rectangle and write \"Remember this number.\" 6. More numbers?: Draw a diamond and write \"More numbers?\" Draw arrows for \"Yes\" and \"No.\" 7. End: If \"No,\" draw an oval and write \"End.\"","title":"Representation with Natural Language and Flow Diagrams"},{"location":"contents/programming/abstraction.html#putting-it-all-together","text":"By learning about abstraction, sequencing, and algorithmic thinking, and how to represent these with natural language and flow diagrams, you can solve problems step-by-step. Activity: Try writing an algorithm in natural language and drawing a flow diagram for a simple task, like brushing your teeth. List each step clearly and create shapes for the flow diagram. Understanding these concepts will make it easier to write and understand programs, design robots, and create AI systems. Practice these skills, and you\u2019ll be well on your way to becoming a proficient programmer and robotics engineer!","title":"Putting It All Together"},{"location":"contents/programming/abstraction.html#videos","text":"","title":"Videos"},{"location":"contents/programming/intro.html","text":"Introduction to Programming","title":"Introduction to Programming"},{"location":"contents/programming/intro.html#introduction-to-programming","text":"","title":"Introduction to Programming"},{"location":"contents/programming/nl-flowdiagrams.html","text":"","title":"Nl flowdiagrams"},{"location":"contents/programming/problem-modeling.html","text":"Interpretation of Reality through Problem Modeling In the world of Artificial Intelligence, Programming, and Robotics, understanding and interpreting reality is essential. One of the best ways to do this is through problem modeling . Problem modeling involves creating a simplified representation of a real-world situation to help us understand, analyze, and solve problems more effectively. What is Problem Modeling? Problem modeling is the process of taking a complex real-world problem and breaking it down into smaller, more manageable parts . By creating a model, we can better understand the problem and develop solutions. This model can be in the form of diagrams, equations, or simulations, depending on the nature of the problem. Why is Problem Modeling Important? Simplification: Modeling helps simplify complex problems, making them easier to understand and solve. Visualization: Models allow us to visualize the problem, which can help in identifying patterns and relationships. Experimentation: With a model, we can test different solutions and see their effects without experimenting in the real world, which can be costly or impractical. Communication: Models provide a common language for discussing problems and solutions with others. Problem modeling is a powerful tool in AI, programming, and robotics. It helps us understand complex problems, develop effective solutions, and communicate our ideas. Steps in Problem Modeling Identify the Problem: The first step is to clearly understand and define the problem. What are you trying to solve? What are the key aspects of the problem? Simplify the Problem: Break the problem down into smaller parts. Identify the most important factors and ignore the less critical details. Create the Model: Develop a representation of the problem. This could be a flowchart, a mathematical equation, or a computer simulation. Analyze the Model: Use the model to analyze the problem. Look for patterns, relationships, and possible solutions. Test Solutions: Use the model to test different solutions. See which solutions work best and why. Refine the Model: Based on your analysis and testing, refine the model to better represent the problem and improve your solutions. Example of Problem Modeling Imagine you want to design a robot that can navigate through a maze. Here\u2019s how you might model this problem: Identify the Problem: The problem is to design a robot that can find its way from the start to the end of a maze. Simplify the Problem: Focus on the key elements: the maze layout, the robot's sensors, and the robot's movement capabilities. Create the Model: Draw a simple map of the maze. Represent the robot's sensors as circles that detect walls and openings. Use arrows to show possible movements. Analyze the Model: Look at how the robot can move through the maze. Identify any patterns or obstacles that the robot needs to overcome. Test Solutions: Simulate the robot's movement through the maze. Try different algorithms, such as always turning right or following the left wall, to see which one works best. Refine the Model: If the robot gets stuck or takes too long, adjust the model. Maybe add more sensors or change the movement algorithm. Real-World Applications Problem modeling is used in many fields: Healthcare: Modeling the spread of diseases to find the best ways to control outbreaks. Environment: Modeling climate change to predict future conditions and develop solutions. Business: Modeling customer behavior to improve marketing strategies and product designs. Robotics: Modeling robot movements to optimize their tasks, such as in manufacturing or search and rescue operations. Conclusion Problem modeling is a powerful tool in AI, programming, and robotics. It helps us understand complex problems, develop effective solutions, and communicate our ideas. By learning to create and use models, you will be better equipped to tackle real-world problems and contribute to advancements in technology and society. Remember, the key steps are identifying, simplifying, creating, analyzing, testing, and refining your models. Happy modeling!","title":"Interpretation of Reality through Problem Modeling"},{"location":"contents/programming/problem-modeling.html#interpretation-of-reality-through-problem-modeling","text":"In the world of Artificial Intelligence, Programming, and Robotics, understanding and interpreting reality is essential. One of the best ways to do this is through problem modeling . Problem modeling involves creating a simplified representation of a real-world situation to help us understand, analyze, and solve problems more effectively.","title":"Interpretation of Reality through Problem Modeling"},{"location":"contents/programming/problem-modeling.html#what-is-problem-modeling","text":"Problem modeling is the process of taking a complex real-world problem and breaking it down into smaller, more manageable parts . By creating a model, we can better understand the problem and develop solutions. This model can be in the form of diagrams, equations, or simulations, depending on the nature of the problem.","title":"What is Problem Modeling?"},{"location":"contents/programming/problem-modeling.html#why-is-problem-modeling-important","text":"Simplification: Modeling helps simplify complex problems, making them easier to understand and solve. Visualization: Models allow us to visualize the problem, which can help in identifying patterns and relationships. Experimentation: With a model, we can test different solutions and see their effects without experimenting in the real world, which can be costly or impractical. Communication: Models provide a common language for discussing problems and solutions with others. Problem modeling is a powerful tool in AI, programming, and robotics. It helps us understand complex problems, develop effective solutions, and communicate our ideas.","title":"Why is Problem Modeling Important?"},{"location":"contents/programming/problem-modeling.html#steps-in-problem-modeling","text":"Identify the Problem: The first step is to clearly understand and define the problem. What are you trying to solve? What are the key aspects of the problem? Simplify the Problem: Break the problem down into smaller parts. Identify the most important factors and ignore the less critical details. Create the Model: Develop a representation of the problem. This could be a flowchart, a mathematical equation, or a computer simulation. Analyze the Model: Use the model to analyze the problem. Look for patterns, relationships, and possible solutions. Test Solutions: Use the model to test different solutions. See which solutions work best and why. Refine the Model: Based on your analysis and testing, refine the model to better represent the problem and improve your solutions.","title":"Steps in Problem Modeling"},{"location":"contents/programming/problem-modeling.html#example-of-problem-modeling","text":"Imagine you want to design a robot that can navigate through a maze. Here\u2019s how you might model this problem: Identify the Problem: The problem is to design a robot that can find its way from the start to the end of a maze. Simplify the Problem: Focus on the key elements: the maze layout, the robot's sensors, and the robot's movement capabilities. Create the Model: Draw a simple map of the maze. Represent the robot's sensors as circles that detect walls and openings. Use arrows to show possible movements. Analyze the Model: Look at how the robot can move through the maze. Identify any patterns or obstacles that the robot needs to overcome. Test Solutions: Simulate the robot's movement through the maze. Try different algorithms, such as always turning right or following the left wall, to see which one works best. Refine the Model: If the robot gets stuck or takes too long, adjust the model. Maybe add more sensors or change the movement algorithm.","title":"Example of Problem Modeling"},{"location":"contents/programming/problem-modeling.html#real-world-applications","text":"Problem modeling is used in many fields: Healthcare: Modeling the spread of diseases to find the best ways to control outbreaks. Environment: Modeling climate change to predict future conditions and develop solutions. Business: Modeling customer behavior to improve marketing strategies and product designs. Robotics: Modeling robot movements to optimize their tasks, such as in manufacturing or search and rescue operations.","title":"Real-World Applications"},{"location":"contents/programming/problem-modeling.html#conclusion","text":"Problem modeling is a powerful tool in AI, programming, and robotics. It helps us understand complex problems, develop effective solutions, and communicate our ideas. By learning to create and use models, you will be better equipped to tackle real-world problems and contribute to advancements in technology and society. Remember, the key steps are identifying, simplifying, creating, analyzing, testing, and refining your models. Happy modeling!","title":"Conclusion"},{"location":"contents/programming/rpsls/animation.html","text":"Programming Graphics and Animation In this stage of the project, we will program the animation of both hands. When we press the space key, the two hands will start displaying various random positions (rock, paper, scissors, lizard, Spock). Finally, one fixed hand position will remain. In other words, in this version of the game, the machine plays against itself, showing two random moves, one for player A and another for player B. The Checklist Create the game project in Scratch on its web version : scratch.mit.edu . First, choose a background for the game and insert text in the bottom right corner with the names of the programming team members (pair). Search the internet for 5 images of hands representing the different options for playing Rock, Paper, Scissors, Lizard, Spock. The images should have appropriate quality and resolution. Each of the 5 images should be in a separate PNG file with the following names: rock.png, paper.png, scissors.png, lizard.png, and spock.png. Modify the images if necessary to have a transparent background. You can remove the background using Scratch tools or other tools like GIMP or websites such as www.remove.bg/es . Create 3 sprites in Scratch: one for the game referee (a person) and two for each hand (player A and B). Use the 5 prepared images to define 5 costumes for each hand in Scratch. Program the necessary code in the referee and each hand so that, when the space key is pressed, the animation starts simultaneously in each hand and ends with a random option. Test that everything works correctly. Download the Scratch project file (.sb3) and rename it according to the last names and names of the members 9. 1 and 2 of the team: LastName1FirstName1_LastName2FirstName2.sb3 (for example: P\u00e9rezJuan_L\u00f3pezAna.sb3) Attach submit the .sb3 file here. 1. Scratch Scratch is a visual programming language and an online community developed by the MIT Media Lab. It is designed to be user-friendly, especially for beginners, allowing them to create interactive stories, games, and animations without the need for traditional coding. Scratch uses a drag-and-drop interface where users snap together blocks of code, making it accessible to people of all ages. You can use Scratch online. The platform is web-based, and you can access it through your web browser. This means you don't need to download or install any software to start programming in Scratch. The online version allows users to create, share, and remix projects, fostering a collaborative and creative learning environment. You can find the Scratch platform at the official website: scratch.mit.edu/ . 2. The Background First, choose a background for the game and insert text in the bottom right corner with the names of the In Scratch, a backdrop is the background or scenery that serves as the visual environment for your project. It provides context to the sprites and actions happening in your project. Backdrops can be static images or even dynamic scenes that change over time. To add a new backdrop in Scratch: Open Your Project: - Go to the Scratch website (https://scratch.mit.edu/) and log in if you aren't already. - Open the project to which you want to add a new backdrop. Choose or Upload a Backdrop: - In the stage area (the large white space where your sprites and backdrops are displayed), find the \"Choose a backdrop from library\" option. It's usually located in the bottom-left corner. - Click on it to open the backdrop library. Here, you can choose from a variety of pre-made backdrops. - If you want to use your own image as a backdrop, click on the \"Upload Backdrop\" button, which allows you to upload an image from your computer. Select and Add the Backdrop: - If you're choosing from the library, click on the backdrop you want to use, and it will be added to your project. - If you're uploading your own image, select the image from your computer, and it will be added as a new backdrop. Adding backdrops allows you to create more engaging and visually appealing projects in Scratch, enhancing the overall experience for your users. 3. Five images Search the internet for 5 images of hands representing the different options for playing Rock, Paper, Scissors, Lizard, Spock. The images should have appropriate quality and resolution. Each of the 5 images should be in a separate PNG file with the following names: rock.png paper.png scissors.png lizard.png spock.png If the objects Rock, Paper, Scissors, Lizard, and Spock appear together in a single image, you can make 5 cuts of the image using GIMP or another image editor. 4. Edit the pictures Modify the images if necessary to have a transparent background. You can remove the background using Scratch tools or other tools like GIMP or websites such as www.remove.bg/es . 5. The Sprites Create 3 sprites in Scratch: one for the game referee (a person) and two for each hand (player A and B). In Scratch, a sprite is a graphic object or character that can be programmed to perform various actions. Sprites are the interactive elements in a Scratch project, and they can be customized and controlled using Scratch's visual programming language. Each sprite has its own set of scripts (programming instructions) that dictate its behavior. Users can create or choose sprites from Scratch's library, which includes a variety of characters, animals, objects, and more. Sprites can be moved, rotated, and resized, and they can respond to different events or user inputs, such as keyboard presses or mouse clicks. In the context of a game like Rock Paper Scissors Lizard Spock, sprites represent the hands making different gestures, and their movements and positions. 6. Five costumes: rock, paper, scissors, lizard, and Spock Use the 5 prepared images to define 5 costumes for each hand in Scratch. 7. The animation code Program the necessary code in the referee and each hand so that, when the space key is pressed, the animation starts simultaneously in each hand and ends with a random option. Exercise Use the blocksin the image to program the animation. This is the algorithm that you have to program: when space key pressed say(Rock, Paper, Scissors, Lizard, Spock!) MoveHand define MoveHand repeat(10) playerA_move = pick_random(1,5) costume = playerA_move wait 0.1 seconds SayMove 8. Test it! Test that everything works correctly. The animation of the hands should start when the space key is pressed. 9. Download the Scratch project file (.sb3) Download the Scratch project file (.sb3) and rename it according to the last names and names of the members 1 and 2 of the team: LastName1FirstName1_LastName2FirstName2.sb3 For example: P\u00e9rezJuan_L\u00f3pezAna.sb3 10. Turn in your project Attach and submit the .sb3 file. This is how .","title":"Programming Graphics and Animation"},{"location":"contents/programming/rpsls/animation.html#programming-graphics-and-animation","text":"In this stage of the project, we will program the animation of both hands. When we press the space key, the two hands will start displaying various random positions (rock, paper, scissors, lizard, Spock). Finally, one fixed hand position will remain. In other words, in this version of the game, the machine plays against itself, showing two random moves, one for player A and another for player B.","title":"Programming Graphics and Animation"},{"location":"contents/programming/rpsls/animation.html#the-checklist","text":"Create the game project in Scratch on its web version : scratch.mit.edu . First, choose a background for the game and insert text in the bottom right corner with the names of the programming team members (pair). Search the internet for 5 images of hands representing the different options for playing Rock, Paper, Scissors, Lizard, Spock. The images should have appropriate quality and resolution. Each of the 5 images should be in a separate PNG file with the following names: rock.png, paper.png, scissors.png, lizard.png, and spock.png. Modify the images if necessary to have a transparent background. You can remove the background using Scratch tools or other tools like GIMP or websites such as www.remove.bg/es . Create 3 sprites in Scratch: one for the game referee (a person) and two for each hand (player A and B). Use the 5 prepared images to define 5 costumes for each hand in Scratch. Program the necessary code in the referee and each hand so that, when the space key is pressed, the animation starts simultaneously in each hand and ends with a random option. Test that everything works correctly. Download the Scratch project file (.sb3) and rename it according to the last names and names of the members 9. 1 and 2 of the team: LastName1FirstName1_LastName2FirstName2.sb3 (for example: P\u00e9rezJuan_L\u00f3pezAna.sb3) Attach submit the .sb3 file here.","title":"The Checklist"},{"location":"contents/programming/rpsls/animation.html#1-scratch","text":"Scratch is a visual programming language and an online community developed by the MIT Media Lab. It is designed to be user-friendly, especially for beginners, allowing them to create interactive stories, games, and animations without the need for traditional coding. Scratch uses a drag-and-drop interface where users snap together blocks of code, making it accessible to people of all ages. You can use Scratch online. The platform is web-based, and you can access it through your web browser. This means you don't need to download or install any software to start programming in Scratch. The online version allows users to create, share, and remix projects, fostering a collaborative and creative learning environment. You can find the Scratch platform at the official website: scratch.mit.edu/ .","title":"1. Scratch"},{"location":"contents/programming/rpsls/animation.html#2-the-background","text":"First, choose a background for the game and insert text in the bottom right corner with the names of the In Scratch, a backdrop is the background or scenery that serves as the visual environment for your project. It provides context to the sprites and actions happening in your project. Backdrops can be static images or even dynamic scenes that change over time. To add a new backdrop in Scratch: Open Your Project: - Go to the Scratch website (https://scratch.mit.edu/) and log in if you aren't already. - Open the project to which you want to add a new backdrop. Choose or Upload a Backdrop: - In the stage area (the large white space where your sprites and backdrops are displayed), find the \"Choose a backdrop from library\" option. It's usually located in the bottom-left corner. - Click on it to open the backdrop library. Here, you can choose from a variety of pre-made backdrops. - If you want to use your own image as a backdrop, click on the \"Upload Backdrop\" button, which allows you to upload an image from your computer. Select and Add the Backdrop: - If you're choosing from the library, click on the backdrop you want to use, and it will be added to your project. - If you're uploading your own image, select the image from your computer, and it will be added as a new backdrop. Adding backdrops allows you to create more engaging and visually appealing projects in Scratch, enhancing the overall experience for your users.","title":"2. The Background"},{"location":"contents/programming/rpsls/animation.html#3-five-images","text":"Search the internet for 5 images of hands representing the different options for playing Rock, Paper, Scissors, Lizard, Spock. The images should have appropriate quality and resolution. Each of the 5 images should be in a separate PNG file with the following names: rock.png paper.png scissors.png lizard.png spock.png If the objects Rock, Paper, Scissors, Lizard, and Spock appear together in a single image, you can make 5 cuts of the image using GIMP or another image editor.","title":"3. Five images"},{"location":"contents/programming/rpsls/animation.html#4-edit-the-pictures","text":"Modify the images if necessary to have a transparent background. You can remove the background using Scratch tools or other tools like GIMP or websites such as www.remove.bg/es .","title":"4. Edit the pictures"},{"location":"contents/programming/rpsls/animation.html#5-the-sprites","text":"Create 3 sprites in Scratch: one for the game referee (a person) and two for each hand (player A and B). In Scratch, a sprite is a graphic object or character that can be programmed to perform various actions. Sprites are the interactive elements in a Scratch project, and they can be customized and controlled using Scratch's visual programming language. Each sprite has its own set of scripts (programming instructions) that dictate its behavior. Users can create or choose sprites from Scratch's library, which includes a variety of characters, animals, objects, and more. Sprites can be moved, rotated, and resized, and they can respond to different events or user inputs, such as keyboard presses or mouse clicks. In the context of a game like Rock Paper Scissors Lizard Spock, sprites represent the hands making different gestures, and their movements and positions.","title":"5. The Sprites"},{"location":"contents/programming/rpsls/animation.html#6-five-costumes-rock-paper-scissors-lizard-and-spock","text":"Use the 5 prepared images to define 5 costumes for each hand in Scratch.","title":"6. Five costumes: rock, paper, scissors, lizard, and Spock"},{"location":"contents/programming/rpsls/animation.html#7-the-animation-code","text":"Program the necessary code in the referee and each hand so that, when the space key is pressed, the animation starts simultaneously in each hand and ends with a random option.","title":"7. The animation code"},{"location":"contents/programming/rpsls/animation.html#exercise","text":"Use the blocksin the image to program the animation. This is the algorithm that you have to program: when space key pressed say(Rock, Paper, Scissors, Lizard, Spock!) MoveHand define MoveHand repeat(10) playerA_move = pick_random(1,5) costume = playerA_move wait 0.1 seconds SayMove","title":"Exercise"},{"location":"contents/programming/rpsls/animation.html#8-test-it","text":"Test that everything works correctly. The animation of the hands should start when the space key is pressed.","title":"8. Test it!"},{"location":"contents/programming/rpsls/animation.html#9-download-the-scratch-project-file-sb3","text":"Download the Scratch project file (.sb3) and rename it according to the last names and names of the members 1 and 2 of the team: LastName1FirstName1_LastName2FirstName2.sb3 For example: P\u00e9rezJuan_L\u00f3pezAna.sb3","title":"9. Download the Scratch project file (.sb3)"},{"location":"contents/programming/rpsls/animation.html#10-turn-in-your-project","text":"Attach and submit the .sb3 file. This is how .","title":"10. Turn in your project"},{"location":"contents/programming/rpsls/final.html","text":"Final Version and Testing Create a final version of the videogame: add a point system, sound effects and music, and test the app. Add the last functions: Adding points Main menu and start button Player wins with 3 points + Message announcing the winner Game Over backdrop when the game ends Add sound effects and background music to your project. Test your video game Create the main menu backdrop with AI Use an AI tool like DALL-E or Copilot to create an illustration for the main manu backdrop. DALL-E Copilot Important Save the text of the prompt that you used to generate the illustration. You will have to submit it in the activity. Music and Sound Effects You can find music and sound effects here: Music https://www.jamendo.com/ Sound Effects https://pixabay.com/es/sound-effects/ https://soundbible.com/ https://mixkit.co/free-sound-effects/ https://freesound.org/browse/tags/sound-effects/","title":"Final Version and Testing"},{"location":"contents/programming/rpsls/final.html#final-version-and-testing","text":"Create a final version of the videogame: add a point system, sound effects and music, and test the app. Add the last functions: Adding points Main menu and start button Player wins with 3 points + Message announcing the winner Game Over backdrop when the game ends Add sound effects and background music to your project. Test your video game","title":"Final Version and Testing"},{"location":"contents/programming/rpsls/final.html#create-the-main-menu-backdrop-with-ai","text":"Use an AI tool like DALL-E or Copilot to create an illustration for the main manu backdrop. DALL-E Copilot","title":"Create the main menu backdrop with AI"},{"location":"contents/programming/rpsls/final.html#important","text":"Save the text of the prompt that you used to generate the illustration. You will have to submit it in the activity.","title":"Important"},{"location":"contents/programming/rpsls/final.html#music-and-sound-effects","text":"You can find music and sound effects here:","title":"Music and Sound Effects"},{"location":"contents/programming/rpsls/final.html#music","text":"https://www.jamendo.com/","title":"Music"},{"location":"contents/programming/rpsls/final.html#sound-effects","text":"https://pixabay.com/es/sound-effects/ https://soundbible.com/ https://mixkit.co/free-sound-effects/ https://freesound.org/browse/tags/sound-effects/","title":"Sound Effects"},{"location":"contents/programming/rpsls/logic.html","text":"Logic and Flow Control In this phase of game development, we will program the referee Sprite, which will be responsible for deciding the winner after each move. To achieve this, we need to create several code blocks: DecideWinner , PlayerA_Rock , PlayerA_Paper , PlayerA_Scissors , PlayerA_Lizard , and PlayerA_Spock . DecideWinner block The DecideWinner block will first check the value of Player A's move , and based on this value (1, 2, 3, 4, or 5), the corresponding block (PlayerA_Rock, PlayerA_Paper, etc.) will be called to check the value of Player B's move . In this latter block, the message for the winning move will be displayed, and points will be added to each player. graph TD A[DecideWinner] --> B{PlayerA_move?}; B -->|1 Rock| C[PlayerA_Rock]; B -->|2 Paper| D[PlayerA_Paper]; B -->|3 Scissors| E[PlayerA_Scissors]; B -->|4 Lizard| F[PlayerA_Lizard]; B -->|5 Spock| G[PlayerA_Spock]; C --> H{PlayerB_move?}; H -->|1 Rock| I[Tie]; H -->|2 Paper| J[Paper wins]; H -->|3 Scissors| K[Rock wins]; H -->|4 Lizard| L[Rock wins]; H -->|5 Spock| M[Spock wins]; D --> N2{?}; E --> N3{?}; F --> N4{?}; G --> N5{?}; PlayerA_ blocks","title":"Logic and Flow Control"},{"location":"contents/programming/rpsls/logic.html#logic-and-flow-control","text":"In this phase of game development, we will program the referee Sprite, which will be responsible for deciding the winner after each move. To achieve this, we need to create several code blocks: DecideWinner , PlayerA_Rock , PlayerA_Paper , PlayerA_Scissors , PlayerA_Lizard , and PlayerA_Spock .","title":"Logic and Flow Control"},{"location":"contents/programming/rpsls/logic.html#decidewinner-block","text":"The DecideWinner block will first check the value of Player A's move , and based on this value (1, 2, 3, 4, or 5), the corresponding block (PlayerA_Rock, PlayerA_Paper, etc.) will be called to check the value of Player B's move . In this latter block, the message for the winning move will be displayed, and points will be added to each player. graph TD A[DecideWinner] --> B{PlayerA_move?}; B -->|1 Rock| C[PlayerA_Rock]; B -->|2 Paper| D[PlayerA_Paper]; B -->|3 Scissors| E[PlayerA_Scissors]; B -->|4 Lizard| F[PlayerA_Lizard]; B -->|5 Spock| G[PlayerA_Spock]; C --> H{PlayerB_move?}; H -->|1 Rock| I[Tie]; H -->|2 Paper| J[Paper wins]; H -->|3 Scissors| K[Rock wins]; H -->|4 Lizard| L[Rock wins]; H -->|5 Spock| M[Spock wins]; D --> N2{?}; E --> N3{?}; F --> N4{?}; G --> N5{?};","title":"DecideWinner block"},{"location":"contents/programming/rpsls/logic.html#playera_-blocks","text":"","title":"PlayerA_ blocks"},{"location":"contents/programming/rpsls/project.html","text":"Game Programming: Rock, Paper, Scissors, Lizard, Spock The game appears in one of the episodes of The Big Bang Theory series. One of the characters, Sheldon, suggests playing this extended version of the Rock, Paper, Scissors game The game is an expansion on the game Rock, Paper, Scissors . Each player picks a variable and reveals it at the same time. The winner is the one who defeats the others. In a tie, the process is repeated until a winner is found. The Game","title":"Game Programming: Rock, Paper, Scissors, Lizard, Spock"},{"location":"contents/programming/rpsls/project.html#game-programming-rock-paper-scissors-lizard-spock","text":"The game appears in one of the episodes of The Big Bang Theory series. One of the characters, Sheldon, suggests playing this extended version of the Rock, Paper, Scissors game The game is an expansion on the game Rock, Paper, Scissors . Each player picks a variable and reveals it at the same time. The winner is the one who defeats the others. In a tie, the process is repeated until a winner is found.","title":"Game Programming: Rock, Paper, Scissors, Lizard, Spock"},{"location":"contents/programming/rpsls/project.html#the-game","text":"","title":"The Game"},{"location":"contents/programming/rpsls/rps_tutorial.html","text":"Programming Rock, Paper, Scissors with Scratch Here's a tutorial for programming the Rock, Paper, Scissors game (3 elements) with Scratch that can help you build the project with 5 elements: rock, paper, scissors, lizard, and Spock . .embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }","title":"Programming Rock, Paper, Scissors with Scratch"},{"location":"contents/programming/rpsls/rps_tutorial.html#programming-rock-paper-scissors-with-scratch","text":"Here's a tutorial for programming the Rock, Paper, Scissors game (3 elements) with Scratch that can help you build the project with 5 elements: rock, paper, scissors, lizard, and Spock . .embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }","title":"Programming Rock, Paper, Scissors with Scratch"},{"location":"contents/programming/rpsls/thegame.html","text":"Understanding the Game Rules: Rock, Paper, Scissors, Lizard, Spock The game is an expansion on the game Rock, Paper, Scissors . Each player picks a variable and reveals it at the same time. The winner is the one who defeats the others. In a tie, the process is repeated until a winner is found. The Rules Scissors cuts paper. Paper covers rock. Rock crushes lizard. Lizard poisons Spock. Spock smashes scissors. Scissors decapitates lizard. Lizard eats paper. Paper disproves Spock. Spock vaporizes rock. Rock crushes scissors. The Game","title":"Understanding the Game Rules: Rock, Paper, Scissors, Lizard, Spock"},{"location":"contents/programming/rpsls/thegame.html#understanding-the-game-rules-rock-paper-scissors-lizard-spock","text":"The game is an expansion on the game Rock, Paper, Scissors . Each player picks a variable and reveals it at the same time. The winner is the one who defeats the others. In a tie, the process is repeated until a winner is found.","title":"Understanding the Game Rules: Rock, Paper, Scissors, Lizard, Spock"},{"location":"contents/programming/rpsls/thegame.html#the-rules","text":"Scissors cuts paper. Paper covers rock. Rock crushes lizard. Lizard poisons Spock. Spock smashes scissors. Scissors decapitates lizard. Lizard eats paper. Paper disproves Spock. Spock vaporizes rock. Rock crushes scissors.","title":"The Rules"},{"location":"contents/programming/rpsls/thegame.html#the-game","text":"","title":"The Game"},{"location":"contents/robotics/actuators.html","text":"Actuators An actuator is a component of a robot that is responsible for creating movement or motion . In other words, an actuator is what makes a robot move, grab, lift, or perform any other physical action. There are different types of actuators used in robotics, depending on the purpose and design of the robot. Some common types of actuators include: Motors : These are electrical or mechanical devices that convert electrical energy into mechanical energy to create motion. Motors are commonly used in robots to drive wheels, move robot arms, or control the position of robot joints. Pneumatic cylinders : These are devices that use compressed air to create motion. Pneumatic cylinders are often used in industrial robots to move heavy loads or in applications where precision and speed are important. Hydraulic cylinders : Similar to pneumatic cylinders, hydraulic cylinders use fluid instead of air to create motion. They are often used in large industrial robots for heavy-duty applications. Solenoids : These are electromechanical devices that convert electrical energy into linear or rotary motion. Solenoids are commonly used in small robots for precise movements, such as opening and closing robot grippers. In summary, an actuator is a critical component of a robot that creates motion or movement . Different types of actuators are used depending on the application and design of the robot. By using actuators, robots can perform physical tasks and interact with their environment, making them useful for a wide range of applications, from manufacturing to healthcare. Glossary English Spanish Example Sentence (English) Actuators Actuadores \"The robot's actuators allowed it to perform precise movements and interact with objects.\" Applications Aplicaciones \"Robots have various applications in industries such as manufacturing, healthcare, and more.\" Arms Brazos \"The robot's multiple arms enabled it to manipulate objects with dexterity.\" Component Componente \"The actuator is an essential component of a robot's mechanism.\" Control Control \"The robot's actuators were operated by a sophisticated control system.\" Convert Convertir \"The motor converts electrical energy into mechanical energy for locomotion.\" Create Crear \"The hydraulic cylinder creates powerful motion to lift heavy loads.\" Critical Cr\u00edtico \"The actuator is a critical element for the robot's functionality.\" Design Dise\u00f1o \"The choice of actuators depends on the robot's design and intended tasks.\" Devices Dispositivos \"Motors, solenoids, and cylinders are common devices used as actuators.\" Drive Impulsar \"The motors drive the robot's wheels, propelling it forward.\" Electrical El\u00e9ctrico \"Solenoids are electrical devices that convert energy into motion.\" Energy Energ\u00eda \"Actuators require a power source to operate and convert energy into motion.\" Fluid Fluido \"Hydraulic cylinders use fluid to generate motion in the robot's limbs.\" Grab Agarrar \"The robot's gripper can grab and manipulate objects of different shapes and sizes.\" Heavy-duty Resistente \"Industrial robots equipped with hydraulic cylinders can handle heavy-duty tasks.\" Important Importante \"Precision and speed are important factors in choosing pneumatic cylinders for a robot.\" Interact Interactuar \"Robots can interact with humans and their surroundings using various actuators.\" Linear Lineal \"Solenoids can produce linear or rotary motion depending on the design.\" Mechanical Mec\u00e1nico \"Motors are mechanical devices that convert electrical energy into mechanical motion.\" Motion Movimiento \"Actuators are responsible for creating motion and enabling a robot's locomotion.\" Multiple M\u00faltiple \"The robot had multiple actuators that worked together for coordinated movements.\" Perform Realizar \"Actuators allow robots to perform complex tasks with precision and accuracy.\" Position Posici\u00f3n \"Motors can control the position of a robot's arm or joint with high accuracy.\"","title":"Actuators"},{"location":"contents/robotics/actuators.html#actuators","text":"An actuator is a component of a robot that is responsible for creating movement or motion . In other words, an actuator is what makes a robot move, grab, lift, or perform any other physical action. There are different types of actuators used in robotics, depending on the purpose and design of the robot. Some common types of actuators include: Motors : These are electrical or mechanical devices that convert electrical energy into mechanical energy to create motion. Motors are commonly used in robots to drive wheels, move robot arms, or control the position of robot joints. Pneumatic cylinders : These are devices that use compressed air to create motion. Pneumatic cylinders are often used in industrial robots to move heavy loads or in applications where precision and speed are important. Hydraulic cylinders : Similar to pneumatic cylinders, hydraulic cylinders use fluid instead of air to create motion. They are often used in large industrial robots for heavy-duty applications. Solenoids : These are electromechanical devices that convert electrical energy into linear or rotary motion. Solenoids are commonly used in small robots for precise movements, such as opening and closing robot grippers. In summary, an actuator is a critical component of a robot that creates motion or movement . Different types of actuators are used depending on the application and design of the robot. By using actuators, robots can perform physical tasks and interact with their environment, making them useful for a wide range of applications, from manufacturing to healthcare.","title":"Actuators"},{"location":"contents/robotics/actuators.html#glossary","text":"English Spanish Example Sentence (English) Actuators Actuadores \"The robot's actuators allowed it to perform precise movements and interact with objects.\" Applications Aplicaciones \"Robots have various applications in industries such as manufacturing, healthcare, and more.\" Arms Brazos \"The robot's multiple arms enabled it to manipulate objects with dexterity.\" Component Componente \"The actuator is an essential component of a robot's mechanism.\" Control Control \"The robot's actuators were operated by a sophisticated control system.\" Convert Convertir \"The motor converts electrical energy into mechanical energy for locomotion.\" Create Crear \"The hydraulic cylinder creates powerful motion to lift heavy loads.\" Critical Cr\u00edtico \"The actuator is a critical element for the robot's functionality.\" Design Dise\u00f1o \"The choice of actuators depends on the robot's design and intended tasks.\" Devices Dispositivos \"Motors, solenoids, and cylinders are common devices used as actuators.\" Drive Impulsar \"The motors drive the robot's wheels, propelling it forward.\" Electrical El\u00e9ctrico \"Solenoids are electrical devices that convert energy into motion.\" Energy Energ\u00eda \"Actuators require a power source to operate and convert energy into motion.\" Fluid Fluido \"Hydraulic cylinders use fluid to generate motion in the robot's limbs.\" Grab Agarrar \"The robot's gripper can grab and manipulate objects of different shapes and sizes.\" Heavy-duty Resistente \"Industrial robots equipped with hydraulic cylinders can handle heavy-duty tasks.\" Important Importante \"Precision and speed are important factors in choosing pneumatic cylinders for a robot.\" Interact Interactuar \"Robots can interact with humans and their surroundings using various actuators.\" Linear Lineal \"Solenoids can produce linear or rotary motion depending on the design.\" Mechanical Mec\u00e1nico \"Motors are mechanical devices that convert electrical energy into mechanical motion.\" Motion Movimiento \"Actuators are responsible for creating motion and enabling a robot's locomotion.\" Multiple M\u00faltiple \"The robot had multiple actuators that worked together for coordinated movements.\" Perform Realizar \"Actuators allow robots to perform complex tasks with precision and accuracy.\" Position Posici\u00f3n \"Motors can control the position of a robot's arm or joint with high accuracy.\"","title":"Glossary"},{"location":"contents/robotics/controllers.html","text":"Controller A controller is a device or system that manages and controls the behavior of a robot. It receives input from sensors and provides output to actuators to ensure the robot moves or behaves in a specific way. Controllers are essential for ensuring that a robot operates safely, efficiently, and effectively. They can be simple or complex, depending on the complexity of the robot and the tasks it is designed to perform. For example, a simple controller might be used to control the motion of a small robot that moves in a straight line, while a more complex controller might be used to manage the movements of a larger robot with multiple arms and sensors. There are different types of controllers used in robotics, such as: Microcontrollers : These are small computers that are embedded within the robot itself. They can receive input from sensors, process data, and provide output to actuators, all in real-time. Microcontrollers are often used in small, simple robots. Programmable Logic Controllers (PLCs) : These are specialized computers that are designed to control industrial machinery, including robots. They can manage multiple inputs and outputs, and are often used in large, complex robotic systems. Robot Operating System (ROS) : This is an open-source platform for programming robots. It provides a range of tools and libraries that enable developers to create and manage the behavior of robots, including controllers. In summary, a controller is a device or system that manages and controls the behavior of a robot. It receives input from sensors and provides output to actuators, ensuring that the robot moves and behaves in a specific way. Different types of controllers are used depending on the complexity of the robot and the tasks it is designed to perform. Glossary English Spanish Example Sentence (English) Actuators Actuadores \"The robot's actuators responded to the controller's commands, enabling precise movements.\" Behavior Comportamiento \"The controller dictated the robot's behavior , ensuring it followed the desired operating parameters.\" Complexity Complejidad \"The controller's design varied based on the robot's complexity and the tasks it needed to accomplish.\" Computers Computadoras \"Microcontrollers and PLCs are types of computers used as controllers in robotics.\" Control Control \"The controller's main function was to control the robot's actions and responses to the environment.\" Efficiency Eficiencia \"The advanced controller improved the robot's efficiency by optimizing its movements and power usage.\" Embedded Incorporado \"Microcontrollers are embedded within the robot's structure, enabling real-time control.\" Input Entrada \"The controller processed the input from various sensors to make informed decisions.\" Manage Gestionar \"The controller was responsible for managing the robot's operations and maintaining its performance.\" Microcontrollers Microcontroladores \"Small robots often rely on microcontrollers as their primary controllers due to their compact size.\" Movements Movimientos \"The controller coordinated the robot's movements with precision and smoothness.\" Multiple M\u00faltiple \"Complex robots with multiple arms and sensors required a sophisticated controller for coordinated control.\" Open-source C\u00f3digo abierto \"ROS, an open-source platform, provided flexible and accessible tools for robot behavior control.\" Output Salida \"The controller generated output signals to direct the actuators and influence the robot's behavior.\" Platform Plataforma \"ROS served as a powerful platform for developing and implementing robot controllers.\" Programmable Programable \"PLCs offered a programmable solution for controlling complex robotic systems in industrial settings.\" Real-time Tiempo real \"Microcontrollers processed sensor data and produced real-time control signals for immediate robot response.\" Receive Recibir \"The controller could receive and interpret signals from various sensors to make informed decisions.\" Robotic systems Sistemas rob\u00f3ticos \"PLCs were commonly used in large robotic systems for managing multiple actuators and sensors.\" Sensors Sensores \"The controller relied on sensors to gather information about the robot's environment and conditions.\" Simple Simple \"A simple controller sufficed for the basic motion control of a small line-following robot.\" Tasks Tareas \"The controller assigned specific tasks to different actuators, enabling coordinated robot behavior.\" Tools Herramientas \"ROS provided a rich set of","title":"Controllers"},{"location":"contents/robotics/controllers.html#controller","text":"A controller is a device or system that manages and controls the behavior of a robot. It receives input from sensors and provides output to actuators to ensure the robot moves or behaves in a specific way. Controllers are essential for ensuring that a robot operates safely, efficiently, and effectively. They can be simple or complex, depending on the complexity of the robot and the tasks it is designed to perform. For example, a simple controller might be used to control the motion of a small robot that moves in a straight line, while a more complex controller might be used to manage the movements of a larger robot with multiple arms and sensors. There are different types of controllers used in robotics, such as: Microcontrollers : These are small computers that are embedded within the robot itself. They can receive input from sensors, process data, and provide output to actuators, all in real-time. Microcontrollers are often used in small, simple robots. Programmable Logic Controllers (PLCs) : These are specialized computers that are designed to control industrial machinery, including robots. They can manage multiple inputs and outputs, and are often used in large, complex robotic systems. Robot Operating System (ROS) : This is an open-source platform for programming robots. It provides a range of tools and libraries that enable developers to create and manage the behavior of robots, including controllers. In summary, a controller is a device or system that manages and controls the behavior of a robot. It receives input from sensors and provides output to actuators, ensuring that the robot moves and behaves in a specific way. Different types of controllers are used depending on the complexity of the robot and the tasks it is designed to perform.","title":"Controller"},{"location":"contents/robotics/controllers.html#glossary","text":"English Spanish Example Sentence (English) Actuators Actuadores \"The robot's actuators responded to the controller's commands, enabling precise movements.\" Behavior Comportamiento \"The controller dictated the robot's behavior , ensuring it followed the desired operating parameters.\" Complexity Complejidad \"The controller's design varied based on the robot's complexity and the tasks it needed to accomplish.\" Computers Computadoras \"Microcontrollers and PLCs are types of computers used as controllers in robotics.\" Control Control \"The controller's main function was to control the robot's actions and responses to the environment.\" Efficiency Eficiencia \"The advanced controller improved the robot's efficiency by optimizing its movements and power usage.\" Embedded Incorporado \"Microcontrollers are embedded within the robot's structure, enabling real-time control.\" Input Entrada \"The controller processed the input from various sensors to make informed decisions.\" Manage Gestionar \"The controller was responsible for managing the robot's operations and maintaining its performance.\" Microcontrollers Microcontroladores \"Small robots often rely on microcontrollers as their primary controllers due to their compact size.\" Movements Movimientos \"The controller coordinated the robot's movements with precision and smoothness.\" Multiple M\u00faltiple \"Complex robots with multiple arms and sensors required a sophisticated controller for coordinated control.\" Open-source C\u00f3digo abierto \"ROS, an open-source platform, provided flexible and accessible tools for robot behavior control.\" Output Salida \"The controller generated output signals to direct the actuators and influence the robot's behavior.\" Platform Plataforma \"ROS served as a powerful platform for developing and implementing robot controllers.\" Programmable Programable \"PLCs offered a programmable solution for controlling complex robotic systems in industrial settings.\" Real-time Tiempo real \"Microcontrollers processed sensor data and produced real-time control signals for immediate robot response.\" Receive Recibir \"The controller could receive and interpret signals from various sensors to make informed decisions.\" Robotic systems Sistemas rob\u00f3ticos \"PLCs were commonly used in large robotic systems for managing multiple actuators and sensors.\" Sensors Sensores \"The controller relied on sensors to gather information about the robot's environment and conditions.\" Simple Simple \"A simple controller sufficed for the basic motion control of a small line-following robot.\" Tasks Tareas \"The controller assigned specific tasks to different actuators, enabling coordinated robot behavior.\" Tools Herramientas \"ROS provided a rich set of","title":"Glossary"},{"location":"contents/robotics/crashcourse_robotics_ai.html","text":"Robotics: Crash Course AI #11 Video #2: Robotics (Crash Course AI #11) Robots aren\u2019t like humans who can do a lot of different things. They\u2019re designed for very specific tasks like vacuuming our homes, assembling cars in a factory, or exploring the surface of other planets. So even though it may be a while before we have a general household robot that can do it all, robots are still really important because they can do some things incredibly well even better than humans. So today, we're going to take a look at the role of AI in overcoming three key challenges in the field of robotics: localization, planning, and manipulation.","title":"Robotics: Crash Course AI #11"},{"location":"contents/robotics/crashcourse_robotics_ai.html#robotics-crash-course-ai-11","text":"","title":"Robotics: Crash Course AI #11"},{"location":"contents/robotics/crashcourse_robotics_ai.html#video-2-robotics-crash-course-ai-11","text":"Robots aren\u2019t like humans who can do a lot of different things. They\u2019re designed for very specific tasks like vacuuming our homes, assembling cars in a factory, or exploring the surface of other planets. So even though it may be a while before we have a general household robot that can do it all, robots are still really important because they can do some things incredibly well even better than humans. So today, we're going to take a look at the role of AI in overcoming three key challenges in the field of robotics: localization, planning, and manipulation.","title":"Video #2: Robotics (Crash Course AI #11)"},{"location":"contents/robotics/crashcourse_robots.html","text":"Robots Video #1: Robots (Crash Course Computer Science #37) Today we're going to talk about robots! Robots are often thought as a technology of the future, but they're already here by the millions in the workplace, our homes, and pretty soon on the roads. We'll discuss the origins of robotics to its proliferation, and even look at some common control designs that were implemented to make them more useful in the workplace. Robots are often thought of as a menace or danger to society, and although there definitely is the propensity for malicious uses, robots also have the potential to drastically improve the world. Video #1 Transcription Hi, I\u2019m Carrie Anne, and welcome to CrashCourse Computer Science! Today we\u2019re going to talk about robots. The word \u201crobot\u201d was first used in a 1920 Czech play to denote artificial, humanoid characters. The word was derived from \u201crobota\u201d, the slavic-language word for a forced laborer, indicating peasants in compulsory service in feudal, nineteenth century Europe. But even a century later, it\u2019s still a common portrayal: mass-produced, efficient, tireless creatures that look human-esque, but are emotionless, indifferent to self-preservation and lack creativity. There are many definitions for robots, but in general, these are machines capable of carrying out a series of actions automatically, guided by computer control. How they look isn\u2019t part of the equation \u2013 robots can be industrial arms that spray paint cars, drones that fly, snake-like medical robots that assist surgeons, as well as humanoid robotic assistants. Although the term \u201crobot\u201d is sometimes applied to interactive virtual characters, it\u2019s more appropriate to call these \u201cbots\u201d, or even better, \u201cagents.\u201d That\u2019s because the term \u201crobot\u201d carries a physical connotation, a machine that lives in and acts on the real world. The more general idea of self-operating machines goes back even further than the 1920s. Many ancient inventors created mechanical devices that performed functions automatically, like keeping the time and striking bells on the hour. There are plenty of examples of automated animal and humanoid figures that would perform dances, sing songs, strike drums, and do other physical actions. These non-electrical and certainly non-electronic machines were called automatons. For instance, an early automaton created in 1739 by the Frenchman Jacques de Vaucanson was the Canard Digerateur or Digesting Duck, a machine in the shape of a duck that appeared to eat grain and then defecate. The first machines controlled by computers emerged in the late 1940s. These Computer Numerical Control, or CNC, machines could run programs that instructed a machine to perform a series of operations. This level of control also enabled the creation of new manufactured goods, like milling a complex propellor design out of a block of aluminum \u2013 something that was difficult to do using standard machine tools, and with tolerances too small to be done by hand. CNC machines were a huge boon to industry, not just due to increased capability and precision, but also in terms of reducing labor costs by automating human jobs \u2013 a topic we\u2019ll revisit in a later episode. The first commercial deployment was a programmable industrial robot called the Unimate, sold to General Motors in 1960 to lift hot pieces of metal from a die casting machine and stack them. This was the start of the robotics industry. Soon, robots were stacking pallets, welding parts, painting cars and much more. The first image that jumps to your mind is probably a humanoid robot, like we usually see in shows or movies. Sometimes they\u2019re our friends and colleagues, but more often, they\u2019re sinister, apathetic, and battle-hardened. We also tend to think of robots as a technology of the future. But the reality is: they\u2019re already here \u2013 by the millions \u2013 and they\u2019re our workmates, helping us to do things harder, better, faster, and stronger. For simple motions \u2013 like a robotic gripper that moves back and forth on a track \u2013 a robot can be instructed to move to a particular position, and it\u2019ll keep moving in that direction until the desired position is reached, at which point it\u2019ll stop. This behavior can be achieved through a simple control loop. First, sense the robot position. Are we there yet? Nope. So keep moving. Now sense position again. Are we there yet? Nope So keep moving. Now sense position again. Are we there yet? Nope, so keep moving. Are we there yet? Yes! So we can stop moving, and also please be quiet! Because we\u2019re trying to minimize the distance between the sensed position and the desired position, this control loop is, more specifically, a negative feedback loop. A negative feedback control loop has three key pieces. There\u2019s a sensor, that measures things in the real world, like water pressure, motor position, air temperature, or whatever you\u2019re trying to control. From this measurement, we calculate how far we are from where we want to be \u2013 the error. The error is then interpreted by a controller, which decides how to instruct the system to minimize that error. Then, the system acts on the world though pumps, motors, heating elements, and other physical actuators. In tightly controlled environments, simple control loops, like this, work OK. But in many real world applications, things are a tad more complicated. Imagine that our gripper is really heavy, and even when the control loop says to stop, momentum causes the gripper to overshoot the desired position. That would cause the control loop to take over again, this time backing the gripper up. A badly tuned control loop might overshoot and overshoot and overshoot, and maybe even wobble forever. To make matters worse, in real world settings, there are typically external and variable forces acting on a robot, like friction, wind and items of different weight. To handle this gracefully, more sophisticated control logic is needed. A widely used control-loop, feedback mechanism is a proportional\u2013integral\u2013derivative controller. That\u2019s a bit of a mouthful, so people call them PID controllers. These used to be mechanical devices, but now it\u2019s all done in software. Let\u2019s imagine a robot that delivers coffee. Its goal is to travel between customers at two meters per second, which has been determined to be the ideal speed that\u2019s both safe and expedient. Of course, the environment doesn\u2019t always cooperate. Sometimes there\u2019s wind, and sometimes there's uphills and downhills and all sorts of things that affect the speed of the robot. So, it\u2019s going to have to increase and decrease power to its motors to maintain the desired speed. Using the robot's speed sensor, we can keep track of its actual speed and plot that alongside its desired speed. PID controllers calculate three values from this data. First is the proportional value, which is the difference between the desired value and the actual value at the most recent instant in time or the present. This is what our simpler control loop used before. The bigger the gap between actual and desired, the harder you'll push towards your target. In other words, it\u2019s proportional control. Next, the integral value is computed, which is the sum of error over a window of time, like the last few seconds. This look back helps compensate for steady state errors, resulting from things like motoring up a long hill. If this value is large, it means proportional control is not enough, and we have to push harder still. Finally, there\u2019s the derivative value, which is the rate of change between the desired and actual values. This helps account for possible future error and is sometimes called \"anticipatory control\". For example, if you are screaming in towards your goal too fast, you\u2019ll need to ease up a little to prevent overshoot. These three values are summed together, with different relative weights, to produce a controller output that\u2019s passed to the system. PID controllers are everywhere, from the cruise control in your car to drones that automatically adjust their rotor speeds to maintain level flight, as well as more exotic robots, like this one that balances on a ball to move around. Advanced robots often require many control loops running in parallel, working together, managing everything from robot balance to limb position. Control loops are responsible for getting robot attributes like location to desired values. So, you may be wondering where these values come from. This is the responsibility of higher-level robot software, which plans and executes robot actions, like plotting a path around sensed obstacles, or breaking down physical tasks, like picking up a ball, into simple, sequential motions. Using these techniques, robots have racked up some impressive achievements \u2013 they\u2019ve been to the deepest depths of Earth\u2019s oceans and roved around on Mars for over a decade. But interestingly, lots of problems that are trivial for many humans have turned out to be devilishly difficult for robots: like walking on two legs, opening a door, picking up objects without crushing them, putting on a t-shirt, or petting a dog. These are tasks you may be able to do without thinking, but a supercomputer-powered robot fails at spectacularly. These sorts of tasks are all active areas of robotics research. Artificial intelligence techniques, which we discussed a few episodes ago, are perhaps the most promising avenue to overcome these challenges. For example, Google has been running an experiment with a series of robotic arms that spend their days moving miscellaneous objects from one box to another, learning from trial and error. After thousands of hours of practice, the robots had cut their error rate in half. Of course, unlike humans, robots can run twenty-four hours a day and practice with many arms at the same time. So, it may just be a matter of time until they become adept at grasping things. But, for the time being, toddlers can out-grasp them. One of the biggest and most visible robotic breakthroughs in recent years has been self-driving, autonomous cars. If you think about it, cars don\u2019t have too many system inputs \u2013 you can speed up or slow down, and you can steer left or right. The tough part is sensing lanes, reading signs, and anticipating and navigating traffic, pedestrians, bicyclists, and a whole host of obstacles. In addition to being studded with proximity sensors, these robotic vehicles heavily rely on Computer Vision algorithms, which we discussed in Episode 35. We\u2019re also seeing the emergence of very primitive androids \u2013 robots that look and act like humans. Arguably, we\u2019re not close on either of those goals, as they tend to look pretty weird and act even weirder. At least we\u2019ll always have Westworld. But anyway, these remain a tantalizing goal for roboticists that combine many computer science topics we\u2019ve touched on over the last few episodes, like artificial intelligence, computer vision, and natural language processing. As for why humans are so fascinated by creating artificial embodiments of ourselves...you\u2019ll have to go to Crash Course Philosophy for that. And for the foreseeable future, realistic androids will continue to be the stuff of science fiction. Militaries also have a great interest in robots \u2013 they\u2019re not only replaceable but can surpass humans in attributes like strength, endurance, attention, and accuracy. Bomb disposal robots and reconnaissance drones are fairly common today. But fully autonomous, armed-to-the-teeth robots are slowly appearing, like the Samsung SGR-A1 sentry gun deployed by South Korea. Robots with the intelligence and capability to take human lives are called lethal autonomous weapons. And they\u2019re widely considered a complex and thorny issue. Without doubt, these systems could save soldiers lives by taking them off the battlefield and out of harm\u2019s way. It might even discourage war altogether. Though it\u2019s worth noting that people said the same thing about dynamite and nuclear weapons. On the flip side, we might be creating ruthlessly efficient killing machines that don\u2019t apply human judgment or compassion to complex situations. And the fog of war is about as complex and murky as they come. These robots would be taking orders and executing them as efficiently as they can, and sometimes human orders turn out to be really bad. This debate is going to continue for a long time, and pundits on both sides will grow louder as robotic technology improves. It\u2019s also an old debate \u2013 the danger was obvious to science fiction writer Isaac Asimov, who introduced a fictional \u201cThree Laws of Robotics\u201d in his 1942 short story \"Runaround\". And then, later he added a zeroth rule. In short, it\u2019s a code of conduct or moral compass for robots \u2013 guiding them to do no harm, especially to humans. It\u2019s pretty inadequate for practical application and it leaves plenty of room for equivocation. But still, Asimov\u2019s laws inspired a ton of science fiction and academic discussion, and today there are whole conferences on robot ethics. Importantly, Asimov crafted his fictional rules as a way to push back on \u201cRobot as a Menace\u201d memes common in fiction from his childhood. These were stories where robots went off the rails, harming or even destroying their creators in the process. Asimov, on the other hand, envisioned robots as useful, reliable, and even lovable machines. And it\u2019s this duality I want to leave you thinking about today. Like many of the technologies we\u2019ve discussed throughout this series, there are benevolent and malicious uses. Our job is to carefully reflect on computing's potential and peril, and wield our inventive talents to improve the state of the world. And robots are one of the most potent reminders of this responsibility. I\u2019ll see you next week.","title":"Robots"},{"location":"contents/robotics/crashcourse_robots.html#robots","text":"","title":"Robots"},{"location":"contents/robotics/crashcourse_robots.html#video-1-robots-crash-course-computer-science-37","text":"Today we're going to talk about robots! Robots are often thought as a technology of the future, but they're already here by the millions in the workplace, our homes, and pretty soon on the roads. We'll discuss the origins of robotics to its proliferation, and even look at some common control designs that were implemented to make them more useful in the workplace. Robots are often thought of as a menace or danger to society, and although there definitely is the propensity for malicious uses, robots also have the potential to drastically improve the world.","title":"Video #1: Robots (Crash Course Computer Science #37)"},{"location":"contents/robotics/crashcourse_robots.html#video-1-transcription","text":"Hi, I\u2019m Carrie Anne, and welcome to CrashCourse Computer Science! Today we\u2019re going to talk about robots. The word \u201crobot\u201d was first used in a 1920 Czech play to denote artificial, humanoid characters. The word was derived from \u201crobota\u201d, the slavic-language word for a forced laborer, indicating peasants in compulsory service in feudal, nineteenth century Europe. But even a century later, it\u2019s still a common portrayal: mass-produced, efficient, tireless creatures that look human-esque, but are emotionless, indifferent to self-preservation and lack creativity. There are many definitions for robots, but in general, these are machines capable of carrying out a series of actions automatically, guided by computer control. How they look isn\u2019t part of the equation \u2013 robots can be industrial arms that spray paint cars, drones that fly, snake-like medical robots that assist surgeons, as well as humanoid robotic assistants. Although the term \u201crobot\u201d is sometimes applied to interactive virtual characters, it\u2019s more appropriate to call these \u201cbots\u201d, or even better, \u201cagents.\u201d That\u2019s because the term \u201crobot\u201d carries a physical connotation, a machine that lives in and acts on the real world. The more general idea of self-operating machines goes back even further than the 1920s. Many ancient inventors created mechanical devices that performed functions automatically, like keeping the time and striking bells on the hour. There are plenty of examples of automated animal and humanoid figures that would perform dances, sing songs, strike drums, and do other physical actions. These non-electrical and certainly non-electronic machines were called automatons. For instance, an early automaton created in 1739 by the Frenchman Jacques de Vaucanson was the Canard Digerateur or Digesting Duck, a machine in the shape of a duck that appeared to eat grain and then defecate. The first machines controlled by computers emerged in the late 1940s. These Computer Numerical Control, or CNC, machines could run programs that instructed a machine to perform a series of operations. This level of control also enabled the creation of new manufactured goods, like milling a complex propellor design out of a block of aluminum \u2013 something that was difficult to do using standard machine tools, and with tolerances too small to be done by hand. CNC machines were a huge boon to industry, not just due to increased capability and precision, but also in terms of reducing labor costs by automating human jobs \u2013 a topic we\u2019ll revisit in a later episode. The first commercial deployment was a programmable industrial robot called the Unimate, sold to General Motors in 1960 to lift hot pieces of metal from a die casting machine and stack them. This was the start of the robotics industry. Soon, robots were stacking pallets, welding parts, painting cars and much more. The first image that jumps to your mind is probably a humanoid robot, like we usually see in shows or movies. Sometimes they\u2019re our friends and colleagues, but more often, they\u2019re sinister, apathetic, and battle-hardened. We also tend to think of robots as a technology of the future. But the reality is: they\u2019re already here \u2013 by the millions \u2013 and they\u2019re our workmates, helping us to do things harder, better, faster, and stronger. For simple motions \u2013 like a robotic gripper that moves back and forth on a track \u2013 a robot can be instructed to move to a particular position, and it\u2019ll keep moving in that direction until the desired position is reached, at which point it\u2019ll stop. This behavior can be achieved through a simple control loop. First, sense the robot position. Are we there yet? Nope. So keep moving. Now sense position again. Are we there yet? Nope So keep moving. Now sense position again. Are we there yet? Nope, so keep moving. Are we there yet? Yes! So we can stop moving, and also please be quiet! Because we\u2019re trying to minimize the distance between the sensed position and the desired position, this control loop is, more specifically, a negative feedback loop. A negative feedback control loop has three key pieces. There\u2019s a sensor, that measures things in the real world, like water pressure, motor position, air temperature, or whatever you\u2019re trying to control. From this measurement, we calculate how far we are from where we want to be \u2013 the error. The error is then interpreted by a controller, which decides how to instruct the system to minimize that error. Then, the system acts on the world though pumps, motors, heating elements, and other physical actuators. In tightly controlled environments, simple control loops, like this, work OK. But in many real world applications, things are a tad more complicated. Imagine that our gripper is really heavy, and even when the control loop says to stop, momentum causes the gripper to overshoot the desired position. That would cause the control loop to take over again, this time backing the gripper up. A badly tuned control loop might overshoot and overshoot and overshoot, and maybe even wobble forever. To make matters worse, in real world settings, there are typically external and variable forces acting on a robot, like friction, wind and items of different weight. To handle this gracefully, more sophisticated control logic is needed. A widely used control-loop, feedback mechanism is a proportional\u2013integral\u2013derivative controller. That\u2019s a bit of a mouthful, so people call them PID controllers. These used to be mechanical devices, but now it\u2019s all done in software. Let\u2019s imagine a robot that delivers coffee. Its goal is to travel between customers at two meters per second, which has been determined to be the ideal speed that\u2019s both safe and expedient. Of course, the environment doesn\u2019t always cooperate. Sometimes there\u2019s wind, and sometimes there's uphills and downhills and all sorts of things that affect the speed of the robot. So, it\u2019s going to have to increase and decrease power to its motors to maintain the desired speed. Using the robot's speed sensor, we can keep track of its actual speed and plot that alongside its desired speed. PID controllers calculate three values from this data. First is the proportional value, which is the difference between the desired value and the actual value at the most recent instant in time or the present. This is what our simpler control loop used before. The bigger the gap between actual and desired, the harder you'll push towards your target. In other words, it\u2019s proportional control. Next, the integral value is computed, which is the sum of error over a window of time, like the last few seconds. This look back helps compensate for steady state errors, resulting from things like motoring up a long hill. If this value is large, it means proportional control is not enough, and we have to push harder still. Finally, there\u2019s the derivative value, which is the rate of change between the desired and actual values. This helps account for possible future error and is sometimes called \"anticipatory control\". For example, if you are screaming in towards your goal too fast, you\u2019ll need to ease up a little to prevent overshoot. These three values are summed together, with different relative weights, to produce a controller output that\u2019s passed to the system. PID controllers are everywhere, from the cruise control in your car to drones that automatically adjust their rotor speeds to maintain level flight, as well as more exotic robots, like this one that balances on a ball to move around. Advanced robots often require many control loops running in parallel, working together, managing everything from robot balance to limb position. Control loops are responsible for getting robot attributes like location to desired values. So, you may be wondering where these values come from. This is the responsibility of higher-level robot software, which plans and executes robot actions, like plotting a path around sensed obstacles, or breaking down physical tasks, like picking up a ball, into simple, sequential motions. Using these techniques, robots have racked up some impressive achievements \u2013 they\u2019ve been to the deepest depths of Earth\u2019s oceans and roved around on Mars for over a decade. But interestingly, lots of problems that are trivial for many humans have turned out to be devilishly difficult for robots: like walking on two legs, opening a door, picking up objects without crushing them, putting on a t-shirt, or petting a dog. These are tasks you may be able to do without thinking, but a supercomputer-powered robot fails at spectacularly. These sorts of tasks are all active areas of robotics research. Artificial intelligence techniques, which we discussed a few episodes ago, are perhaps the most promising avenue to overcome these challenges. For example, Google has been running an experiment with a series of robotic arms that spend their days moving miscellaneous objects from one box to another, learning from trial and error. After thousands of hours of practice, the robots had cut their error rate in half. Of course, unlike humans, robots can run twenty-four hours a day and practice with many arms at the same time. So, it may just be a matter of time until they become adept at grasping things. But, for the time being, toddlers can out-grasp them. One of the biggest and most visible robotic breakthroughs in recent years has been self-driving, autonomous cars. If you think about it, cars don\u2019t have too many system inputs \u2013 you can speed up or slow down, and you can steer left or right. The tough part is sensing lanes, reading signs, and anticipating and navigating traffic, pedestrians, bicyclists, and a whole host of obstacles. In addition to being studded with proximity sensors, these robotic vehicles heavily rely on Computer Vision algorithms, which we discussed in Episode 35. We\u2019re also seeing the emergence of very primitive androids \u2013 robots that look and act like humans. Arguably, we\u2019re not close on either of those goals, as they tend to look pretty weird and act even weirder. At least we\u2019ll always have Westworld. But anyway, these remain a tantalizing goal for roboticists that combine many computer science topics we\u2019ve touched on over the last few episodes, like artificial intelligence, computer vision, and natural language processing. As for why humans are so fascinated by creating artificial embodiments of ourselves...you\u2019ll have to go to Crash Course Philosophy for that. And for the foreseeable future, realistic androids will continue to be the stuff of science fiction. Militaries also have a great interest in robots \u2013 they\u2019re not only replaceable but can surpass humans in attributes like strength, endurance, attention, and accuracy. Bomb disposal robots and reconnaissance drones are fairly common today. But fully autonomous, armed-to-the-teeth robots are slowly appearing, like the Samsung SGR-A1 sentry gun deployed by South Korea. Robots with the intelligence and capability to take human lives are called lethal autonomous weapons. And they\u2019re widely considered a complex and thorny issue. Without doubt, these systems could save soldiers lives by taking them off the battlefield and out of harm\u2019s way. It might even discourage war altogether. Though it\u2019s worth noting that people said the same thing about dynamite and nuclear weapons. On the flip side, we might be creating ruthlessly efficient killing machines that don\u2019t apply human judgment or compassion to complex situations. And the fog of war is about as complex and murky as they come. These robots would be taking orders and executing them as efficiently as they can, and sometimes human orders turn out to be really bad. This debate is going to continue for a long time, and pundits on both sides will grow louder as robotic technology improves. It\u2019s also an old debate \u2013 the danger was obvious to science fiction writer Isaac Asimov, who introduced a fictional \u201cThree Laws of Robotics\u201d in his 1942 short story \"Runaround\". And then, later he added a zeroth rule. In short, it\u2019s a code of conduct or moral compass for robots \u2013 guiding them to do no harm, especially to humans. It\u2019s pretty inadequate for practical application and it leaves plenty of room for equivocation. But still, Asimov\u2019s laws inspired a ton of science fiction and academic discussion, and today there are whole conferences on robot ethics. Importantly, Asimov crafted his fictional rules as a way to push back on \u201cRobot as a Menace\u201d memes common in fiction from his childhood. These were stories where robots went off the rails, harming or even destroying their creators in the process. Asimov, on the other hand, envisioned robots as useful, reliable, and even lovable machines. And it\u2019s this duality I want to leave you thinking about today. Like many of the technologies we\u2019ve discussed throughout this series, there are benevolent and malicious uses. Our job is to carefully reflect on computing's potential and peril, and wield our inventive talents to improve the state of the world. And robots are one of the most potent reminders of this responsibility. I\u2019ll see you next week.","title":"Video #1 Transcription"},{"location":"contents/robotics/crashcourse_robots_engineering.html","text":"How Engineering Robots Works Video #3: How Engineering Robots Works (Crash Course Engineering #33) In this episode we looked at robots and the engineering principles of robots. We learned how robots use sensors to interpret their environment, how actuators and effectors allow a robot to manipulate the objects around it to accomplish a task, and how computers coordinate the efforts of the two.","title":"How Engineering Robots Works"},{"location":"contents/robotics/crashcourse_robots_engineering.html#how-engineering-robots-works","text":"","title":"How Engineering Robots Works"},{"location":"contents/robotics/crashcourse_robots_engineering.html#video-3-how-engineering-robots-works-crash-course-engineering-33","text":"In this episode we looked at robots and the engineering principles of robots. We learned how robots use sensors to interpret their environment, how actuators and effectors allow a robot to manipulate the objects around it to accomplish a task, and how computers coordinate the efforts of the two.","title":"Video #3: How Engineering Robots Works (Crash Course Engineering #33)"},{"location":"contents/robotics/intro.html","text":"Robotics","title":"Robotics"},{"location":"contents/robotics/intro.html#robotics","text":"","title":"Robotics"},{"location":"contents/robotics/intro_sens_act_contr.html","text":"Sensors, actuators and controllers Sensors are devices that detect or measure physical quantities such as temperature, light, pressure, and distance. In robotics, sensors are used to detect changes in the environment and provide feedback to the system. For example, a robot may use sensors to detect obstacles in its path or to measure the distance to an object. Actuators , on the other hand, are devices that are responsible for controlling motion or movement in a robot. They are used to make a robot move or perform a specific action based on the input received from the controller. Examples of actuators include motors, pneumatic cylinders, and solenoids. Controllers are devices or systems that manage and control the overall behavior of a robot. They process input from sensors and provide output to actuators to ensure the robot moves or behaves in a specific way. Controllers can be simple or complex, depending on the complexity of the robot and the tasks it is designed to perform. To summarize, sensors detect changes in the environment, actuators create motion or movement, and controllers manage the overall behavior of the robot. All three components work together to allow a robot to perform specific tasks and interact with its environment.","title":"Intro sens act contr"},{"location":"contents/robotics/intro_sens_act_contr.html#sensors-actuators-and-controllers","text":"Sensors are devices that detect or measure physical quantities such as temperature, light, pressure, and distance. In robotics, sensors are used to detect changes in the environment and provide feedback to the system. For example, a robot may use sensors to detect obstacles in its path or to measure the distance to an object. Actuators , on the other hand, are devices that are responsible for controlling motion or movement in a robot. They are used to make a robot move or perform a specific action based on the input received from the controller. Examples of actuators include motors, pneumatic cylinders, and solenoids. Controllers are devices or systems that manage and control the overall behavior of a robot. They process input from sensors and provide output to actuators to ensure the robot moves or behaves in a specific way. Controllers can be simple or complex, depending on the complexity of the robot and the tasks it is designed to perform. To summarize, sensors detect changes in the environment, actuators create motion or movement, and controllers manage the overall behavior of the robot. All three components work together to allow a robot to perform specific tasks and interact with its environment.","title":"Sensors, actuators and controllers"},{"location":"contents/robotics/mblock.html","text":"mBlock What Is mBlock 5? mBlock 5 is designed for the Science, Technology, Engineering, Arts and Mathematics (STEAM) education. Inspired by Scratch 3.0, it supports both graphical and textual programming languages. Currently, more than 10 million people are using it to learn programming, create their own projects, and share their creations. With mBlock 5, you can design engaging stories, games, and animations, and program devices such as Makeblock robots and microbit. On mBlock 5, you can switch to the Python mode simply with one-click. In addition, mBlock 5 integrates cutting-edge technologies including Artificial Intelligence (AI) and Internet of Things (IoT). Software versions Currently, the following versions are available: For PCs (software required): www.mblock.cc/en-us/download Web version (no software required): ide.mblock.cc/ For Android and iOS : Search for mBlock on any app store to download it","title":"mBlock"},{"location":"contents/robotics/mblock.html#mblock","text":"","title":"mBlock"},{"location":"contents/robotics/mblock.html#what-is-mblock-5","text":"mBlock 5 is designed for the Science, Technology, Engineering, Arts and Mathematics (STEAM) education. Inspired by Scratch 3.0, it supports both graphical and textual programming languages. Currently, more than 10 million people are using it to learn programming, create their own projects, and share their creations. With mBlock 5, you can design engaging stories, games, and animations, and program devices such as Makeblock robots and microbit. On mBlock 5, you can switch to the Python mode simply with one-click. In addition, mBlock 5 integrates cutting-edge technologies including Artificial Intelligence (AI) and Internet of Things (IoT).","title":"What Is mBlock 5?"},{"location":"contents/robotics/mblock.html#software-versions","text":"Currently, the following versions are available: For PCs (software required): www.mblock.cc/en-us/download Web version (no software required): ide.mblock.cc/ For Android and iOS : Search for mBlock on any app store to download it","title":"Software versions"},{"location":"contents/robotics/mbot.html","text":"mBot Ultrasonic Sensor Me Ultrasonic module is an electronic module designed for distance detection. The distance range it can detect is 3-400 cm. mBot can use this module to avoid obstacles or for other programs about distance detection. The yellow tag on the interface of this module indicates that it is a single digital interface and that it should be connected to a port with the yellow tag on the main control board. The ultrasonic sensor measures distance. One of the \u201ceyes\u201d transmits a sound, and the other waits for the echo of the sound to return. From the time this process takes, the distance of the object from the sensor can be calculated. The ultrasonic sensor has a range of 3-400cm. If an object is outside this range, the sensor will return a value of 400. Line Follower Sensors Me Line Follower is designed for line-following robots. There are two sensors, each with an IR transmitting LED and an IR static induction phototransistor. mBot can move along a black line on a white background or a white line on a black background. It features fast detection and simple circuits. The blue tag on the interface of this module indicates that it is a dual digital interface and that it should be connected to a port with the blue tag on the main control board. The line follower has 2 sensors which can detect a white surface (within the range of 1-2cm). It works by emitting IR (InfraRed) light and recording how much is reflected back: If a lot is reflected back, it can be deduced it is close to a white surface. If a little is reflected back, it can be deduced that the surface is black, or the sensor is not near a surface. A light surface reflects a lot of infrared light back to the receiver. A dark surface only reflects a little light back to the receiver. TT Geared Motor TT Geared Motor DC 6 V / 200 RPM is the new power source with plastic gears. The TT Geared Motor perfectly works with Makeblock Plastic Timing Pulley 62T and Plastic Timing Pulley 90T for the wheel systems of DIY projects. It can be used to power mBot.","title":"mBot"},{"location":"contents/robotics/mbot.html#mbot","text":"","title":"mBot"},{"location":"contents/robotics/mbot.html#ultrasonic-sensor","text":"Me Ultrasonic module is an electronic module designed for distance detection. The distance range it can detect is 3-400 cm. mBot can use this module to avoid obstacles or for other programs about distance detection. The yellow tag on the interface of this module indicates that it is a single digital interface and that it should be connected to a port with the yellow tag on the main control board. The ultrasonic sensor measures distance. One of the \u201ceyes\u201d transmits a sound, and the other waits for the echo of the sound to return. From the time this process takes, the distance of the object from the sensor can be calculated. The ultrasonic sensor has a range of 3-400cm. If an object is outside this range, the sensor will return a value of 400.","title":"Ultrasonic Sensor"},{"location":"contents/robotics/mbot.html#line-follower-sensors","text":"Me Line Follower is designed for line-following robots. There are two sensors, each with an IR transmitting LED and an IR static induction phototransistor. mBot can move along a black line on a white background or a white line on a black background. It features fast detection and simple circuits. The blue tag on the interface of this module indicates that it is a dual digital interface and that it should be connected to a port with the blue tag on the main control board. The line follower has 2 sensors which can detect a white surface (within the range of 1-2cm). It works by emitting IR (InfraRed) light and recording how much is reflected back: If a lot is reflected back, it can be deduced it is close to a white surface. If a little is reflected back, it can be deduced that the surface is black, or the sensor is not near a surface. A light surface reflects a lot of infrared light back to the receiver. A dark surface only reflects a little light back to the receiver.","title":"Line Follower Sensors"},{"location":"contents/robotics/mbot.html#tt-geared-motor","text":"TT Geared Motor DC 6 V / 200 RPM is the new power source with plastic gears. The TT Geared Motor perfectly works with Makeblock Plastic Timing Pulley 62T and Plastic Timing Pulley 90T for the wheel systems of DIY projects. It can be used to power mBot.","title":"TT Geared Motor"},{"location":"contents/robotics/mbotcode.html","text":"mBot Robot Programming Main code The Ultrasonic Sensor Me Ultrasonic module is an electronic module designed for distance detection. The distance range it can detect is 3-400 cm. mBot can use this module to avoid obstacles or for other programs about distance detection. The yellow tag on the interface of this module indicates that it is a single digital interface and that it should be connected to a port with the yellow tag on the main control board. The ultrasonic sensor measures distance. One of the \u201ceyes\u201d transmits a sound, and the other waits for the echo of the sound to return. From the time this process takes, the distance of the object from the sensor can be calculated. The ultrasonic sensor has a range of 3-400cm. If an object is outside this range, the sensor will return a value of 400. CheckObstacles block This block is used to check for obstacles in front of the mBot. It allows the program to detect if there is an obstacle in the path of the robot using its sensors, such as the ultrasonic sensor. MoveForward block This block commands the mBot to move forward in a straight line. TurnRandom block This block instructs the mBot to turn in a random direction. It can be used to introduce randomness in the robot's movement or to create unpredictable behaviors. The Line Follower The line follower has 2 sensors which can detect a white surface (within the range of 1-2cm). It works by emitting IR (InfraRed) light and recording how much is reflected back: If a lot is reflected back, it can be deduced it is close to a white surface. If a little is reflected back, it can be deduced that the surface is black, or the sensor is not near a surface. FollowPath block This block instructs the mBot to follow a line using its line-following sensors. The block typically includes parameters or inputs to specify the speed or power at which the robot should move and the behavior it should exhibit when encountering different line configurations. The line-following sensors on the mBot detect the contrast between a line and the surrounding surface. The robot uses this information to determine its position relative to the line and adjust its movement accordingly. The mBot_FollowPath block allows users to define the specific actions the robot should take to stay on the line, such as turning left or right, stopping, or adjusting its speed.","title":"mBot Robot Programming"},{"location":"contents/robotics/mbotcode.html#mbot-robot-programming","text":"","title":"mBot Robot Programming"},{"location":"contents/robotics/mbotcode.html#main-code","text":"","title":"Main code"},{"location":"contents/robotics/mbotcode.html#the-ultrasonic-sensor","text":"Me Ultrasonic module is an electronic module designed for distance detection. The distance range it can detect is 3-400 cm. mBot can use this module to avoid obstacles or for other programs about distance detection. The yellow tag on the interface of this module indicates that it is a single digital interface and that it should be connected to a port with the yellow tag on the main control board. The ultrasonic sensor measures distance. One of the \u201ceyes\u201d transmits a sound, and the other waits for the echo of the sound to return. From the time this process takes, the distance of the object from the sensor can be calculated. The ultrasonic sensor has a range of 3-400cm. If an object is outside this range, the sensor will return a value of 400.","title":"The Ultrasonic Sensor"},{"location":"contents/robotics/mbotcode.html#checkobstacles-block","text":"This block is used to check for obstacles in front of the mBot. It allows the program to detect if there is an obstacle in the path of the robot using its sensors, such as the ultrasonic sensor.","title":"CheckObstacles block"},{"location":"contents/robotics/mbotcode.html#moveforward-block","text":"This block commands the mBot to move forward in a straight line.","title":"MoveForward block"},{"location":"contents/robotics/mbotcode.html#turnrandom-block","text":"This block instructs the mBot to turn in a random direction. It can be used to introduce randomness in the robot's movement or to create unpredictable behaviors.","title":"TurnRandom block"},{"location":"contents/robotics/mbotcode.html#the-line-follower","text":"The line follower has 2 sensors which can detect a white surface (within the range of 1-2cm). It works by emitting IR (InfraRed) light and recording how much is reflected back: If a lot is reflected back, it can be deduced it is close to a white surface. If a little is reflected back, it can be deduced that the surface is black, or the sensor is not near a surface.","title":"The Line Follower"},{"location":"contents/robotics/mbotcode.html#followpath-block","text":"This block instructs the mBot to follow a line using its line-following sensors. The block typically includes parameters or inputs to specify the speed or power at which the robot should move and the behavior it should exhibit when encountering different line configurations. The line-following sensors on the mBot detect the contrast between a line and the surrounding surface. The robot uses this information to determine its position relative to the line and adjust its movement accordingly. The mBot_FollowPath block allows users to define the specific actions the robot should take to stay on the line, such as turning left or right, stopping, or adjusting its speed.","title":"FollowPath block"},{"location":"contents/robotics/robotresearch.html","text":"Project: Researching an Advanced and Innovative Robot In this activity, you will work in pairs to research a specific advanced and innovative robot. You will gather information about the robot and create a presentation to share with the class. Part 1: Choosing a robot Start by discussing advanced and innovative robots with your partner. Choose a specific robot to research. Try to choose a robot that you find interesting or that relates to your personal interests. Part 2: Researching the robot Use reliable sources such as academic journals, reputable websites, and news articles to gather information about the robot you have chosen. Gather information on the following aspects of the robot: Purpose : What is the robot designed to do? Design : What does the robot look like? What components make up the robot? Sensors : What sensors does the robot use to interact with its environment? Actuators : What actuators does the robot use to move and interact with its environment? Controller : What type of controller does the robot use to manage its behavior? Innovations : What makes this robot advanced and innovative? What sets it apart from other robots? Applications : What are some of the potential applications for this robot? How might it be used in industry or everyday life? Part 3: Creating a presentation Use PowerPoint to create a presentation to share your research with the class. Your presentation should include the following: Introduction : Introduce the robot and explain why you chose it. Purpose : Describe what the robot is designed to do. Design : Share images and descriptions of the robot's design and components. Sensors : Explain what sensors the robot uses and how they work. Actuators : Explain what actuators the robot uses and how they work. Controller : Describe the type of controller the robot uses and how it manages the robot's behavior. Innovations : Discuss what makes this robot advanced and innovative. Applications : Share some potential applications for the robot. Conclusion : Summarize the key points and why this robot is interesting or important. Part 4: Presenting to the class Present your research to the class, using your presentation. Be prepared to answer questions from your classmates about your robot. This activity will allow you to explore and learn about advanced and innovative robots, while also developing your research and presentation skills. Have fun!","title":"Robotresearch"},{"location":"contents/robotics/robotresearch.html#project-researching-an-advanced-and-innovative-robot","text":"In this activity, you will work in pairs to research a specific advanced and innovative robot. You will gather information about the robot and create a presentation to share with the class.","title":"Project: Researching an Advanced and Innovative Robot"},{"location":"contents/robotics/robotresearch.html#part-1-choosing-a-robot","text":"Start by discussing advanced and innovative robots with your partner. Choose a specific robot to research. Try to choose a robot that you find interesting or that relates to your personal interests.","title":"Part 1: Choosing a robot"},{"location":"contents/robotics/robotresearch.html#part-2-researching-the-robot","text":"Use reliable sources such as academic journals, reputable websites, and news articles to gather information about the robot you have chosen. Gather information on the following aspects of the robot: Purpose : What is the robot designed to do? Design : What does the robot look like? What components make up the robot? Sensors : What sensors does the robot use to interact with its environment? Actuators : What actuators does the robot use to move and interact with its environment? Controller : What type of controller does the robot use to manage its behavior? Innovations : What makes this robot advanced and innovative? What sets it apart from other robots? Applications : What are some of the potential applications for this robot? How might it be used in industry or everyday life?","title":"Part 2: Researching the robot"},{"location":"contents/robotics/robotresearch.html#part-3-creating-a-presentation","text":"Use PowerPoint to create a presentation to share your research with the class. Your presentation should include the following: Introduction : Introduce the robot and explain why you chose it. Purpose : Describe what the robot is designed to do. Design : Share images and descriptions of the robot's design and components. Sensors : Explain what sensors the robot uses and how they work. Actuators : Explain what actuators the robot uses and how they work. Controller : Describe the type of controller the robot uses and how it manages the robot's behavior. Innovations : Discuss what makes this robot advanced and innovative. Applications : Share some potential applications for the robot. Conclusion : Summarize the key points and why this robot is interesting or important.","title":"Part 3: Creating a presentation"},{"location":"contents/robotics/robotresearch.html#part-4-presenting-to-the-class","text":"Present your research to the class, using your presentation. Be prepared to answer questions from your classmates about your robot. This activity will allow you to explore and learn about advanced and innovative robots, while also developing your research and presentation skills. Have fun!","title":"Part 4: Presenting to the class"},{"location":"contents/robotics/robots.html","text":"Robots What is a robot? A robot is a machine that can be programmed to perform a variety of tasks. These tasks can range from simple actions like moving objects from one place to another, to more complex actions like assembling parts or performing surgery. Robots can be designed to operate autonomously or be controlled by a human operator. What sets robots apart from other machines is their ability to sense their environment and respond to it. They do this through the use of sensors such as cameras, microphones, and touch sensors. Based on the information they receive from these sensors, robots can make decisions about what actions to take. Robots come in many different shapes and sizes, and can be designed for a variety of purposes. For example, some robots are designed to work in factories, while others are used in healthcare settings to assist with surgeries or help patients with mobility issues. As you study robotics, you'll learn more about the different types of robots and how they are used in various industries. Overall, robots are an exciting and rapidly developing field in technology, and studying robotics can lead to many interesting career opportunities. Glossary English Spanish Example Sentence (English) Robots Robots \" Robots are used in manufacturing to automate repetitive tasks.\" Machine M\u00e1quina \"The robotic machine assembled the components with precision.\" Programmed Programado/a \"The robot was programmed to navigate through a maze.\" Tasks Tareas \"The robot was assigned multiple tasks in the industrial setting.\" Actions Acciones \"Robots can perform complex actions such as grasping and manipulating objects.\" Moving Mover \"The robot is capable of moving heavy objects from one location to another.\" Objects Objetos \"The robot detected and identified objects using its vision system.\" Place Lugar \"The robot placed the finished product on the conveyor belt.\" Assembling Ensamblaje \"The robot is responsible for assembling electronic components in the production line.\" Parts Partes \"The robotic arm picked up the small parts and assembled them together.\" Performing Realizar \"The surgical robot is capable of performing precise and delicate procedures.\" Surgery Cirug\u00eda \"Robotic surgery offers the advantages of minimally invasive procedures.\" Operate Operar \"The robot can operate autonomously or be controlled by a human operator.\" Autonomously Aut\u00f3nomamente \"The autonomous robot navigated through the obstacle course without human intervention.\" Controlled Controlado/a \"The robot was controlled remotely by a skilled operator.\" Human operator Operador humano \"The robot collaborated with the human operator to perform complex tasks.\" Environment Entorno \"Robots use sensors to perceive and interact with their environment .\" Sensors Sensores \"The robot's sensors detected the presence of obstacles in its path.\" Cameras C\u00e1maras \"The robot's camera captured high-resolution images for visual inspection.\" Microphones Micr\u00f3fonos \"The robot's microphones picked up sound signals for voice recognition.\" Touch sensors Sensores t\u00e1ctiles \"The robot's touch sensors enabled it to detect and respond to tactile stimuli.\" Decisions Decisiones \"Based on sensor data, the robot made intelligent decisions to navigate its surroundings.\" Shapes Formas \"The robot's gripper was designed to handle objects of various shapes and sizes.\" Sizes Tama\u00f1os \"The robot adjusted its grip strength based on the size of the object it handled.\" Purposes Prop\u00f3sitos \"Robots are used in various industries for different purposes , such as manufacturing and healthcare.\"","title":"Robots"},{"location":"contents/robotics/robots.html#robots","text":"","title":"Robots"},{"location":"contents/robotics/robots.html#what-is-a-robot","text":"A robot is a machine that can be programmed to perform a variety of tasks. These tasks can range from simple actions like moving objects from one place to another, to more complex actions like assembling parts or performing surgery. Robots can be designed to operate autonomously or be controlled by a human operator. What sets robots apart from other machines is their ability to sense their environment and respond to it. They do this through the use of sensors such as cameras, microphones, and touch sensors. Based on the information they receive from these sensors, robots can make decisions about what actions to take. Robots come in many different shapes and sizes, and can be designed for a variety of purposes. For example, some robots are designed to work in factories, while others are used in healthcare settings to assist with surgeries or help patients with mobility issues. As you study robotics, you'll learn more about the different types of robots and how they are used in various industries. Overall, robots are an exciting and rapidly developing field in technology, and studying robotics can lead to many interesting career opportunities.","title":"What is a robot?"},{"location":"contents/robotics/robots.html#glossary","text":"English Spanish Example Sentence (English) Robots Robots \" Robots are used in manufacturing to automate repetitive tasks.\" Machine M\u00e1quina \"The robotic machine assembled the components with precision.\" Programmed Programado/a \"The robot was programmed to navigate through a maze.\" Tasks Tareas \"The robot was assigned multiple tasks in the industrial setting.\" Actions Acciones \"Robots can perform complex actions such as grasping and manipulating objects.\" Moving Mover \"The robot is capable of moving heavy objects from one location to another.\" Objects Objetos \"The robot detected and identified objects using its vision system.\" Place Lugar \"The robot placed the finished product on the conveyor belt.\" Assembling Ensamblaje \"The robot is responsible for assembling electronic components in the production line.\" Parts Partes \"The robotic arm picked up the small parts and assembled them together.\" Performing Realizar \"The surgical robot is capable of performing precise and delicate procedures.\" Surgery Cirug\u00eda \"Robotic surgery offers the advantages of minimally invasive procedures.\" Operate Operar \"The robot can operate autonomously or be controlled by a human operator.\" Autonomously Aut\u00f3nomamente \"The autonomous robot navigated through the obstacle course without human intervention.\" Controlled Controlado/a \"The robot was controlled remotely by a skilled operator.\" Human operator Operador humano \"The robot collaborated with the human operator to perform complex tasks.\" Environment Entorno \"Robots use sensors to perceive and interact with their environment .\" Sensors Sensores \"The robot's sensors detected the presence of obstacles in its path.\" Cameras C\u00e1maras \"The robot's camera captured high-resolution images for visual inspection.\" Microphones Micr\u00f3fonos \"The robot's microphones picked up sound signals for voice recognition.\" Touch sensors Sensores t\u00e1ctiles \"The robot's touch sensors enabled it to detect and respond to tactile stimuli.\" Decisions Decisiones \"Based on sensor data, the robot made intelligent decisions to navigate its surroundings.\" Shapes Formas \"The robot's gripper was designed to handle objects of various shapes and sizes.\" Sizes Tama\u00f1os \"The robot adjusted its grip strength based on the size of the object it handled.\" Purposes Prop\u00f3sitos \"Robots are used in various industries for different purposes , such as manufacturing and healthcare.\"","title":"Glossary"},{"location":"contents/robotics/robots_ai.html","text":"Robots and AI Robots and Artificial Intelligence Robots and artificial intelligence (AI) are closely related, but they are not the same thing. A robot is a machine that can be programmed to perform a variety of tasks, while AI refers to the ability of machines to perform tasks that would normally require human intelligence, such as learning, problem solving, and decision making. In many cases, robots use AI to make decisions about what actions to take. For example, a robot in a manufacturing plant might use AI to decide which parts to pick up and assemble based on the shape and size of the parts. Similarly, a robot in a healthcare setting might use AI to analyze medical images and make recommendations to doctors. However, not all robots use AI. Some robots are programmed to perform a specific set of tasks without any decision making capabilities. For example, a robot used to move heavy objects in a warehouse might simply follow a predetermined path and pick up objects along the way. On the other hand, not all AI is used in robots. AI can be used in many different applications, such as virtual assistants, self-driving cars, and fraud detection systems. These applications do not necessarily involve physical robots. Overall, the relationship between robots and AI is complex and evolving. As you study robotics and AI, you'll learn more about how these technologies are used together and separately to solve real-world problems. Glossary English Spanish Example Sentence (English) Robots Robots \" Robots are used in manufacturing to automate repetitive tasks.\" Artificial Intelligence Inteligencia Artificial \" Artificial Intelligence enables machines to learn, reason, and make decisions.\" Closely related Estrechamente relacionados/as \" Robots and artificial intelligence are closely related in the field of robotics.\" Not the same thing No es lo mismo \" Robots and AI are not the same thing , although they have connections.\" Machine M\u00e1quina \"The robotic machine performed complex tasks with precision.\" Programmed Programado/a \"The robot was programmed to follow a specific set of instructions.\" Variety of tasks Variedad de tareas \"Robots can be programmed to perform a variety of tasks in different industries.\" Learning Aprendizaje \"Artificial Intelligence involves learning from data to improve performance.\" Problem solving Resoluci\u00f3n de problemas \"AI algorithms are capable of problem solving in various domains.\" Decision making Toma de decisiones \"Robots equipped with AI can make intelligent decision making based on sensor data.\" Manufacturing plant Planta de manufactura \"The manufacturing plant used robots to automate the assembly line.\" Parts Partes \"The robot identified and sorted the different parts in the production process.\" Shape and size Forma y tama\u00f1o \"The robot used AI to determine the appropriate shape and size of the objects to handle.\" Healthcare setting Entorno sanitario \"Robots with AI are being used in healthcare settings to assist doctors and nurses.\" Analyze Analizar \"The robot analyzed the medical images to detect anomalies and abnormalities.\" Recommendations Recomendaciones \"Based on AI analysis, the robot provided accurate recommendations for treatment options.\" Decision making capabilities Capacidad de toma de decisiones \"This robot has advanced decision making capabilities based on its AI algorithms.\" Warehouse Almac\u00e9n \"The robot efficiently navigated the warehouse to retrieve and store items.\" Predetermined path Ruta predeterminada \"The robot followed a predetermined path to perform its tasks in the factory.\" Virtual assistants Asistentes virtuales \"Virtual assistants use AI to interact with users and provide helpful information.\" Self-driving cars Coches aut\u00f3nomos \"AI technology is driving the development of self-driving cars .\" Fraud detection systems Sistemas de detecci\u00f3n de fraude \"AI algorithms are employed in fraud detection systems to identify suspicious activities.\" Physical robots Robots f\u00edsicos \"Not all applications of AI involve physical robots ; some are purely software-based.\" Complex Complejo/a \"The relationship between robots and AI is complex and constantly evolving.\"","title":"Robots and Artificial Intelligence"},{"location":"contents/robotics/robots_ai.html#robots-and-ai","text":"","title":"Robots and AI"},{"location":"contents/robotics/robots_ai.html#robots-and-artificial-intelligence","text":"Robots and artificial intelligence (AI) are closely related, but they are not the same thing. A robot is a machine that can be programmed to perform a variety of tasks, while AI refers to the ability of machines to perform tasks that would normally require human intelligence, such as learning, problem solving, and decision making. In many cases, robots use AI to make decisions about what actions to take. For example, a robot in a manufacturing plant might use AI to decide which parts to pick up and assemble based on the shape and size of the parts. Similarly, a robot in a healthcare setting might use AI to analyze medical images and make recommendations to doctors. However, not all robots use AI. Some robots are programmed to perform a specific set of tasks without any decision making capabilities. For example, a robot used to move heavy objects in a warehouse might simply follow a predetermined path and pick up objects along the way. On the other hand, not all AI is used in robots. AI can be used in many different applications, such as virtual assistants, self-driving cars, and fraud detection systems. These applications do not necessarily involve physical robots. Overall, the relationship between robots and AI is complex and evolving. As you study robotics and AI, you'll learn more about how these technologies are used together and separately to solve real-world problems.","title":"Robots and Artificial Intelligence"},{"location":"contents/robotics/robots_ai.html#glossary","text":"English Spanish Example Sentence (English) Robots Robots \" Robots are used in manufacturing to automate repetitive tasks.\" Artificial Intelligence Inteligencia Artificial \" Artificial Intelligence enables machines to learn, reason, and make decisions.\" Closely related Estrechamente relacionados/as \" Robots and artificial intelligence are closely related in the field of robotics.\" Not the same thing No es lo mismo \" Robots and AI are not the same thing , although they have connections.\" Machine M\u00e1quina \"The robotic machine performed complex tasks with precision.\" Programmed Programado/a \"The robot was programmed to follow a specific set of instructions.\" Variety of tasks Variedad de tareas \"Robots can be programmed to perform a variety of tasks in different industries.\" Learning Aprendizaje \"Artificial Intelligence involves learning from data to improve performance.\" Problem solving Resoluci\u00f3n de problemas \"AI algorithms are capable of problem solving in various domains.\" Decision making Toma de decisiones \"Robots equipped with AI can make intelligent decision making based on sensor data.\" Manufacturing plant Planta de manufactura \"The manufacturing plant used robots to automate the assembly line.\" Parts Partes \"The robot identified and sorted the different parts in the production process.\" Shape and size Forma y tama\u00f1o \"The robot used AI to determine the appropriate shape and size of the objects to handle.\" Healthcare setting Entorno sanitario \"Robots with AI are being used in healthcare settings to assist doctors and nurses.\" Analyze Analizar \"The robot analyzed the medical images to detect anomalies and abnormalities.\" Recommendations Recomendaciones \"Based on AI analysis, the robot provided accurate recommendations for treatment options.\" Decision making capabilities Capacidad de toma de decisiones \"This robot has advanced decision making capabilities based on its AI algorithms.\" Warehouse Almac\u00e9n \"The robot efficiently navigated the warehouse to retrieve and store items.\" Predetermined path Ruta predeterminada \"The robot followed a predetermined path to perform its tasks in the factory.\" Virtual assistants Asistentes virtuales \"Virtual assistants use AI to interact with users and provide helpful information.\" Self-driving cars Coches aut\u00f3nomos \"AI technology is driving the development of self-driving cars .\" Fraud detection systems Sistemas de detecci\u00f3n de fraude \"AI algorithms are employed in fraud detection systems to identify suspicious activities.\" Physical robots Robots f\u00edsicos \"Not all applications of AI involve physical robots ; some are purely software-based.\" Complex Complejo/a \"The relationship between robots and AI is complex and constantly evolving.\"","title":"Glossary"},{"location":"contents/robotics/sensors.html","text":"Sensors Definition of sensor Sensors are devices that can detect and measure physical and environmental conditions such as temperature, light, sound, and movement. In this lesson, we will learn about the different types of sensors used in AI applications and the different ways in which they can be used. Types of sensors Optical sensors : These sensors detect light and are used in applications such as facial recognition, object detection, and image processing. Examples of optical sensors include cameras and lidar sensors. Temperature sensors : These sensors measure temperature and are used in applications such as climate control and food safety. Examples of temperature sensors include thermocouples and thermistors. Pressure sensors : These sensors measure pressure and are used in applications such as industrial automation, weather forecasting, and healthcare. Examples of pressure sensors include piezoelectric sensors and strain gauge sensors. Accelerometer sensors : These sensors measure acceleration and are used in applications such as motion detection, navigation, and gaming. Examples of accelerometer sensors include MEMS accelerometers and piezoelectric accelerometers. Gyroscopic sensors : These sensors measure angular velocity and are used in applications such as navigation, gaming, and robotics. Examples of gyroscopic sensors include MEMS gyroscopes and fiber optic gyroscopes. Magnetic sensors : These sensors measure magnetic fields and are used in applications such as navigation, industrial automation, and healthcare. Examples of magnetic sensors include Hall effect sensors and magnetoresistive sensors. Ultrasonic sensors : These sensors measure distance and are used in applications such as object detection, navigation, and industrial automation. Examples of ultrasonic sensors include sonar sensors and lidar sensors. Infrared sensors : These sensors detect infrared radiation and are used in applications such as temperature measurement, night vision, and gesture recognition. Examples of infrared sensors include thermopile sensors and pyroelectric sensors. Proximity sensors : These sensors detect the presence of objects and are used in applications such as gesture recognition, object detection, and access control. Examples of proximity sensors include infrared proximity sensors and ultrasonic proximity sensors. Light sensors : These sensors detect light and are used in applications such as light control, gesture recognition, and object detection. Examples of light sensors include photodiodes and phototransistors. Humidity sensors : These sensors measure humidity and are used in applications such as weather forecasting, agriculture, and healthcare. Examples of humidity sensors include capacitive humidity sensors and resistive humidity sensors. Gas sensors : These sensors detect the presence of gases and are used in applications such as environmental monitoring, industrial automation, and healthcare. Examples of gas sensors include electrochemical gas sensors and metal oxide gas sensors. Quiz 1. What do sensors detect and measure? a) Physical and environmental conditions b) Human emotions c) Food flavors d) Political opinions 2. Which type of sensor is used in facial recognition and image processing? a) Temperature sensors b) Pressure sensors c) Optical sensors d) Magnetic sensors 3. Which type of sensor measures acceleration? a) Temperature sensors b) Gyroscopic sensors c) Humidity sensors d) Gas sensors 4. What do proximity sensors detect? a) The presence of objects b) The color of objects c) The weight of objects d) The shape of objects 5. What type of sensors measure angular velocity and can be used in navigation and robotics? a) Gyroscopic sensors b) Temperature sensors c) Infrared sensors d) Gas sensors Glossary English Spanish Example Sentence (English) Accelerometer sensors Sensores de aceleraci\u00f3n \"The accelerometer sensors detected sudden movements and adjusted the robot's trajectory.\" Color sensors Sensores de color \"The robot's color sensors enabled it to distinguish between different objects based on hue.\" Force sensors Sensores de fuerza \"The robot used force sensors to measure the applied force during object manipulation.\" Gas sensors Sensores de gas \"The robot's safety was enhanced by gas sensors that detected hazardous fumes.\" Gyroscopic sensors Sensores girosc\u00f3picos \"The robot's precise movements were achieved with the help of gyroscopic sensors .\" Humidity sensors Sensores de humedad \"The humidity sensors ensured optimal conditions for plant growth in automated farming.\" Infrared sensors Sensores infrarrojos \"The infrared sensors detected human body heat for gesture recognition.\" Light sensors Sensores de luz \"The robot adjusted its behavior based on the readings from the light sensors .\" Magnetic sensors Sensores magn\u00e9ticos \"The robot relied on magnetic sensors to navigate and avoid obstacles in its path.\" Motion sensors Sensores de movimiento \"The robot's behavior was influenced by the readings from the motion sensors in its environment.\" Pressure sensors Sensores de presi\u00f3n \"The robot used pressure sensors to monitor the gripping force during assembly tasks.\" Proximity sensors Sensores de proximidad \"The robot's precise movements were achieved with the help of proximity sensors .\" Sound sensors Sensores de sonido \"The robot utilized sound sensors to identify specific audio patterns in its environment.\" Temperature sensors Sensores de temperatura \"The robot's temperature sensors ensured optimal conditions for storing perishable goods.\" Touch sensors Sensores t\u00e1ctiles \"The robot's touch sensors allowed it to detect and respond to human touch.\" Ultrasonic sensors Sensores ultras\u00f3nicos \"The robot used ultrasonic sensors to detect the presence of objects in its vicinity.\" Vibration sensors Sensores de vibraci\u00f3n \"The robot's navigation system incorporated vibration sensors for terrain analysis.\" GPS sensors Sensores GPS \"The robot relied on GPS sensors to navigate outdoor environments with precise location tracking.\" Humidity sensors Sensores de humedad \"The humidity sensors ensured optimal conditions for weather forecasting and agriculture.\" Infrared sensors Sensores infrarrojos \"The infrared sensors detected human body heat for gesture recognition.\" Light sensors Sensores de luz \"The robot adjusted its behavior based on the readings from the **light","title":"Robots Sensors"},{"location":"contents/robotics/sensors.html#sensors","text":"","title":"Sensors"},{"location":"contents/robotics/sensors.html#definition-of-sensor","text":"Sensors are devices that can detect and measure physical and environmental conditions such as temperature, light, sound, and movement. In this lesson, we will learn about the different types of sensors used in AI applications and the different ways in which they can be used.","title":"Definition of sensor"},{"location":"contents/robotics/sensors.html#types-of-sensors","text":"Optical sensors : These sensors detect light and are used in applications such as facial recognition, object detection, and image processing. Examples of optical sensors include cameras and lidar sensors. Temperature sensors : These sensors measure temperature and are used in applications such as climate control and food safety. Examples of temperature sensors include thermocouples and thermistors. Pressure sensors : These sensors measure pressure and are used in applications such as industrial automation, weather forecasting, and healthcare. Examples of pressure sensors include piezoelectric sensors and strain gauge sensors. Accelerometer sensors : These sensors measure acceleration and are used in applications such as motion detection, navigation, and gaming. Examples of accelerometer sensors include MEMS accelerometers and piezoelectric accelerometers. Gyroscopic sensors : These sensors measure angular velocity and are used in applications such as navigation, gaming, and robotics. Examples of gyroscopic sensors include MEMS gyroscopes and fiber optic gyroscopes. Magnetic sensors : These sensors measure magnetic fields and are used in applications such as navigation, industrial automation, and healthcare. Examples of magnetic sensors include Hall effect sensors and magnetoresistive sensors. Ultrasonic sensors : These sensors measure distance and are used in applications such as object detection, navigation, and industrial automation. Examples of ultrasonic sensors include sonar sensors and lidar sensors. Infrared sensors : These sensors detect infrared radiation and are used in applications such as temperature measurement, night vision, and gesture recognition. Examples of infrared sensors include thermopile sensors and pyroelectric sensors. Proximity sensors : These sensors detect the presence of objects and are used in applications such as gesture recognition, object detection, and access control. Examples of proximity sensors include infrared proximity sensors and ultrasonic proximity sensors. Light sensors : These sensors detect light and are used in applications such as light control, gesture recognition, and object detection. Examples of light sensors include photodiodes and phototransistors. Humidity sensors : These sensors measure humidity and are used in applications such as weather forecasting, agriculture, and healthcare. Examples of humidity sensors include capacitive humidity sensors and resistive humidity sensors. Gas sensors : These sensors detect the presence of gases and are used in applications such as environmental monitoring, industrial automation, and healthcare. Examples of gas sensors include electrochemical gas sensors and metal oxide gas sensors.","title":"Types of sensors"},{"location":"contents/robotics/sensors.html#quiz","text":"1. What do sensors detect and measure? a) Physical and environmental conditions b) Human emotions c) Food flavors d) Political opinions 2. Which type of sensor is used in facial recognition and image processing? a) Temperature sensors b) Pressure sensors c) Optical sensors d) Magnetic sensors 3. Which type of sensor measures acceleration? a) Temperature sensors b) Gyroscopic sensors c) Humidity sensors d) Gas sensors 4. What do proximity sensors detect? a) The presence of objects b) The color of objects c) The weight of objects d) The shape of objects 5. What type of sensors measure angular velocity and can be used in navigation and robotics? a) Gyroscopic sensors b) Temperature sensors c) Infrared sensors d) Gas sensors","title":"Quiz"},{"location":"contents/robotics/sensors.html#glossary","text":"English Spanish Example Sentence (English) Accelerometer sensors Sensores de aceleraci\u00f3n \"The accelerometer sensors detected sudden movements and adjusted the robot's trajectory.\" Color sensors Sensores de color \"The robot's color sensors enabled it to distinguish between different objects based on hue.\" Force sensors Sensores de fuerza \"The robot used force sensors to measure the applied force during object manipulation.\" Gas sensors Sensores de gas \"The robot's safety was enhanced by gas sensors that detected hazardous fumes.\" Gyroscopic sensors Sensores girosc\u00f3picos \"The robot's precise movements were achieved with the help of gyroscopic sensors .\" Humidity sensors Sensores de humedad \"The humidity sensors ensured optimal conditions for plant growth in automated farming.\" Infrared sensors Sensores infrarrojos \"The infrared sensors detected human body heat for gesture recognition.\" Light sensors Sensores de luz \"The robot adjusted its behavior based on the readings from the light sensors .\" Magnetic sensors Sensores magn\u00e9ticos \"The robot relied on magnetic sensors to navigate and avoid obstacles in its path.\" Motion sensors Sensores de movimiento \"The robot's behavior was influenced by the readings from the motion sensors in its environment.\" Pressure sensors Sensores de presi\u00f3n \"The robot used pressure sensors to monitor the gripping force during assembly tasks.\" Proximity sensors Sensores de proximidad \"The robot's precise movements were achieved with the help of proximity sensors .\" Sound sensors Sensores de sonido \"The robot utilized sound sensors to identify specific audio patterns in its environment.\" Temperature sensors Sensores de temperatura \"The robot's temperature sensors ensured optimal conditions for storing perishable goods.\" Touch sensors Sensores t\u00e1ctiles \"The robot's touch sensors allowed it to detect and respond to human touch.\" Ultrasonic sensors Sensores ultras\u00f3nicos \"The robot used ultrasonic sensors to detect the presence of objects in its vicinity.\" Vibration sensors Sensores de vibraci\u00f3n \"The robot's navigation system incorporated vibration sensors for terrain analysis.\" GPS sensors Sensores GPS \"The robot relied on GPS sensors to navigate outdoor environments with precise location tracking.\" Humidity sensors Sensores de humedad \"The humidity sensors ensured optimal conditions for weather forecasting and agriculture.\" Infrared sensors Sensores infrarrojos \"The infrared sensors detected human body heat for gesture recognition.\" Light sensors Sensores de luz \"The robot adjusted its behavior based on the readings from the **light","title":"Glossary"},{"location":"contents/unit01/activity-1-1.html","text":"Activity 1.1. Learning in biological systems","title":"Activity 1.1. Learning in biological systems"},{"location":"contents/unit01/activity-1-1.html#activity-11-learning-in-biological-systems","text":"","title":"Activity 1.1. Learning in biological systems"},{"location":"contents/unit01/activity-turing.html","text":"The Turing test: Can a computer pass for a human? - Alex Gendler What is consciousness? Can an (1) really think? Does the mind just consist of _ ___ (2) in the brain, or is there some intangible spark at its core? For many, these have been vital considerations for the future of artificial intelligence. But British computer scientist Alan Turing decided to disregard all these questions in favor of a much simpler one: can a computer talk like a human? This question led to an idea for measuring artificial intelligence that would famously come to be known as the _ ______ (3). In the 1950 paper, \"Computing Machinery and Intelligence,\" Turing proposed the following game. A human _ _ ___ (4) has a text conversation with unseen players and evaluates their responses. To pass the test, a computer must be able to replace one of the players without substantially changing the results. In other words, a computer would be considered intelligent if its conversation couldn't be easily distinguished from a human's. Turing predicted that by the year 2000, machines with 100 megabytes of memory would be able to easily pass his test. But he may have jumped the gun. Even though today's computers have far more _ _ (5) than that, few have succeeded, and those that have done well focused more on finding clever ways to fool judges than using overwhelming _ _ ______ (6). Though it was never subjected to a real test, the first program with some claim to success was called ELIZA. With only a fairly short and simple script, it managed to mislead many people by _ _ (7) a psychologist, encouraging them to talk more and reflecting their own questions back at them. Another early script PARRY took the opposite approach by _ _ __ (8) a paranoid schizophrenic who kept steering the conversation back to his own preprogrammed obsessions. Their success in fooling people highlighted one _ _ _____ (9) of the test. Humans regularly attribute intelligence to a whole range of things that are not actually intelligent. Nonetheless, annual competitions like the Loebner Prize, have made the test more formal with judges knowing ahead of time that some of their conversation partners are machines. But while the quality has improved, many _ _ ____ (10) programmers have used similar strategies to ELIZA and PARRY. 1997's winner Catherine could carry on amazingly focused and intelligent conversation, but mostly if the judge wanted to talk about Bill Clinton. And the more recent winner Eugene Goostman was given the persona of a 13-year-old Ukrainian boy, so judges interpreted its nonsequiturs and awkward grammar as language and culture barriers. Meanwhile, other programs like Cleverbot have taken a different approach by _ _ (11) analyzing huge _ _ (12) of real conversations to determine the best responses. Some also store memories of previous conversations in order to improve over time. But while Cleverbot's individual responses can sound incredibly human, its lack of a consistent _ _ ____ (13) and inability to deal with brand new topics are a dead giveaway. Who in Turing's day could have _ _ _ (14) that today's computers would be able to pilot spacecraft, perform delicate surgeries, and solve massive equations, but still struggle with the most basic small talk? Human _ ______ (15) turns out to be an amazingly complex phenomenon that can't be captured by even the largest dictionary. Chatbots can be baffled by simple pauses, like \"umm...\" or questions with no correct answer. And a simple _ _ (16) sentence, like, \"I took the juice out of the fridge and gave it to him, but forgot to check the date,\" requires a wealth of underlying _ _ _ (17) and intuition to parse. It turns out that _ _ (18) a human conversation takes more than just increasing memory and _ _ (19) power, and as we get closer to Turing's goal, we may have to deal with all those big questions about _ ____ (20) after all.","title":"Activity turing"},{"location":"contents/unit01/activity-turing.html#the-turing-test-can-a-computer-pass-for-a-human-alex-gendler","text":"","title":"The Turing test: Can a computer pass for a human? - Alex Gendler"},{"location":"contents/unit01/activity-turing.html#_1","text":"What is consciousness? Can an (1) really think? Does the mind just consist of _ ___ (2) in the brain, or is there some intangible spark at its core? For many, these have been vital considerations for the future of artificial intelligence. But British computer scientist Alan Turing decided to disregard all these questions in favor of a much simpler one: can a computer talk like a human? This question led to an idea for measuring artificial intelligence that would famously come to be known as the _ ______ (3). In the 1950 paper, \"Computing Machinery and Intelligence,\" Turing proposed the following game. A human _ _ ___ (4) has a text conversation with unseen players and evaluates their responses. To pass the test, a computer must be able to replace one of the players without substantially changing the results. In other words, a computer would be considered intelligent if its conversation couldn't be easily distinguished from a human's. Turing predicted that by the year 2000, machines with 100 megabytes of memory would be able to easily pass his test. But he may have jumped the gun. Even though today's computers have far more _ _ (5) than that, few have succeeded, and those that have done well focused more on finding clever ways to fool judges than using overwhelming _ _ ______ (6). Though it was never subjected to a real test, the first program with some claim to success was called ELIZA. With only a fairly short and simple script, it managed to mislead many people by _ _ (7) a psychologist, encouraging them to talk more and reflecting their own questions back at them. Another early script PARRY took the opposite approach by _ _ __ (8) a paranoid schizophrenic who kept steering the conversation back to his own preprogrammed obsessions. Their success in fooling people highlighted one _ _ _____ (9) of the test. Humans regularly attribute intelligence to a whole range of things that are not actually intelligent. Nonetheless, annual competitions like the Loebner Prize, have made the test more formal with judges knowing ahead of time that some of their conversation partners are machines. But while the quality has improved, many _ _ ____ (10) programmers have used similar strategies to ELIZA and PARRY. 1997's winner Catherine could carry on amazingly focused and intelligent conversation, but mostly if the judge wanted to talk about Bill Clinton. And the more recent winner Eugene Goostman was given the persona of a 13-year-old Ukrainian boy, so judges interpreted its nonsequiturs and awkward grammar as language and culture barriers. Meanwhile, other programs like Cleverbot have taken a different approach by _ _ (11) analyzing huge _ _ (12) of real conversations to determine the best responses. Some also store memories of previous conversations in order to improve over time. But while Cleverbot's individual responses can sound incredibly human, its lack of a consistent _ _ ____ (13) and inability to deal with brand new topics are a dead giveaway. Who in Turing's day could have _ _ _ (14) that today's computers would be able to pilot spacecraft, perform delicate surgeries, and solve massive equations, but still struggle with the most basic small talk? Human _ ______ (15) turns out to be an amazingly complex phenomenon that can't be captured by even the largest dictionary. Chatbots can be baffled by simple pauses, like \"umm...\" or questions with no correct answer. And a simple _ _ (16) sentence, like, \"I took the juice out of the fridge and gave it to him, but forgot to check the date,\" requires a wealth of underlying _ _ _ (17) and intuition to parse. It turns out that _ _ (18) a human conversation takes more than just increasing memory and _ _ (19) power, and as we get closer to Turing's goal, we may have to deal with all those big questions about _ ____ (20) after all.","title":""},{"location":"contents/unit01/ai-bio.html","text":"Learning in Biological Systems: Decisions and Free Will When we think about learning , we often think about school, books, and teachers. But learning happens in many ways, especially in biological systems , like our brains and the brains of animals. Let's explore how this works and how it relates to making decisions and free will , and how it connects to artificial intelligence (AI) , programming, and robotics. What is Learning in Biological Systems? Learning in biological systems means how living things (like humans and animals) change their behavior based on experiences. For example, when a dog learns to sit because it gets a treat, that's learning. Our brains learn by forming connections between neurons , which are tiny cells that send messages. These connections help us remember things and improve our skills. How Do We Learn? There are different ways we learn: Classical Conditioning: This is when we learn to link two things together. For example, if you hear a bell every time you get a snack, soon you'll start to feel hungry just by hearing the bell. This is how Pavlov's dogs learned to salivate at the sound of a bell. Operant Conditioning: This is when we learn from the consequences of our actions. If you do something good and get a reward, you'll want to do it again. If you do something bad and get punished, you'll avoid doing it again. This is how many animals and humans learn to behave. Observational Learning: This is when we learn by watching others. If you see your friend solving a puzzle, you might learn how to solve it too just by observing. This type of learning is very important for social animals like humans. Decisions and Free Will When we learn, we also make decisions. A decision is choosing between different options. For example, deciding what to eat for lunch or what game to play. Our decisions are influenced by our past experiences and what we've learned. Free Will is the idea that we can choose our actions independently. But, are our decisions truly free? Let's explore this idea: Influences on Decisions: Our decisions are often influenced by things we can't control. For example, our environment, our upbringing, and our experiences all shape our choices. If you've always had pizza on Fridays, you might choose pizza without really thinking about it. Brain and Choices: Our brain makes decisions by weighing different options and predicting outcomes. Sometimes, our brain makes choices automatically based on what we've learned. Other times, we think carefully before deciding. This process involves different parts of the brain working together. True Freedom?: Some scientists believe that our decisions are not completely free because they are based on previous experiences and biological processes. Others believe that we still have the power to make choices, even if they are influenced by other factors.","title":"Learning in Biological Systems: Decisions and Free Will"},{"location":"contents/unit01/ai-bio.html#learning-in-biological-systems-decisions-and-free-will","text":"When we think about learning , we often think about school, books, and teachers. But learning happens in many ways, especially in biological systems , like our brains and the brains of animals. Let's explore how this works and how it relates to making decisions and free will , and how it connects to artificial intelligence (AI) , programming, and robotics.","title":"Learning in Biological Systems: Decisions and Free Will"},{"location":"contents/unit01/ai-bio.html#what-is-learning-in-biological-systems","text":"Learning in biological systems means how living things (like humans and animals) change their behavior based on experiences. For example, when a dog learns to sit because it gets a treat, that's learning. Our brains learn by forming connections between neurons , which are tiny cells that send messages. These connections help us remember things and improve our skills.","title":"What is Learning in Biological Systems?"},{"location":"contents/unit01/ai-bio.html#how-do-we-learn","text":"There are different ways we learn: Classical Conditioning: This is when we learn to link two things together. For example, if you hear a bell every time you get a snack, soon you'll start to feel hungry just by hearing the bell. This is how Pavlov's dogs learned to salivate at the sound of a bell. Operant Conditioning: This is when we learn from the consequences of our actions. If you do something good and get a reward, you'll want to do it again. If you do something bad and get punished, you'll avoid doing it again. This is how many animals and humans learn to behave. Observational Learning: This is when we learn by watching others. If you see your friend solving a puzzle, you might learn how to solve it too just by observing. This type of learning is very important for social animals like humans.","title":"How Do We Learn?"},{"location":"contents/unit01/ai-bio.html#decisions-and-free-will","text":"When we learn, we also make decisions. A decision is choosing between different options. For example, deciding what to eat for lunch or what game to play. Our decisions are influenced by our past experiences and what we've learned. Free Will is the idea that we can choose our actions independently. But, are our decisions truly free? Let's explore this idea: Influences on Decisions: Our decisions are often influenced by things we can't control. For example, our environment, our upbringing, and our experiences all shape our choices. If you've always had pizza on Fridays, you might choose pizza without really thinking about it. Brain and Choices: Our brain makes decisions by weighing different options and predicting outcomes. Sometimes, our brain makes choices automatically based on what we've learned. Other times, we think carefully before deciding. This process involves different parts of the brain working together. True Freedom?: Some scientists believe that our decisions are not completely free because they are based on previous experiences and biological processes. Others believe that we still have the power to make choices, even if they are influenced by other factors.","title":"Decisions and Free Will"},{"location":"contents/unit01/ai-fundamentals.html","text":"Fundamentals of AI: Decision Trees, Big Data, and Neural Networks Artificial Intelligence (AI) is a fascinating field that combines computer science, data, and learning to create smart machines. In this section, we will explore three important concepts in AI: Decision Trees, Big Data, and Neural Networks. Understanding these concepts will help you grasp how AI works and why it is so powerful. Decision Trees A Decision Tree is a tool used in AI to make decisions based on data. It looks like a tree with branches. Each branch represents a choice, and each leaf represents an outcome. How Decision Trees Work: Imagine you are trying to decide what game to play. You start at the root of the tree with a question, like \"Is it raining?\" If the answer is yes, you follow one branch; if the answer is no, you follow another branch. Each branch leads to more questions until you reach a leaf, which tells you what game to play. This process of asking questions and making choices is how a decision tree helps computers make decisions. Examples in Real Life: Decision trees are used in many areas. For example, doctors use them to diagnose diseases by asking questions about symptoms. Online stores use them to recommend products by analyzing your past purchases. Big Data Big Data refers to extremely large sets of data that can be analyzed to find patterns, trends, and associations. Why Big Data is Important: In the past, collecting and analyzing data was slow and difficult. Now, with the help of computers, we can gather huge amounts of data from the internet, sensors, and other sources. This data helps AI systems learn and improve. How Big Data Works: Imagine you have a massive library of books. Instead of reading each book one by one, you use a computer to quickly scan and analyze all the books to find useful information. This is what big data does. It allows AI to process vast amounts of information quickly and accurately. Examples in Real Life: Big data is used in many fields, like healthcare, where it helps doctors find better treatments by analyzing patient records. In social media, it helps companies understand user behavior and improve their services. Neural Networks Neural Networks are a key technology in AI that mimic the way the human brain works. How Neural Networks Work: A neural network is made up of layers of nodes, similar to neurons in the brain. Each node processes information and passes it to the next layer. The network learns by adjusting the connections between nodes based on the data it receives. Training Neural Networks: Training a neural network involves feeding it large amounts of data and adjusting the connections to improve its performance. For example, to train a network to recognize pictures of cats, you show it thousands of cat pictures. The network learns the patterns and features that define a cat. Examples in Real Life: Neural networks are used in many applications. They power voice assistants like Siri and Alexa, recognize faces in photos, and even help self-driving cars navigate. Conclusion Understanding Decision Trees, Big Data, and Neural Networks is essential to grasp the basics of AI. Decision Trees help AI make choices based on data. Big Data provides the vast amount of information needed to train AI systems. Neural Networks mimic the brain's learning process to recognize patterns and make decisions. Together, these technologies enable AI to solve complex problems and improve our lives in many ways. By learning about these concepts, you are taking the first step into the exciting world of AI, programming, and robotics.","title":"Fundamentals of AI"},{"location":"contents/unit01/ai-fundamentals.html#fundamentals-of-ai-decision-trees-big-data-and-neural-networks","text":"Artificial Intelligence (AI) is a fascinating field that combines computer science, data, and learning to create smart machines. In this section, we will explore three important concepts in AI: Decision Trees, Big Data, and Neural Networks. Understanding these concepts will help you grasp how AI works and why it is so powerful.","title":"Fundamentals of AI: Decision Trees, Big Data, and Neural Networks"},{"location":"contents/unit01/ai-fundamentals.html#decision-trees","text":"A Decision Tree is a tool used in AI to make decisions based on data. It looks like a tree with branches. Each branch represents a choice, and each leaf represents an outcome. How Decision Trees Work: Imagine you are trying to decide what game to play. You start at the root of the tree with a question, like \"Is it raining?\" If the answer is yes, you follow one branch; if the answer is no, you follow another branch. Each branch leads to more questions until you reach a leaf, which tells you what game to play. This process of asking questions and making choices is how a decision tree helps computers make decisions. Examples in Real Life: Decision trees are used in many areas. For example, doctors use them to diagnose diseases by asking questions about symptoms. Online stores use them to recommend products by analyzing your past purchases.","title":"Decision Trees"},{"location":"contents/unit01/ai-fundamentals.html#big-data","text":"Big Data refers to extremely large sets of data that can be analyzed to find patterns, trends, and associations. Why Big Data is Important: In the past, collecting and analyzing data was slow and difficult. Now, with the help of computers, we can gather huge amounts of data from the internet, sensors, and other sources. This data helps AI systems learn and improve. How Big Data Works: Imagine you have a massive library of books. Instead of reading each book one by one, you use a computer to quickly scan and analyze all the books to find useful information. This is what big data does. It allows AI to process vast amounts of information quickly and accurately. Examples in Real Life: Big data is used in many fields, like healthcare, where it helps doctors find better treatments by analyzing patient records. In social media, it helps companies understand user behavior and improve their services.","title":"Big Data"},{"location":"contents/unit01/ai-fundamentals.html#neural-networks","text":"Neural Networks are a key technology in AI that mimic the way the human brain works. How Neural Networks Work: A neural network is made up of layers of nodes, similar to neurons in the brain. Each node processes information and passes it to the next layer. The network learns by adjusting the connections between nodes based on the data it receives. Training Neural Networks: Training a neural network involves feeding it large amounts of data and adjusting the connections to improve its performance. For example, to train a network to recognize pictures of cats, you show it thousands of cat pictures. The network learns the patterns and features that define a cat. Examples in Real Life: Neural networks are used in many applications. They power voice assistants like Siri and Alexa, recognize faces in photos, and even help self-driving cars navigate.","title":"Neural Networks"},{"location":"contents/unit01/ai-fundamentals.html#conclusion","text":"Understanding Decision Trees, Big Data, and Neural Networks is essential to grasp the basics of AI. Decision Trees help AI make choices based on data. Big Data provides the vast amount of information needed to train AI systems. Neural Networks mimic the brain's learning process to recognize patterns and make decisions. Together, these technologies enable AI to solve complex problems and improve our lives in many ways. By learning about these concepts, you are taking the first step into the exciting world of AI, programming, and robotics.","title":"Conclusion"},{"location":"contents/unit01/big-data.html","text":"Big Data Big Data refers to extremely large sets of data that can be analyzed to find patterns, trends, and associations. This is important for AI because AI systems learn and make decisions based on data. Why Big Data is Important In the past, collecting and analyzing data was slow and difficult. People had to go through information manually, which took a lot of time. Now, with the help of computers, we can gather huge amounts of data from the internet, sensors, and other sources. This data helps AI systems learn and improve. Speed and Efficiency: Computers can process large amounts of data very quickly. This means that AI systems can learn faster and make more accurate decisions. For example, an AI system can analyze millions of pictures to learn how to recognize objects in just a few hours, something that would take humans years to do. Better Learning: The more data an AI system has, the better it can learn. Big data provides AI with a wealth of information, which helps it make more accurate predictions and decisions. For instance, an AI system that analyzes weather data from all over the world can make better weather forecasts. How Big Data Works Imagine you have a massive library of books. Instead of reading each book one by one, you use a computer to quickly scan and analyze all the books to find useful information. This is what big data does. It allows AI to process vast amounts of information quickly and accurately. Data Collection: Data can come from many sources like websites, social media, sensors, and cameras. For example, a fitness app collects data from users' phones and smartwatches to track their exercise habits. Data Storage: Once collected, the data needs to be stored. This is done using big data technologies that can handle large volumes of information. Companies use big servers and cloud storage to keep all this data safe and accessible. Data Analysis: After storing the data, it needs to be analyzed. AI uses algorithms to look for patterns and trends in the data. For example, an AI system can analyze shopping data to see which products are popular and when they are bought the most. Examples in Real Life Big data is used in many fields. Let's look at a few examples to understand how it works and connects with AI and decision trees. Healthcare: In healthcare, big data helps doctors find better treatments by analyzing patient records. For example, an AI system can look at thousands of medical records to identify which treatments work best for certain diseases. This helps doctors make better decisions about patient care. Social Media: Companies like Facebook and Instagram use big data to understand user behavior. They analyze data from millions of users to see what kind of content people like and how they interact with it. This helps them improve their services and keep users engaged. Sports: In sports, big data is used to analyze player performance. Teams collect data on players' movements, speed, and health. AI systems can then analyze this data to help coaches make decisions about training and strategy. For example, by looking at data from past games, an AI system can suggest the best lineup for an upcoming match. Transportation: Big data helps improve transportation systems. For instance, AI can analyze traffic data from sensors and cameras around a city to optimize traffic light patterns. This helps reduce traffic jams and makes transportation more efficient. Retail: Retailers use big data to understand customer preferences. By analyzing shopping data, AI systems can recommend products to customers based on their past purchases. For example, if you often buy sports gear, an online store might recommend new sports equipment to you. Connection with Decision Trees Big data and decision trees are closely connected in AI. Decision trees need data to make decisions, and big data provides a large amount of information for them to analyze. Better Decision Making: With big data, decision trees can make better decisions. For example, a decision tree used by an online store to recommend products can analyze millions of purchase records to make more accurate recommendations. Training Decision Trees: Big data helps train decision trees. By providing lots of data, we can train decision trees to recognize patterns and make better predictions. For example, a decision tree used in healthcare can be trained on thousands of medical records to diagnose diseases more accurately. Real-Time Analysis: Big data allows decision trees to analyze information in real-time. For instance, in transportation, a decision tree can use real-time traffic data to make decisions about traffic light patterns, helping to reduce congestion immediately. Conclusion Big data is a crucial part of AI. It provides the information needed for AI systems to learn and make decisions. By understanding how big data works and seeing real-life examples, we can appreciate its importance in various fields. Whether it\u2019s in healthcare, social media, sports, transportation, or retail, big data helps AI systems perform better. And when combined with decision trees, big data makes AI even more powerful, allowing for smarter and faster decisions.","title":"Big Data"},{"location":"contents/unit01/big-data.html#big-data","text":"Big Data refers to extremely large sets of data that can be analyzed to find patterns, trends, and associations. This is important for AI because AI systems learn and make decisions based on data.","title":"Big Data"},{"location":"contents/unit01/big-data.html#why-big-data-is-important","text":"In the past, collecting and analyzing data was slow and difficult. People had to go through information manually, which took a lot of time. Now, with the help of computers, we can gather huge amounts of data from the internet, sensors, and other sources. This data helps AI systems learn and improve. Speed and Efficiency: Computers can process large amounts of data very quickly. This means that AI systems can learn faster and make more accurate decisions. For example, an AI system can analyze millions of pictures to learn how to recognize objects in just a few hours, something that would take humans years to do. Better Learning: The more data an AI system has, the better it can learn. Big data provides AI with a wealth of information, which helps it make more accurate predictions and decisions. For instance, an AI system that analyzes weather data from all over the world can make better weather forecasts.","title":"Why Big Data is Important"},{"location":"contents/unit01/big-data.html#how-big-data-works","text":"Imagine you have a massive library of books. Instead of reading each book one by one, you use a computer to quickly scan and analyze all the books to find useful information. This is what big data does. It allows AI to process vast amounts of information quickly and accurately. Data Collection: Data can come from many sources like websites, social media, sensors, and cameras. For example, a fitness app collects data from users' phones and smartwatches to track their exercise habits. Data Storage: Once collected, the data needs to be stored. This is done using big data technologies that can handle large volumes of information. Companies use big servers and cloud storage to keep all this data safe and accessible. Data Analysis: After storing the data, it needs to be analyzed. AI uses algorithms to look for patterns and trends in the data. For example, an AI system can analyze shopping data to see which products are popular and when they are bought the most.","title":"How Big Data Works"},{"location":"contents/unit01/big-data.html#examples-in-real-life","text":"Big data is used in many fields. Let's look at a few examples to understand how it works and connects with AI and decision trees. Healthcare: In healthcare, big data helps doctors find better treatments by analyzing patient records. For example, an AI system can look at thousands of medical records to identify which treatments work best for certain diseases. This helps doctors make better decisions about patient care. Social Media: Companies like Facebook and Instagram use big data to understand user behavior. They analyze data from millions of users to see what kind of content people like and how they interact with it. This helps them improve their services and keep users engaged. Sports: In sports, big data is used to analyze player performance. Teams collect data on players' movements, speed, and health. AI systems can then analyze this data to help coaches make decisions about training and strategy. For example, by looking at data from past games, an AI system can suggest the best lineup for an upcoming match. Transportation: Big data helps improve transportation systems. For instance, AI can analyze traffic data from sensors and cameras around a city to optimize traffic light patterns. This helps reduce traffic jams and makes transportation more efficient. Retail: Retailers use big data to understand customer preferences. By analyzing shopping data, AI systems can recommend products to customers based on their past purchases. For example, if you often buy sports gear, an online store might recommend new sports equipment to you.","title":"Examples in Real Life"},{"location":"contents/unit01/big-data.html#connection-with-decision-trees","text":"Big data and decision trees are closely connected in AI. Decision trees need data to make decisions, and big data provides a large amount of information for them to analyze. Better Decision Making: With big data, decision trees can make better decisions. For example, a decision tree used by an online store to recommend products can analyze millions of purchase records to make more accurate recommendations. Training Decision Trees: Big data helps train decision trees. By providing lots of data, we can train decision trees to recognize patterns and make better predictions. For example, a decision tree used in healthcare can be trained on thousands of medical records to diagnose diseases more accurately. Real-Time Analysis: Big data allows decision trees to analyze information in real-time. For instance, in transportation, a decision tree can use real-time traffic data to make decisions about traffic light patterns, helping to reduce congestion immediately.","title":"Connection with Decision Trees"},{"location":"contents/unit01/big-data.html#conclusion","text":"Big data is a crucial part of AI. It provides the information needed for AI systems to learn and make decisions. By understanding how big data works and seeing real-life examples, we can appreciate its importance in various fields. Whether it\u2019s in healthcare, social media, sports, transportation, or retail, big data helps AI systems perform better. And when combined with decision trees, big data makes AI even more powerful, allowing for smarter and faster decisions.","title":"Conclusion"},{"location":"contents/unit01/decision-trees.html","text":"Decision Trees A Decision Tree is a tool used in AI to make decisions based on data. It looks like a tree with branches. Each branch represents a choice, and each leaf represents an outcome. How Decision Trees Work Imagine you are trying to decide what game to play. You start at the root of the tree with a question, like \"Is it raining?\" If the answer is yes, you follow one branch; if the answer is no, you follow another branch. Each branch leads to more questions until you reach a leaf, which tells you what game to play. This process of asking questions and making choices is how a decision tree helps computers make decisions. Nodes and Branches: In a decision tree, each node represents a question. The branches coming out of a node represent the possible answers. Each answer leads to another node or to a leaf. Leaves represent the final decision. Building a Decision Tree: To build a decision tree, you need data. For example, if you want to build a tree to decide what game to play, you need data about the weather, available games, and preferences. The tree is built by choosing the most important questions that help split the data into different categories. Examples in Real Life Decision trees are used in many areas. Let's look at a few examples to understand how they are used in everyday life. Medical Diagnosis: Doctors use decision trees to diagnose diseases. For example, a decision tree for diagnosing flu might start with the question, \"Do you have a fever?\" If the answer is yes, the next question might be, \"Do you have a cough?\" Each question helps narrow down the possible diseases until a diagnosis is reached. This helps doctors make accurate diagnoses based on symptoms. Product Recommendations: Online stores like Amazon use decision trees to recommend products. When you browse products, the store collects data about your preferences. The decision tree might start with questions like, \"Have you bought electronics recently?\" If the answer is yes, it might recommend similar electronics. If the answer is no, it might ask, \"Do you like sports?\" and recommend sports equipment based on your past purchases. This helps personalize your shopping experience. Customer Support: Many companies use decision trees to improve customer support. When you call a helpline, an automated system might use a decision tree to ask questions like, \"Is your issue related to billing?\" Depending on your answers, it directs you to the right support representative or provides a solution directly. This makes customer support more efficient and faster. Loan Approval: Banks use decision trees to decide whether to approve a loan. The tree might start with questions like, \"What is your credit score?\" Based on the answer, it might ask, \"Do you have a stable income?\" Each question helps the bank assess the risk of lending money to you. This helps ensure that loans are given to people who are likely to repay them. Weather Prediction: Meteorologists use decision trees to predict weather conditions. The tree might start with questions like, \"What is the current temperature?\" and \"Is there a high pressure system nearby?\" Each question helps narrow down the possible weather outcomes. This helps provide accurate weather forecasts. Benefits and Limitations Benefits: Decision trees are easy to understand and interpret. They can handle both numerical and categorical data and are useful for both classification (e.g., diagnosing diseases) and regression (e.g., predicting prices). Limitations: Decision trees can become very complex and overfit the data, meaning they work well on training data but poorly on new data. They can also be sensitive to small changes in the data, which can lead to different trees being generated from slightly different data sets. Conclusion Decision trees are powerful tools in AI that help make decisions based on data. By understanding how they work and seeing real-life examples, we can appreciate their importance in various fields. Whether it\u2019s diagnosing diseases, recommending products, or predicting the weather, decision trees help computers and humans make informed decisions. As we continue to explore AI, understanding decision trees will provide a solid foundation for learning more advanced concepts.","title":"Decision Trees"},{"location":"contents/unit01/decision-trees.html#decision-trees","text":"A Decision Tree is a tool used in AI to make decisions based on data. It looks like a tree with branches. Each branch represents a choice, and each leaf represents an outcome.","title":"Decision Trees"},{"location":"contents/unit01/decision-trees.html#how-decision-trees-work","text":"Imagine you are trying to decide what game to play. You start at the root of the tree with a question, like \"Is it raining?\" If the answer is yes, you follow one branch; if the answer is no, you follow another branch. Each branch leads to more questions until you reach a leaf, which tells you what game to play. This process of asking questions and making choices is how a decision tree helps computers make decisions. Nodes and Branches: In a decision tree, each node represents a question. The branches coming out of a node represent the possible answers. Each answer leads to another node or to a leaf. Leaves represent the final decision. Building a Decision Tree: To build a decision tree, you need data. For example, if you want to build a tree to decide what game to play, you need data about the weather, available games, and preferences. The tree is built by choosing the most important questions that help split the data into different categories.","title":"How Decision Trees Work"},{"location":"contents/unit01/decision-trees.html#examples-in-real-life","text":"Decision trees are used in many areas. Let's look at a few examples to understand how they are used in everyday life. Medical Diagnosis: Doctors use decision trees to diagnose diseases. For example, a decision tree for diagnosing flu might start with the question, \"Do you have a fever?\" If the answer is yes, the next question might be, \"Do you have a cough?\" Each question helps narrow down the possible diseases until a diagnosis is reached. This helps doctors make accurate diagnoses based on symptoms. Product Recommendations: Online stores like Amazon use decision trees to recommend products. When you browse products, the store collects data about your preferences. The decision tree might start with questions like, \"Have you bought electronics recently?\" If the answer is yes, it might recommend similar electronics. If the answer is no, it might ask, \"Do you like sports?\" and recommend sports equipment based on your past purchases. This helps personalize your shopping experience. Customer Support: Many companies use decision trees to improve customer support. When you call a helpline, an automated system might use a decision tree to ask questions like, \"Is your issue related to billing?\" Depending on your answers, it directs you to the right support representative or provides a solution directly. This makes customer support more efficient and faster. Loan Approval: Banks use decision trees to decide whether to approve a loan. The tree might start with questions like, \"What is your credit score?\" Based on the answer, it might ask, \"Do you have a stable income?\" Each question helps the bank assess the risk of lending money to you. This helps ensure that loans are given to people who are likely to repay them. Weather Prediction: Meteorologists use decision trees to predict weather conditions. The tree might start with questions like, \"What is the current temperature?\" and \"Is there a high pressure system nearby?\" Each question helps narrow down the possible weather outcomes. This helps provide accurate weather forecasts.","title":"Examples in Real Life"},{"location":"contents/unit01/decision-trees.html#benefits-and-limitations","text":"Benefits: Decision trees are easy to understand and interpret. They can handle both numerical and categorical data and are useful for both classification (e.g., diagnosing diseases) and regression (e.g., predicting prices). Limitations: Decision trees can become very complex and overfit the data, meaning they work well on training data but poorly on new data. They can also be sensitive to small changes in the data, which can lead to different trees being generated from slightly different data sets.","title":"Benefits and Limitations"},{"location":"contents/unit01/decision-trees.html#conclusion","text":"Decision trees are powerful tools in AI that help make decisions based on data. By understanding how they work and seeing real-life examples, we can appreciate their importance in various fields. Whether it\u2019s diagnosing diseases, recommending products, or predicting the weather, decision trees help computers and humans make informed decisions. As we continue to explore AI, understanding decision trees will provide a solid foundation for learning more advanced concepts.","title":"Conclusion"},{"location":"contents/unit01/exercises-1-1.html","text":"Exercises","title":"\u270f\ufe0f Exercises"},{"location":"contents/unit01/exercises-1-1.html#exercises","text":"","title":"Exercises"},{"location":"contents/unit01/expert-systems.html","text":"Expert Systems Expert Systems are a fundamental concept in Artificial Intelligence (AI) that mimic human expertise to solve complex problems. They are designed to make decisions and provide solutions based on a set of rules and knowledge provided by human experts. Let\u2019s explore how expert systems work, where they are applied, and their implications. Fundamentals of Expert Systems Expert systems are built on a knowledge base, which contains facts, rules, and reasoning mechanisms. These systems use this knowledge to emulate the decision-making process of a human expert in a specific domain. Here\u2019s how they typically operate: Knowledge Base: This is where all the information and rules about a particular subject are stored. For example, in a medical expert system, the knowledge base would contain information about symptoms, diseases, and treatments. Inference Engine: This component processes the information in the knowledge base and applies logical rules to draw conclusions or make recommendations. It mimics human reasoning by following a set of logical steps. User Interface: Users interact with the expert system through a user-friendly interface. They input data or answer questions posed by the system, which then uses this information to provide solutions or recommendations. How Expert Systems Work Imagine a medical diagnosis expert system. When a patient enters symptoms into the system, the inference engine matches these symptoms against the rules and data in the knowledge base. It then generates a list of possible diseases and recommended treatments based on the input. Example Scenario: If a patient inputs symptoms like fever, cough, and fatigue, the expert system might infer that they have a cold or flu based on its rules about common symptoms and diseases. Applications of Expert Systems Expert systems are used in various fields where expertise is crucial for decision-making: Healthcare: They assist doctors in diagnosing diseases and recommending treatments based on patient symptoms and medical history. Finance: They help financial advisors assess investment opportunities based on market trends and risk analysis. Engineering: They aid engineers in troubleshooting complex systems or designing solutions based on established engineering principles. Ethical and Social Implications While expert systems offer many benefits, such as increased efficiency and consistency in decision-making, they also raise ethical concerns: Accuracy and Reliability: It\u2019s critical that expert systems provide accurate recommendations. Errors in diagnosis or advice can have serious consequences for individuals. Responsibility: Who is accountable if an expert system makes a wrong diagnosis or recommendation? The responsibility might lie with the developers, the users, or both. Bias: If the knowledge base or rules are biased or incomplete, the expert system\u2019s decisions may reflect these biases, leading to unfair outcomes. Using Expert Systems in Simple Applications To understand how expert systems work practically, you can engage in guided activities where they interact with simplified expert systems. For instance: Scenario: you could use a basic expert system to diagnose fictional medical cases or troubleshoot simple technical problems. Learning Outcomes: By engaging with these systems, you can grasp the foundational concepts of AI, understand how rules and data interact in decision-making, and begin to appreciate the practical applications of expert systems in everyday scenarios. In conclusion, expert systems play a vital role in AI by leveraging human expertise to solve complex problems efficiently. Understanding their fundamentals, applications, and ethical implications prepares students to explore more advanced AI techniques and their impact on society responsibly.","title":"Expert systems"},{"location":"contents/unit01/expert-systems.html#expert-systems","text":"Expert Systems are a fundamental concept in Artificial Intelligence (AI) that mimic human expertise to solve complex problems. They are designed to make decisions and provide solutions based on a set of rules and knowledge provided by human experts. Let\u2019s explore how expert systems work, where they are applied, and their implications.","title":"Expert Systems"},{"location":"contents/unit01/expert-systems.html#fundamentals-of-expert-systems","text":"Expert systems are built on a knowledge base, which contains facts, rules, and reasoning mechanisms. These systems use this knowledge to emulate the decision-making process of a human expert in a specific domain. Here\u2019s how they typically operate: Knowledge Base: This is where all the information and rules about a particular subject are stored. For example, in a medical expert system, the knowledge base would contain information about symptoms, diseases, and treatments. Inference Engine: This component processes the information in the knowledge base and applies logical rules to draw conclusions or make recommendations. It mimics human reasoning by following a set of logical steps. User Interface: Users interact with the expert system through a user-friendly interface. They input data or answer questions posed by the system, which then uses this information to provide solutions or recommendations.","title":"Fundamentals of Expert Systems"},{"location":"contents/unit01/expert-systems.html#how-expert-systems-work","text":"Imagine a medical diagnosis expert system. When a patient enters symptoms into the system, the inference engine matches these symptoms against the rules and data in the knowledge base. It then generates a list of possible diseases and recommended treatments based on the input. Example Scenario: If a patient inputs symptoms like fever, cough, and fatigue, the expert system might infer that they have a cold or flu based on its rules about common symptoms and diseases.","title":"How Expert Systems Work"},{"location":"contents/unit01/expert-systems.html#applications-of-expert-systems","text":"Expert systems are used in various fields where expertise is crucial for decision-making: Healthcare: They assist doctors in diagnosing diseases and recommending treatments based on patient symptoms and medical history. Finance: They help financial advisors assess investment opportunities based on market trends and risk analysis. Engineering: They aid engineers in troubleshooting complex systems or designing solutions based on established engineering principles.","title":"Applications of Expert Systems"},{"location":"contents/unit01/expert-systems.html#ethical-and-social-implications","text":"While expert systems offer many benefits, such as increased efficiency and consistency in decision-making, they also raise ethical concerns: Accuracy and Reliability: It\u2019s critical that expert systems provide accurate recommendations. Errors in diagnosis or advice can have serious consequences for individuals. Responsibility: Who is accountable if an expert system makes a wrong diagnosis or recommendation? The responsibility might lie with the developers, the users, or both. Bias: If the knowledge base or rules are biased or incomplete, the expert system\u2019s decisions may reflect these biases, leading to unfair outcomes.","title":"Ethical and Social Implications"},{"location":"contents/unit01/expert-systems.html#using-expert-systems-in-simple-applications","text":"To understand how expert systems work practically, you can engage in guided activities where they interact with simplified expert systems. For instance: Scenario: you could use a basic expert system to diagnose fictional medical cases or troubleshoot simple technical problems. Learning Outcomes: By engaging with these systems, you can grasp the foundational concepts of AI, understand how rules and data interact in decision-making, and begin to appreciate the practical applications of expert systems in everyday scenarios. In conclusion, expert systems play a vital role in AI by leveraging human expertise to solve complex problems efficiently. Understanding their fundamentals, applications, and ethical implications prepares students to explore more advanced AI techniques and their impact on society responsibly.","title":"Using Expert Systems in Simple Applications"},{"location":"contents/unit01/glossary-ud01.html","text":"Glossary","title":"Glossary"},{"location":"contents/unit01/glossary-ud01.html#glossary","text":"","title":"Glossary"},{"location":"contents/unit01/intro.html","text":"Artificial Intelligence","title":"0.1. Introduction to AI, Programming and Robotics"},{"location":"contents/unit01/intro.html#artificial-intelligence","text":"","title":"Artificial Intelligence"},{"location":"contents/unit01/learning-aipr.html","text":"Learning: AI, Programming and Robots Learning and Robots In artificial intelligence (AI) and robotics, we try to mimic how biological systems learn. Let's see how this works: Machine Learning: Just like our brains, AI systems can learn from experiences. Machine learning is a type of AI where computers learn from data. For example, a computer can learn to recognize pictures of cats by looking at many cat photos and finding patterns. Reinforcement Learning: This is similar to operant conditioning in animals. In reinforcement learning, an AI learns by trying different actions and receiving rewards or punishments. For example, a robot can learn to navigate a maze by getting points for moving in the right direction and losing points for hitting walls. Neural Networks: These are computer systems modeled after the human brain. They consist of layers of interconnected nodes (like neurons) that process information. Neural networks are used in many AI applications, such as recognizing speech or translating languages. Programming AI and Robots Programming AI and robots involves writing code that allows them to learn and make decisions. Here are some key points: Algorithms: Algorithms are step-by-step instructions for solving problems. In AI, algorithms help computers learn from data. For example, a sorting algorithm can help a robot organize objects by size. Sensors and Actuators: Robots use sensors to collect information about their environment (like cameras or touch sensors) and actuators to perform actions (like moving arms or wheels). Programming involves making sure the robot can process sensor data and respond appropriately. Autonomous Decision-Making: Advanced AI systems can make decisions on their own, based on their programming and learning. For example, self-driving cars use AI to decide when to turn, stop, or speed up, based on data from their sensors. Conclusion Learning in biological systems is a complex process that helps living things adapt and survive. By understanding how we learn and make decisions, we can create better AI and robots. These smart machines can learn from experiences, make decisions, and help us in many ways. So, every choice we make, whether influenced by our past or not, helps us grow and learn even more, just like the AI and robots we build.","title":"Learning, AI, Programming, and Robots"},{"location":"contents/unit01/learning-aipr.html#learning-ai-programming-and-robots","text":"","title":"Learning: AI, Programming and Robots"},{"location":"contents/unit01/learning-aipr.html#learning-and-robots","text":"In artificial intelligence (AI) and robotics, we try to mimic how biological systems learn. Let's see how this works: Machine Learning: Just like our brains, AI systems can learn from experiences. Machine learning is a type of AI where computers learn from data. For example, a computer can learn to recognize pictures of cats by looking at many cat photos and finding patterns. Reinforcement Learning: This is similar to operant conditioning in animals. In reinforcement learning, an AI learns by trying different actions and receiving rewards or punishments. For example, a robot can learn to navigate a maze by getting points for moving in the right direction and losing points for hitting walls. Neural Networks: These are computer systems modeled after the human brain. They consist of layers of interconnected nodes (like neurons) that process information. Neural networks are used in many AI applications, such as recognizing speech or translating languages.","title":"Learning and Robots"},{"location":"contents/unit01/learning-aipr.html#programming-ai-and-robots","text":"Programming AI and robots involves writing code that allows them to learn and make decisions. Here are some key points: Algorithms: Algorithms are step-by-step instructions for solving problems. In AI, algorithms help computers learn from data. For example, a sorting algorithm can help a robot organize objects by size. Sensors and Actuators: Robots use sensors to collect information about their environment (like cameras or touch sensors) and actuators to perform actions (like moving arms or wheels). Programming involves making sure the robot can process sensor data and respond appropriately. Autonomous Decision-Making: Advanced AI systems can make decisions on their own, based on their programming and learning. For example, self-driving cars use AI to decide when to turn, stop, or speed up, based on data from their sensors.","title":"Programming AI and Robots"},{"location":"contents/unit01/learning-aipr.html#conclusion","text":"Learning in biological systems is a complex process that helps living things adapt and survive. By understanding how we learn and make decisions, we can create better AI and robots. These smart machines can learn from experiences, make decisions, and help us in many ways. So, every choice we make, whether influenced by our past or not, helps us grow and learn even more, just like the AI and robots we build.","title":"Conclusion"},{"location":"contents/unit01/machine-learning.html","text":"Machine Learning Machine Learning (ML) is a branch of Artificial Intelligence (AI) that enables computers to learn from data and improve their performance without being explicitly programmed. It is widely used in various applications to make predictions, recognize patterns, and automate decision-making processes. Let\u2019s explore the fundamentals of machine learning, its applications, and the ethical considerations associated with its use. Fundamentals of Machine Learning Machine learning algorithms learn from data by identifying patterns and making decisions based on statistical analysis. Here are key concepts: Training Data: Machine learning models are trained using large datasets that contain examples of inputs (features) and their corresponding outputs (labels or predictions). Types of Machine Learning: There are three main types of machine learning: Supervised Learning: The model learns from labeled data, where it is trained with input-output pairs (e.g., predicting housing prices based on features like size and location). Unsupervised Learning: The model learns from unlabeled data to discover patterns and relationships (e.g., clustering similar customer behavior). Reinforcement Learning: The model learns through trial and error by interacting with an environment and receiving feedback (e.g., training a robot to navigate a maze). Algorithm Training: During training, the machine learning algorithm adjusts its internal parameters (weights) to minimize errors and improve accuracy in predicting outputs for new, unseen data. How Machine Learning Works To understand its function better, consider an example of training a machine learning model to classify images of animals: Data Preparation: The model is trained using a dataset of animal images labeled with their respective species (e.g., dogs, cats, birds). Feature Extraction: The model analyzes features such as shapes, colors, and textures in the images to differentiate between different animal species. Model Training: Using supervised learning, the model adjusts its parameters based on labeled examples to correctly classify new images it hasn\u2019t seen before. Applications of Machine Learning Machine learning is applied in various fields due to its ability to analyze vast amounts of data and derive insights: Healthcare: ML models assist in diagnosing diseases from medical images, predicting patient outcomes, and personalizing treatment plans. Finance: They are used for credit scoring, fraud detection, and stock market predictions based on historical data. Recommendation Systems: ML powers recommendation engines in e-commerce and streaming platforms to suggest products or content based on user preferences. Ethical and Social Implications While machine learning offers significant benefits, it also presents ethical challenges: Bias and Fairness: ML algorithms can perpetuate biases present in training data, leading to unfair decisions (e.g., biased hiring practices in automated systems). Privacy Concerns: ML models trained on personal data raise concerns about privacy and data security, especially in healthcare and finance. Impact on Employment: Automation driven by ML may lead to job displacement in certain industries, impacting the workforce. Using Machine Learning in Simple Applications You can explore the fascinating world of machine learning through hands-on activities that illustrate its practical applications. For example, imagine using a basic machine learning model to predict the weather. By analyzing historical data on temperature and humidity, you can train the model to forecast future weather conditions. This activity allows you to see firsthand how machine learning algorithms can analyze data patterns to make predictions. Participating in such activities offers valuable learning outcomes: Grasping Foundational ML Concepts: You'll understand the fundamental principles of machine learning, such as training data, algorithms, and model predictions. Learning Prediction Algorithms: You'll learn how algorithms process data to forecast outcomes, whether it's predicting the weather or making recommendations based on user preferences. Appreciating Real-World Applications: By engaging with machine learning models, you'll appreciate how these technologies are used in various fields to solve complex problems, from healthcare to finance and beyond. These activities not only enhance your understanding of artificial intelligence but also prepare you to think critically about its ethical implications and societal impact. Embrace the opportunity to explore machine learning\u2014it's a pivotal technology shaping the future! In conclusion, machine learning represents a powerful tool in AI, enabling computers to learn and make decisions from data. Understanding its fundamentals, applications, and ethical implications prepares students to navigate the complexities of AI responsibly and innovatively in their future endeavors.","title":"Machine learning"},{"location":"contents/unit01/machine-learning.html#machine-learning","text":"Machine Learning (ML) is a branch of Artificial Intelligence (AI) that enables computers to learn from data and improve their performance without being explicitly programmed. It is widely used in various applications to make predictions, recognize patterns, and automate decision-making processes. Let\u2019s explore the fundamentals of machine learning, its applications, and the ethical considerations associated with its use.","title":"Machine Learning"},{"location":"contents/unit01/machine-learning.html#fundamentals-of-machine-learning","text":"Machine learning algorithms learn from data by identifying patterns and making decisions based on statistical analysis. Here are key concepts: Training Data: Machine learning models are trained using large datasets that contain examples of inputs (features) and their corresponding outputs (labels or predictions). Types of Machine Learning: There are three main types of machine learning: Supervised Learning: The model learns from labeled data, where it is trained with input-output pairs (e.g., predicting housing prices based on features like size and location). Unsupervised Learning: The model learns from unlabeled data to discover patterns and relationships (e.g., clustering similar customer behavior). Reinforcement Learning: The model learns through trial and error by interacting with an environment and receiving feedback (e.g., training a robot to navigate a maze). Algorithm Training: During training, the machine learning algorithm adjusts its internal parameters (weights) to minimize errors and improve accuracy in predicting outputs for new, unseen data.","title":"Fundamentals of Machine Learning"},{"location":"contents/unit01/machine-learning.html#how-machine-learning-works","text":"To understand its function better, consider an example of training a machine learning model to classify images of animals: Data Preparation: The model is trained using a dataset of animal images labeled with their respective species (e.g., dogs, cats, birds). Feature Extraction: The model analyzes features such as shapes, colors, and textures in the images to differentiate between different animal species. Model Training: Using supervised learning, the model adjusts its parameters based on labeled examples to correctly classify new images it hasn\u2019t seen before.","title":"How Machine Learning Works"},{"location":"contents/unit01/machine-learning.html#applications-of-machine-learning","text":"Machine learning is applied in various fields due to its ability to analyze vast amounts of data and derive insights: Healthcare: ML models assist in diagnosing diseases from medical images, predicting patient outcomes, and personalizing treatment plans. Finance: They are used for credit scoring, fraud detection, and stock market predictions based on historical data. Recommendation Systems: ML powers recommendation engines in e-commerce and streaming platforms to suggest products or content based on user preferences.","title":"Applications of Machine Learning"},{"location":"contents/unit01/machine-learning.html#ethical-and-social-implications","text":"While machine learning offers significant benefits, it also presents ethical challenges: Bias and Fairness: ML algorithms can perpetuate biases present in training data, leading to unfair decisions (e.g., biased hiring practices in automated systems). Privacy Concerns: ML models trained on personal data raise concerns about privacy and data security, especially in healthcare and finance. Impact on Employment: Automation driven by ML may lead to job displacement in certain industries, impacting the workforce.","title":"Ethical and Social Implications"},{"location":"contents/unit01/machine-learning.html#using-machine-learning-in-simple-applications","text":"You can explore the fascinating world of machine learning through hands-on activities that illustrate its practical applications. For example, imagine using a basic machine learning model to predict the weather. By analyzing historical data on temperature and humidity, you can train the model to forecast future weather conditions. This activity allows you to see firsthand how machine learning algorithms can analyze data patterns to make predictions. Participating in such activities offers valuable learning outcomes: Grasping Foundational ML Concepts: You'll understand the fundamental principles of machine learning, such as training data, algorithms, and model predictions. Learning Prediction Algorithms: You'll learn how algorithms process data to forecast outcomes, whether it's predicting the weather or making recommendations based on user preferences. Appreciating Real-World Applications: By engaging with machine learning models, you'll appreciate how these technologies are used in various fields to solve complex problems, from healthcare to finance and beyond. These activities not only enhance your understanding of artificial intelligence but also prepare you to think critically about its ethical implications and societal impact. Embrace the opportunity to explore machine learning\u2014it's a pivotal technology shaping the future! In conclusion, machine learning represents a powerful tool in AI, enabling computers to learn and make decisions from data. Understanding its fundamentals, applications, and ethical implications prepares students to navigate the complexities of AI responsibly and innovatively in their future endeavors.","title":"Using Machine Learning in Simple Applications"},{"location":"contents/unit01/neural-networks-tech.html","text":"Neural Networks Neural Networks are a fundamental technology in Artificial Intelligence (AI) that mimics the human brain's ability to learn and recognize patterns. They are used in various applications to make decisions, classify data, and improve accuracy over time. Let's explore how neural networks work, where they are applied, and their ethical implications. Fundamentals of Neural Networks Neural networks are composed of layers of nodes, similar to neurons in the brain. Each node processes information and passes it to the next layer. Here\u2019s how they typically operate: Layers and Nodes: Neural networks consist of an input layer where data enters, hidden layers that process the data, and an output layer that provides the final result. Nodes within each layer are interconnected, and each connection has a weight that adjusts as the network learns. Processing Data: When data enters the network, it is processed through the layers of nodes. Each node applies a mathematical function to the input data, transforming it into a form that can be understood by the next layer. This process continues until the final output layer produces a result, such as a classification or prediction. How Neural Networks Work To understand their function better, consider an example of training a neural network to recognize handwritten digits: Training Process: The network is fed with thousands of images of handwritten digits, each labeled with the correct digit. During training, it adjusts the weights of connections between nodes to minimize errors in its predictions. This iterative process improves the network's ability to accurately recognize digits it has not seen before. Learning Patterns: Neural networks learn by recognizing patterns in data. For instance, when analyzing images, they identify features like edges, shapes, and textures that distinguish one object from another. Applications of Neural Networks Neural networks are applied in diverse fields due to their ability to handle complex tasks: Image and Speech Recognition: They power applications like facial recognition in smartphones and voice assistants that understand and respond to spoken commands. Medical Diagnosis: In healthcare, neural networks assist in diagnosing diseases by analyzing medical images and patient data to identify patterns indicative of specific conditions. Autonomous Vehicles: Self-driving cars use neural networks to interpret sensor data and make decisions about steering, braking, and navigating traffic. Ethical and Social Implications Despite their benefits, neural networks raise ethical concerns: Privacy: Applications like facial recognition raise concerns about privacy and surveillance, as they can track individuals without their consent. Bias: If trained on biased data, neural networks may produce unfair outcomes, perpetuating societal inequalities. Job Displacement: Automation driven by AI, including neural networks, may lead to job losses in certain sectors. Using Neural Networks in Simple Applications You can engage with neural networks through guided activities to understand their practical applications: Activity Example: You could use a simplified neural network to classify images of animals based on their features, demonstrating how the network learns to distinguish between different types of animals. Learning Outcomes: By interacting with these systems, you can develop a foundational understanding of AI concepts, learn how neural networks process information, and begin to appreciate their role in solving real-world problems. In conclusion, neural networks represent a powerful tool in AI, capable of learning from data and making decisions akin to human cognition. Understanding their fundamentals, applications, and ethical considerations prepares students to navigate the evolving landscape of AI responsibly and innovatively.","title":"Neural networks"},{"location":"contents/unit01/neural-networks-tech.html#neural-networks","text":"Neural Networks are a fundamental technology in Artificial Intelligence (AI) that mimics the human brain's ability to learn and recognize patterns. They are used in various applications to make decisions, classify data, and improve accuracy over time. Let's explore how neural networks work, where they are applied, and their ethical implications.","title":"Neural Networks"},{"location":"contents/unit01/neural-networks-tech.html#fundamentals-of-neural-networks","text":"Neural networks are composed of layers of nodes, similar to neurons in the brain. Each node processes information and passes it to the next layer. Here\u2019s how they typically operate: Layers and Nodes: Neural networks consist of an input layer where data enters, hidden layers that process the data, and an output layer that provides the final result. Nodes within each layer are interconnected, and each connection has a weight that adjusts as the network learns. Processing Data: When data enters the network, it is processed through the layers of nodes. Each node applies a mathematical function to the input data, transforming it into a form that can be understood by the next layer. This process continues until the final output layer produces a result, such as a classification or prediction.","title":"Fundamentals of Neural Networks"},{"location":"contents/unit01/neural-networks-tech.html#how-neural-networks-work","text":"To understand their function better, consider an example of training a neural network to recognize handwritten digits: Training Process: The network is fed with thousands of images of handwritten digits, each labeled with the correct digit. During training, it adjusts the weights of connections between nodes to minimize errors in its predictions. This iterative process improves the network's ability to accurately recognize digits it has not seen before. Learning Patterns: Neural networks learn by recognizing patterns in data. For instance, when analyzing images, they identify features like edges, shapes, and textures that distinguish one object from another.","title":"How Neural Networks Work"},{"location":"contents/unit01/neural-networks-tech.html#applications-of-neural-networks","text":"Neural networks are applied in diverse fields due to their ability to handle complex tasks: Image and Speech Recognition: They power applications like facial recognition in smartphones and voice assistants that understand and respond to spoken commands. Medical Diagnosis: In healthcare, neural networks assist in diagnosing diseases by analyzing medical images and patient data to identify patterns indicative of specific conditions. Autonomous Vehicles: Self-driving cars use neural networks to interpret sensor data and make decisions about steering, braking, and navigating traffic.","title":"Applications of Neural Networks"},{"location":"contents/unit01/neural-networks-tech.html#ethical-and-social-implications","text":"Despite their benefits, neural networks raise ethical concerns: Privacy: Applications like facial recognition raise concerns about privacy and surveillance, as they can track individuals without their consent. Bias: If trained on biased data, neural networks may produce unfair outcomes, perpetuating societal inequalities. Job Displacement: Automation driven by AI, including neural networks, may lead to job losses in certain sectors.","title":"Ethical and Social Implications"},{"location":"contents/unit01/neural-networks-tech.html#using-neural-networks-in-simple-applications","text":"You can engage with neural networks through guided activities to understand their practical applications: Activity Example: You could use a simplified neural network to classify images of animals based on their features, demonstrating how the network learns to distinguish between different types of animals. Learning Outcomes: By interacting with these systems, you can develop a foundational understanding of AI concepts, learn how neural networks process information, and begin to appreciate their role in solving real-world problems. In conclusion, neural networks represent a powerful tool in AI, capable of learning from data and making decisions akin to human cognition. Understanding their fundamentals, applications, and ethical considerations prepares students to navigate the evolving landscape of AI responsibly and innovatively.","title":"Using Neural Networks in Simple Applications"},{"location":"contents/unit01/neural-networks.html","text":"Neural Networks Neural Networks are a key technology in AI that mimic the way the human brain works. They are used to recognize patterns, make decisions, and improve over time. Let's explore how neural networks work, how they are trained, and some real-life examples. How Neural Networks Work A neural network is made up of layers of nodes, similar to neurons in the brain. Each node processes information and passes it to the next layer. The network learns by adjusting the connections between nodes based on the data it receives. Layers of Nodes: Neural networks have three main layers: the input layer, hidden layers, and the output layer. The input layer receives the data, the hidden layers process the data, and the output layer provides the final result. Each node in a layer is connected to nodes in the next layer. Processing Information: When data enters the network, each node in the input layer processes a small part of it. The nodes pass this information to the hidden layers, where it is further processed and refined. Finally, the output layer produces the result, which could be a decision, a classification, or a prediction. Learning Process: The network learns by adjusting the connections (called weights) between nodes. When the network makes a mistake, it adjusts the weights to reduce errors in future predictions. This process is called training. Training Neural Networks Training a neural network involves feeding it large amounts of data and adjusting the connections to improve its performance. For example, to train a network to recognize pictures of cats, you show it thousands of cat pictures. The network learns the patterns and features that define a cat. Data Feeding: The training process starts by feeding the network a large set of labeled data. For example, if you want to train a network to recognize handwritten digits, you would provide it with thousands of images of handwritten numbers, each labeled with the correct digit. Adjusting Weights: During training, the network makes predictions and compares them to the correct answers. If the prediction is wrong, the network adjusts the weights of the connections to improve accuracy. This process is repeated many times until the network learns to make accurate predictions. Validation and Testing: After training, the network is validated and tested using new data to ensure it can make accurate predictions on data it has never seen before. This helps to confirm that the network has learned correctly and can generalize its knowledge to new situations. Examples in Real Life Neural networks are used in many applications. They power voice assistants like Siri and Alexa, recognize faces in photos, and even help self-driving cars navigate. Voice Assistants: Voice assistants like Siri, Alexa, and Google Assistant use neural networks to understand and respond to spoken language. When you ask a question, the voice assistant processes your speech, converts it into text, and uses a neural network to understand the meaning and provide an answer. This involves recognizing patterns in speech and understanding context. Facial Recognition: Neural networks are used in facial recognition systems, such as those in smartphones and security cameras. These systems can identify individuals by analyzing facial features. For example, when you unlock your phone with your face, a neural network processes the image, recognizes your facial features, and compares them to the stored data to verify your identity. Self-Driving Cars: Self-driving cars use neural networks to navigate and make driving decisions. The car\u2019s sensors collect data from the surroundings, such as other vehicles, pedestrians, and road signs. The neural network processes this data in real-time, helping the car make decisions about steering, braking, and accelerating to ensure safe driving. Connection with AI and Decision Trees Neural networks and decision trees are both important tools in AI. While decision trees make decisions based on a series of questions, neural networks recognize complex patterns in data. Complementary Tools: In some AI systems, neural networks and decision trees are used together. For example, a neural network might be used to recognize patterns in images, and a decision tree could use this information to make decisions. This combination allows AI systems to benefit from the strengths of both methods. Big Data and Learning: Neural networks, like decision trees, rely on big data to learn and improve. The more data a neural network has, the better it can recognize patterns and make accurate predictions. This is why big data is crucial for training both neural networks and decision trees. Improving AI Systems: By combining neural networks with decision trees and big data, AI systems can become more powerful and accurate. For example, an AI system in healthcare might use a neural network to analyze medical images and a decision tree to diagnose diseases based on the results. Conclusion Neural networks are a key technology in AI, enabling systems to recognize patterns, make decisions, and learn from data. By understanding how they work and seeing real-life examples, we can appreciate their importance in various fields. Neural networks, along with decision trees and big data, form the foundation of modern AI, making it possible to create smart and efficient systems that improve our lives. Exercises What are the main layers of a neural network? A) Input layer, Output layer, Surface layer B) Input layer, Hidden layers, Output layer C) Output layer, Middle layer, End layer D) Start layer, Middle layer, End layer What is the purpose of the output layer in a neural network? A) To collect data B) To process data C) To provide the final result D) To adjust weights What is the process of adjusting connections in a neural network called? What technology do voice assistants like Siri and Alexa use to understand speech? Explain how self-driving cars use neural networks.","title":"Neural Networks"},{"location":"contents/unit01/neural-networks.html#neural-networks","text":"Neural Networks are a key technology in AI that mimic the way the human brain works. They are used to recognize patterns, make decisions, and improve over time. Let's explore how neural networks work, how they are trained, and some real-life examples.","title":"Neural Networks"},{"location":"contents/unit01/neural-networks.html#how-neural-networks-work","text":"A neural network is made up of layers of nodes, similar to neurons in the brain. Each node processes information and passes it to the next layer. The network learns by adjusting the connections between nodes based on the data it receives. Layers of Nodes: Neural networks have three main layers: the input layer, hidden layers, and the output layer. The input layer receives the data, the hidden layers process the data, and the output layer provides the final result. Each node in a layer is connected to nodes in the next layer. Processing Information: When data enters the network, each node in the input layer processes a small part of it. The nodes pass this information to the hidden layers, where it is further processed and refined. Finally, the output layer produces the result, which could be a decision, a classification, or a prediction. Learning Process: The network learns by adjusting the connections (called weights) between nodes. When the network makes a mistake, it adjusts the weights to reduce errors in future predictions. This process is called training.","title":"How Neural Networks Work"},{"location":"contents/unit01/neural-networks.html#training-neural-networks","text":"Training a neural network involves feeding it large amounts of data and adjusting the connections to improve its performance. For example, to train a network to recognize pictures of cats, you show it thousands of cat pictures. The network learns the patterns and features that define a cat. Data Feeding: The training process starts by feeding the network a large set of labeled data. For example, if you want to train a network to recognize handwritten digits, you would provide it with thousands of images of handwritten numbers, each labeled with the correct digit. Adjusting Weights: During training, the network makes predictions and compares them to the correct answers. If the prediction is wrong, the network adjusts the weights of the connections to improve accuracy. This process is repeated many times until the network learns to make accurate predictions. Validation and Testing: After training, the network is validated and tested using new data to ensure it can make accurate predictions on data it has never seen before. This helps to confirm that the network has learned correctly and can generalize its knowledge to new situations.","title":"Training Neural Networks"},{"location":"contents/unit01/neural-networks.html#examples-in-real-life","text":"Neural networks are used in many applications. They power voice assistants like Siri and Alexa, recognize faces in photos, and even help self-driving cars navigate. Voice Assistants: Voice assistants like Siri, Alexa, and Google Assistant use neural networks to understand and respond to spoken language. When you ask a question, the voice assistant processes your speech, converts it into text, and uses a neural network to understand the meaning and provide an answer. This involves recognizing patterns in speech and understanding context. Facial Recognition: Neural networks are used in facial recognition systems, such as those in smartphones and security cameras. These systems can identify individuals by analyzing facial features. For example, when you unlock your phone with your face, a neural network processes the image, recognizes your facial features, and compares them to the stored data to verify your identity. Self-Driving Cars: Self-driving cars use neural networks to navigate and make driving decisions. The car\u2019s sensors collect data from the surroundings, such as other vehicles, pedestrians, and road signs. The neural network processes this data in real-time, helping the car make decisions about steering, braking, and accelerating to ensure safe driving.","title":"Examples in Real Life"},{"location":"contents/unit01/neural-networks.html#connection-with-ai-and-decision-trees","text":"Neural networks and decision trees are both important tools in AI. While decision trees make decisions based on a series of questions, neural networks recognize complex patterns in data. Complementary Tools: In some AI systems, neural networks and decision trees are used together. For example, a neural network might be used to recognize patterns in images, and a decision tree could use this information to make decisions. This combination allows AI systems to benefit from the strengths of both methods. Big Data and Learning: Neural networks, like decision trees, rely on big data to learn and improve. The more data a neural network has, the better it can recognize patterns and make accurate predictions. This is why big data is crucial for training both neural networks and decision trees. Improving AI Systems: By combining neural networks with decision trees and big data, AI systems can become more powerful and accurate. For example, an AI system in healthcare might use a neural network to analyze medical images and a decision tree to diagnose diseases based on the results.","title":"Connection with AI and Decision Trees"},{"location":"contents/unit01/neural-networks.html#conclusion","text":"Neural networks are a key technology in AI, enabling systems to recognize patterns, make decisions, and learn from data. By understanding how they work and seeing real-life examples, we can appreciate their importance in various fields. Neural networks, along with decision trees and big data, form the foundation of modern AI, making it possible to create smart and efficient systems that improve our lives.","title":"Conclusion"},{"location":"contents/unit01/neural-networks.html#exercises","text":"What are the main layers of a neural network? A) Input layer, Output layer, Surface layer B) Input layer, Hidden layers, Output layer C) Output layer, Middle layer, End layer D) Start layer, Middle layer, End layer What is the purpose of the output layer in a neural network? A) To collect data B) To process data C) To provide the final result D) To adjust weights What is the process of adjusting connections in a neural network called? What technology do voice assistants like Siri and Alexa use to understand speech? Explain how self-driving cars use neural networks.","title":"Exercises"},{"location":"contents/unit01/sensors-applications.html","text":"Sensors applications","title":"Applications"},{"location":"contents/unit01/sensors-applications.html#sensors-applications","text":"","title":"Sensors applications"},{"location":"contents/unit01/sensors.html","text":"Sensors Artificial Intelligence Artificial Intelligence (AI) is a technology that allows machines to learn, understand, and process information like humans. One of the key components of AI systems is sensors. Sensors are devices that can detect and measure physical and environmental conditions such as temperature, light, sound, and movement. In this lesson, we will learn about the different types of sensors used in AI applications and the different ways in which they can be used. Types of sensors Optical sensors : These sensors detect light and are used in applications such as facial recognition, object detection, and image processing. Examples of optical sensors include cameras and lidar sensors. Temperature sensors: These sensors measure temperature and are used in applications such as climate control and food safety. Examples of temperature sensors include thermocouples and thermistors. Pressure sensors: These sensors measure pressure and are used in applications such as industrial automation, weather forecasting, and healthcare. Examples of pressure sensors include piezoelectric sensors and strain gauge sensors. Accelerometer sensors: These sensors measure acceleration and are used in applications such as motion detection, navigation, and gaming. Examples of accelerometer sensors include MEMS accelerometers and piezoelectric accelerometers. Gyroscopic sensors: These sensors measure angular velocity and are used in applications such as navigation, gaming, and robotics. Examples of gyroscopic sensors include MEMS gyroscopes and fiber optic gyroscopes. Magnetic sensors: These sensors measure magnetic fields and are used in applications such as navigation, industrial automation, and healthcare. Examples of magnetic sensors include Hall effect sensors and magnetoresistive sensors. Ultrasonic sensors: These sensors measure distance and are used in applications such as object detection, navigation, and industrial automation. Examples of ultrasonic sensors include sonar sensors and lidar sensors. Infrared sensors: These sensors detect infrared radiation and are used in applications such as temperature measurement, night vision, and gesture recognition. Examples of infrared sensors include thermopile sensors and pyroelectric sensors. Proximity sensors: These sensors detect the presence of objects and are used in applications such as gesture recognition, object detection, and access control. Examples of proximity sensors include infrared proximity sensors and ultrasonic proximity sensors. Light sensors: These sensors detect light and are used in applications such as light control, gesture recognition, and object detection. Examples of light sensors include photodiodes and phototransistors. Humidity sensors: These sensors measure humidity and are used in applications such as weather forecasting, agriculture, and healthcare. Examples of humidity sensors include capacitive humidity sensors and resistive humidity sensors. Gas sensors: These sensors detect the presence of gases and are used in applications such as environmental monitoring, industrial automation, and healthcare. Examples of gas sensors include electrochemical gas sensors and metal oxide gas sensors. Images Artificial Intelligence","title":"Sensors"},{"location":"contents/unit01/sensors.html#sensors","text":"","title":"Sensors"},{"location":"contents/unit01/sensors.html#artificial-intelligence","text":"Artificial Intelligence (AI) is a technology that allows machines to learn, understand, and process information like humans. One of the key components of AI systems is sensors. Sensors are devices that can detect and measure physical and environmental conditions such as temperature, light, sound, and movement. In this lesson, we will learn about the different types of sensors used in AI applications and the different ways in which they can be used.","title":"Artificial Intelligence"},{"location":"contents/unit01/sensors.html#types-of-sensors","text":"Optical sensors : These sensors detect light and are used in applications such as facial recognition, object detection, and image processing. Examples of optical sensors include cameras and lidar sensors. Temperature sensors: These sensors measure temperature and are used in applications such as climate control and food safety. Examples of temperature sensors include thermocouples and thermistors. Pressure sensors: These sensors measure pressure and are used in applications such as industrial automation, weather forecasting, and healthcare. Examples of pressure sensors include piezoelectric sensors and strain gauge sensors. Accelerometer sensors: These sensors measure acceleration and are used in applications such as motion detection, navigation, and gaming. Examples of accelerometer sensors include MEMS accelerometers and piezoelectric accelerometers. Gyroscopic sensors: These sensors measure angular velocity and are used in applications such as navigation, gaming, and robotics. Examples of gyroscopic sensors include MEMS gyroscopes and fiber optic gyroscopes. Magnetic sensors: These sensors measure magnetic fields and are used in applications such as navigation, industrial automation, and healthcare. Examples of magnetic sensors include Hall effect sensors and magnetoresistive sensors. Ultrasonic sensors: These sensors measure distance and are used in applications such as object detection, navigation, and industrial automation. Examples of ultrasonic sensors include sonar sensors and lidar sensors. Infrared sensors: These sensors detect infrared radiation and are used in applications such as temperature measurement, night vision, and gesture recognition. Examples of infrared sensors include thermopile sensors and pyroelectric sensors. Proximity sensors: These sensors detect the presence of objects and are used in applications such as gesture recognition, object detection, and access control. Examples of proximity sensors include infrared proximity sensors and ultrasonic proximity sensors. Light sensors: These sensors detect light and are used in applications such as light control, gesture recognition, and object detection. Examples of light sensors include photodiodes and phototransistors. Humidity sensors: These sensors measure humidity and are used in applications such as weather forecasting, agriculture, and healthcare. Examples of humidity sensors include capacitive humidity sensors and resistive humidity sensors. Gas sensors: These sensors detect the presence of gases and are used in applications such as environmental monitoring, industrial automation, and healthcare. Examples of gas sensors include electrochemical gas sensors and metal oxide gas sensors.","title":"Types of sensors"},{"location":"contents/unit01/sensors.html#images","text":"Artificial Intelligence","title":"Images"},{"location":"contents/unit01/terms.html","text":"Artificial Intelligence (AI) terms AI-Powered Assistant An AI-powered assistant is a virtual assistant that uses artificial intelligence (AI) technology to understand and respond to user requests. AI-powered assistants can be used to perform tasks such as scheduling appointments, setting reminders, providing information, and answering questions. Artificial Intelligence Artificial Intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to perform tasks that would typically require human intelligence, such as reasoning, learning, perception, and problem-solving. Artificial intelligence is everywhere and it's already making a huge impact on our lives. It's autocompleting texts on our cellphones, telling us which videos to watch on YouTube, beating us at video games, recognizing us in photos, ordering products in stores, driving cars, scheduling appointments, you get the idea. Today we're going to explain what AI can (and can't) do right now and explain how we got to where we are today. Chatbot A chatbot is an AI-powered computer program designed to simulate conversation with human users, typically through text messages or voice interactions. Chatbots can be used for customer service, sales, marketing, and other applications. By now most of us have interacted with a chatbot in one form or another, but exactly how do they work? Do chatbots only operate on websites, or are there other mediums that a chatbot can facilitate a conversation? And why would anyone want to use a chatbot? In this lightboard video, Morgan Carroll with IBM Cloud, answers these questions and many more as she walks through an example of Floral company using a chatbot and shows first hand what a chatbot is, how it works, and why you may want to use one for your business. Do you ever lay awake at night wondering what, exactly, a chatbot is? Or how chatbots work? Or even if bots will steal customer service representatives\u2019 jobs? Well, you can rest easy because we\u2019re going to answer all your questions. Computer Vision Computer Vision is a field of artificial intelligence that focuses on enabling machines to interpret and understand visual data from the world around them, such as images and videos. Today we\u2019re going to talk about how computers see. We\u2019ve long known that our digital cameras and smartphones can take incredibly detailed images, but taking pictures is not quite the same thing. For the past half-century, computer scientists have been working to help our computing devices understand the imagery they capture, leading to advancements everywhere, from tracking hands and whole bodies, biometrics to unlock our phones, and eventually giving autonomous cars the ability to understand their surroundings. Decision Tree A decision tree is a graphical representation of a decision-making process that uses a tree-like model of decisions and their possible consequences. Decision trees are often used in machine learning and artificial intelligence applications. Decision tree organizes a series rules in a tree structure. It is one of the most practical methods for non-parametric supervised learning. Our goal in this video is to demonstrate how to create a decision tree that predicts the value of a target by learning decision rules inferred from the training data. Deep Learning Deep learning is a subset of machine learning that involves training artificial neural networks with large amounts of data to perform complex tasks, such as image and speech recognition. Expert System An expert system is an AI-powered system that uses a knowledge base and reasoning algorithms to simulate the decision-making abilities of a human expert in a particular domain. Machine Learning Machine learning is a subset of artificial intelligence that involves training computer programs to learn from data and improve their performance on specific tasks over time, without being explicitly programmed to do so. In this video, you\u2019ll learn more about the evolution of machine learning and its impact on daily life. Narrow AI Narrow AI refers to artificial intelligence systems that are designed to perform a specific task or set of tasks, rather than exhibiting general intelligence. Natural Language Generation Natural Language Generation is a field of artificial intelligence that focuses on using machine learning algorithms to automatically generate natural language text from structured data or other sources. Natural Language Processing Natural Language Processing is a field of artificial intelligence that focuses on enabling computers to understand, interpret, and generate human language. We\u2019re going to talk about how computers understand speech and speak themselves. As computers play an increasing role in our daily lives there has been an growing demand for voice user interfaces, but speech is also terribly complicated. Vocabularies are diverse, sentence structures can often dictate the meaning of certain words, and computers also have to deal with accents, mispronunciations, and many common linguistic faux pas. The field of Natural Language Processing, or NLP, attempts to solve these problems, with a number of techniques we\u2019ll discuss today. And even though our virtual assistants like Siri, Alexa, Google Home, Bixby, and Cortana have come a long way from the first speech processing and synthesis models, there is still much room for improvement. Neural Network A neural network is a type of artificial intelligence algorithm that is modeled after the structure and function of the human brain. Neural networks are often used in deep learning applications. We're going to combine the artificial neuron we created last week into an artificial neural network. Artificial neural networks are better than other methods for more complicated tasks like image recognition, and the key to their success is their hidden layers. We'll talk about how the math of these networks work and how using many hidden layers allows us to do deep learning. Neural networks are really powerful at finding patterns in data which is why they've become one of the most dominant machine learning technologies used today. Reinforcement Learning Reinforcement learning is a type of machine learning that involves training an algorithm to make decisions based on feedback it receives from its environment. Supervised Learning Supervised learning is a type of machine learning that involves training an algorithm using labeled data, where the desired output is known. Today we\u2019re going to teach John Green Bot how to tell the difference between donuts and bagels using supervised learning! Supervised learning is the process of learning WITH training labels, and is the most widely used kind of learning with it comes to AI - helping with stuff like tagging photos on Facebook and filtering spam from your email. We\u2019re going to start small today and show how just a single neuron (or perceptron) is constructed, and explain the differences between precision and recall. Next week, we'll build our first neural network. Training Data Training data is a set of data used to train machine learning algorithms. Training data typically consists of input data and corresponding output data, which is used to teach the algorithm how to make predictions. Turing Test The Turing Test is a test of a machine's ability to exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human. What is consciousness? Can an artificial machine really think? For many, these have been vital considerations for the future of artificial intelligence. But British computer scientist Alan Turing decided to disregard all these questions in favor of a much simpler one: Can a computer talk like a human? Alex Gendler describes the Turing test and details some of its surprising results. Lesson by Alex Gendler, animation by Patrick Smith. Unsupervised Learning Unsupervised learning is a type of machine learning that involves training an algorithm using unlabeled data, where the desired output is unknown. The algorithm must find patterns and relationships in the data on its own. We\u2019re moving on from artificial intelligence that needs training labels, called Supervised Learning, to Unsupervised Learning which is learning by finding patterns in the world. We\u2019ll focus on the performing unsupervised clustering, specifically K-means clustering, and show you how we can extract meaningful patterns from data even when you don't know where those patterns are.","title":"Terms"},{"location":"contents/unit01/terms.html#artificial-intelligence-ai-terms","text":"","title":"Artificial Intelligence (AI) terms"},{"location":"contents/unit01/terms.html#ai-powered-assistant","text":"An AI-powered assistant is a virtual assistant that uses artificial intelligence (AI) technology to understand and respond to user requests. AI-powered assistants can be used to perform tasks such as scheduling appointments, setting reminders, providing information, and answering questions.","title":"AI-Powered Assistant"},{"location":"contents/unit01/terms.html#artificial-intelligence","text":"Artificial Intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to perform tasks that would typically require human intelligence, such as reasoning, learning, perception, and problem-solving. Artificial intelligence is everywhere and it's already making a huge impact on our lives. It's autocompleting texts on our cellphones, telling us which videos to watch on YouTube, beating us at video games, recognizing us in photos, ordering products in stores, driving cars, scheduling appointments, you get the idea. Today we're going to explain what AI can (and can't) do right now and explain how we got to where we are today.","title":"Artificial Intelligence"},{"location":"contents/unit01/terms.html#chatbot","text":"A chatbot is an AI-powered computer program designed to simulate conversation with human users, typically through text messages or voice interactions. Chatbots can be used for customer service, sales, marketing, and other applications. By now most of us have interacted with a chatbot in one form or another, but exactly how do they work? Do chatbots only operate on websites, or are there other mediums that a chatbot can facilitate a conversation? And why would anyone want to use a chatbot? In this lightboard video, Morgan Carroll with IBM Cloud, answers these questions and many more as she walks through an example of Floral company using a chatbot and shows first hand what a chatbot is, how it works, and why you may want to use one for your business. Do you ever lay awake at night wondering what, exactly, a chatbot is? Or how chatbots work? Or even if bots will steal customer service representatives\u2019 jobs? Well, you can rest easy because we\u2019re going to answer all your questions.","title":"Chatbot"},{"location":"contents/unit01/terms.html#computer-vision","text":"Computer Vision is a field of artificial intelligence that focuses on enabling machines to interpret and understand visual data from the world around them, such as images and videos. Today we\u2019re going to talk about how computers see. We\u2019ve long known that our digital cameras and smartphones can take incredibly detailed images, but taking pictures is not quite the same thing. For the past half-century, computer scientists have been working to help our computing devices understand the imagery they capture, leading to advancements everywhere, from tracking hands and whole bodies, biometrics to unlock our phones, and eventually giving autonomous cars the ability to understand their surroundings.","title":"Computer Vision"},{"location":"contents/unit01/terms.html#decision-tree","text":"A decision tree is a graphical representation of a decision-making process that uses a tree-like model of decisions and their possible consequences. Decision trees are often used in machine learning and artificial intelligence applications. Decision tree organizes a series rules in a tree structure. It is one of the most practical methods for non-parametric supervised learning. Our goal in this video is to demonstrate how to create a decision tree that predicts the value of a target by learning decision rules inferred from the training data.","title":"Decision Tree"},{"location":"contents/unit01/terms.html#deep-learning","text":"Deep learning is a subset of machine learning that involves training artificial neural networks with large amounts of data to perform complex tasks, such as image and speech recognition.","title":"Deep Learning"},{"location":"contents/unit01/terms.html#expert-system","text":"An expert system is an AI-powered system that uses a knowledge base and reasoning algorithms to simulate the decision-making abilities of a human expert in a particular domain.","title":"Expert System"},{"location":"contents/unit01/terms.html#machine-learning","text":"Machine learning is a subset of artificial intelligence that involves training computer programs to learn from data and improve their performance on specific tasks over time, without being explicitly programmed to do so. In this video, you\u2019ll learn more about the evolution of machine learning and its impact on daily life.","title":"Machine Learning"},{"location":"contents/unit01/terms.html#narrow-ai","text":"Narrow AI refers to artificial intelligence systems that are designed to perform a specific task or set of tasks, rather than exhibiting general intelligence.","title":"Narrow AI"},{"location":"contents/unit01/terms.html#natural-language-generation","text":"Natural Language Generation is a field of artificial intelligence that focuses on using machine learning algorithms to automatically generate natural language text from structured data or other sources.","title":"Natural Language Generation"},{"location":"contents/unit01/terms.html#natural-language-processing","text":"Natural Language Processing is a field of artificial intelligence that focuses on enabling computers to understand, interpret, and generate human language. We\u2019re going to talk about how computers understand speech and speak themselves. As computers play an increasing role in our daily lives there has been an growing demand for voice user interfaces, but speech is also terribly complicated. Vocabularies are diverse, sentence structures can often dictate the meaning of certain words, and computers also have to deal with accents, mispronunciations, and many common linguistic faux pas. The field of Natural Language Processing, or NLP, attempts to solve these problems, with a number of techniques we\u2019ll discuss today. And even though our virtual assistants like Siri, Alexa, Google Home, Bixby, and Cortana have come a long way from the first speech processing and synthesis models, there is still much room for improvement.","title":"Natural Language Processing"},{"location":"contents/unit01/terms.html#neural-network","text":"A neural network is a type of artificial intelligence algorithm that is modeled after the structure and function of the human brain. Neural networks are often used in deep learning applications. We're going to combine the artificial neuron we created last week into an artificial neural network. Artificial neural networks are better than other methods for more complicated tasks like image recognition, and the key to their success is their hidden layers. We'll talk about how the math of these networks work and how using many hidden layers allows us to do deep learning. Neural networks are really powerful at finding patterns in data which is why they've become one of the most dominant machine learning technologies used today.","title":"Neural Network"},{"location":"contents/unit01/terms.html#reinforcement-learning","text":"Reinforcement learning is a type of machine learning that involves training an algorithm to make decisions based on feedback it receives from its environment.","title":"Reinforcement Learning"},{"location":"contents/unit01/terms.html#supervised-learning","text":"Supervised learning is a type of machine learning that involves training an algorithm using labeled data, where the desired output is known. Today we\u2019re going to teach John Green Bot how to tell the difference between donuts and bagels using supervised learning! Supervised learning is the process of learning WITH training labels, and is the most widely used kind of learning with it comes to AI - helping with stuff like tagging photos on Facebook and filtering spam from your email. We\u2019re going to start small today and show how just a single neuron (or perceptron) is constructed, and explain the differences between precision and recall. Next week, we'll build our first neural network.","title":"Supervised Learning"},{"location":"contents/unit01/terms.html#training-data","text":"Training data is a set of data used to train machine learning algorithms. Training data typically consists of input data and corresponding output data, which is used to teach the algorithm how to make predictions.","title":"Training Data"},{"location":"contents/unit01/terms.html#turing-test","text":"The Turing Test is a test of a machine's ability to exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human. What is consciousness? Can an artificial machine really think? For many, these have been vital considerations for the future of artificial intelligence. But British computer scientist Alan Turing decided to disregard all these questions in favor of a much simpler one: Can a computer talk like a human? Alex Gendler describes the Turing test and details some of its surprising results. Lesson by Alex Gendler, animation by Patrick Smith.","title":"Turing Test"},{"location":"contents/unit01/terms.html#unsupervised-learning","text":"Unsupervised learning is a type of machine learning that involves training an algorithm using unlabeled data, where the desired output is unknown. The algorithm must find patterns and relationships in the data on its own. We\u2019re moving on from artificial intelligence that needs training labels, called Supervised Learning, to Unsupervised Learning which is learning by finding patterns in the world. We\u2019ll focus on the performing unsupervised clustering, specifically K-means clustering, and show you how we can extract meaningful patterns from data even when you don't know where those patterns are.","title":"Unsupervised Learning"},{"location":"contents/unit01/the-turing-test.html","text":"The Turing Test The Turing test is a way to measure a machine's ability to think and understand like a human. It was proposed by Alan Turing, a famous computer scientist, in 1950. The test works by having a human judge talk to both a human and a machine through a computer screen or other means of communication. If the judge can't tell which one is the machine, then the machine is said to have passed the Turing test and is considered to have human-like intelligence. It's a way to test the intelligence of machines. Alan Turing Alan Turing was a British computer scientist and mathematician who lived in the 20th century. He is famous for his work on cracking the code used by the Germans during World War II, which helped the Allies win the war. He also proposed the Turing test, which is a way to measure a machine's ability to think and understand like a human.","title":"The Turing Test"},{"location":"contents/unit01/the-turing-test.html#the-turing-test","text":"The Turing test is a way to measure a machine's ability to think and understand like a human. It was proposed by Alan Turing, a famous computer scientist, in 1950. The test works by having a human judge talk to both a human and a machine through a computer screen or other means of communication. If the judge can't tell which one is the machine, then the machine is said to have passed the Turing test and is considered to have human-like intelligence. It's a way to test the intelligence of machines.","title":"The Turing Test"},{"location":"contents/unit01/the-turing-test.html#alan-turing","text":"Alan Turing was a British computer scientist and mathematician who lived in the 20th century. He is famous for his work on cracking the code used by the Germans during World War II, which helped the Allies win the war. He also proposed the Turing test, which is a way to measure a machine's ability to think and understand like a human.","title":"Alan Turing"},{"location":"contents/unit01/types-of-sensors.html","text":"Types of sensors There are different type of sensors are available to choose from and the characteristics of sensors are used for determining the type of sensor to be used for particular application.","title":"Types of sensors"},{"location":"contents/unit01/types-of-sensors.html#types-of-sensors","text":"There are different type of sensors are available to choose from and the characteristics of sensors are used for determining the type of sensor to be used for particular application.","title":"Types of sensors"},{"location":"contents/unit01/unit1.html","text":"Unit 1. Sensors and AI: Fundamentals and Applications","title":"Sensors and AI: Fundamentals and Applications"},{"location":"contents/unit01/unit1.html#unit-1-sensors-and-ai-fundamentals-and-applications","text":"","title":"Unit 1. Sensors and AI: Fundamentals and Applications"},{"location":"contents/unit01/vr-techniques.html","text":"Virtual Reality Techniques Introduction to Virtual Reality Virtual Reality (VR) is a technology that creates a simulated environment. Unlike traditional user interfaces, VR places the user inside an experience. Instead of viewing a screen in front of them, users are immersed and able to interact with 3D worlds. This makes VR a powerful tool for learning, playing, and exploring. How Virtual Reality Works VR works through a combination of hardware and software. The main hardware components include: VR Headsets: These are like goggles that cover your eyes and show you the virtual world. Examples include the Oculus Rift, HTC Vive, and PlayStation VR. Motion Controllers: These are handheld devices that let you interact with the VR world. They track your hand movements and allow you to pick up objects, draw, or even fight virtual enemies. Tracking Sensors: These sensors monitor the position of your headset and controllers in space, ensuring that your movements in the real world are accurately reflected in the virtual world. The software in VR includes the applications and games that create the virtual environments and allow you to interact with them. Techniques Used in Virtual Reality Several key techniques make VR possible and enhance the experience: 3D Modeling and Animation: - 3D Modeling: Creating a digital representation of any object or environment. For example, a chair or a room. - Animation: Bringing these models to life by making them move. This could be a character walking or a car driving. Example: In a VR art application, you can use 3D modeling to create sculptures. With animation, these sculptures can come to life, moving or changing colors. Spatial Audio: - Spatial audio makes sounds seem like they are coming from specific locations in the virtual environment. This means if someone is talking behind you in VR, the sound will come from behind you. Example: In a VR mystery game, you might hear footsteps behind you, prompting you to turn around and investigate. Head Tracking: - This technique tracks the position and movement of your head, adjusting the view in the VR headset accordingly. It allows you to look around the virtual world naturally. Example: If you\u2019re exploring a VR jungle, you can look up to see the treetops or down to see the underbrush. Motion Tracking: - This tracks the movements of your hands or other parts of your body. It allows for a more interactive experience, as you can move objects, draw, or perform tasks. Example: In a VR cooking game, you can use motion controllers to chop vegetables, stir pots, and serve food. Haptic Feedback: - Haptic feedback uses vibrations or other sensations to simulate touch. This means you can feel when you touch or pick up something in the VR world. Example: When you catch a ball in a VR sports game, you might feel a slight vibration in your hand. Practical Applications of Virtual Reality Education: - VR can create immersive learning experiences. Imagine learning about ancient Egypt by walking around a pyramid or exploring the human body by traveling through its systems. Example: A VR history lesson where students visit a medieval castle and interact with historical figures. Training: - VR is used for training in fields like medicine, aviation, and the military. It allows for safe practice of complex tasks. Example: Medical students can perform virtual surgeries to practice without any risk to real patients. Entertainment: - VR is popular in gaming, where it creates immersive experiences that traditional gaming setups can\u2019t match. Example: Playing a VR zombie game where you need to physically move and fight off zombies coming from all directions. Travel: - VR can provide virtual travel experiences, allowing people to visit places they might never go in real life. Example: A virtual tour of the Eiffel Tower, where you can look around and explore Paris from above. Therapy: - VR is used in therapy to treat conditions like PTSD, anxiety, and phobias. Example: A person afraid of heights can use VR to gradually and safely expose themselves to higher and higher places. Conclusion Virtual Reality is a fascinating and versatile technology. By understanding the basic techniques and applications, you can see how VR is changing the way we learn, work, and play. As technology advances, the possibilities for VR are endless, making it an exciting field for future exploration and innovation.","title":"Virtual Reality Techniques"},{"location":"contents/unit01/vr-techniques.html#virtual-reality-techniques","text":"Introduction to Virtual Reality Virtual Reality (VR) is a technology that creates a simulated environment. Unlike traditional user interfaces, VR places the user inside an experience. Instead of viewing a screen in front of them, users are immersed and able to interact with 3D worlds. This makes VR a powerful tool for learning, playing, and exploring. How Virtual Reality Works VR works through a combination of hardware and software. The main hardware components include: VR Headsets: These are like goggles that cover your eyes and show you the virtual world. Examples include the Oculus Rift, HTC Vive, and PlayStation VR. Motion Controllers: These are handheld devices that let you interact with the VR world. They track your hand movements and allow you to pick up objects, draw, or even fight virtual enemies. Tracking Sensors: These sensors monitor the position of your headset and controllers in space, ensuring that your movements in the real world are accurately reflected in the virtual world. The software in VR includes the applications and games that create the virtual environments and allow you to interact with them. Techniques Used in Virtual Reality Several key techniques make VR possible and enhance the experience: 3D Modeling and Animation: - 3D Modeling: Creating a digital representation of any object or environment. For example, a chair or a room. - Animation: Bringing these models to life by making them move. This could be a character walking or a car driving. Example: In a VR art application, you can use 3D modeling to create sculptures. With animation, these sculptures can come to life, moving or changing colors. Spatial Audio: - Spatial audio makes sounds seem like they are coming from specific locations in the virtual environment. This means if someone is talking behind you in VR, the sound will come from behind you. Example: In a VR mystery game, you might hear footsteps behind you, prompting you to turn around and investigate. Head Tracking: - This technique tracks the position and movement of your head, adjusting the view in the VR headset accordingly. It allows you to look around the virtual world naturally. Example: If you\u2019re exploring a VR jungle, you can look up to see the treetops or down to see the underbrush. Motion Tracking: - This tracks the movements of your hands or other parts of your body. It allows for a more interactive experience, as you can move objects, draw, or perform tasks. Example: In a VR cooking game, you can use motion controllers to chop vegetables, stir pots, and serve food. Haptic Feedback: - Haptic feedback uses vibrations or other sensations to simulate touch. This means you can feel when you touch or pick up something in the VR world. Example: When you catch a ball in a VR sports game, you might feel a slight vibration in your hand. Practical Applications of Virtual Reality Education: - VR can create immersive learning experiences. Imagine learning about ancient Egypt by walking around a pyramid or exploring the human body by traveling through its systems. Example: A VR history lesson where students visit a medieval castle and interact with historical figures. Training: - VR is used for training in fields like medicine, aviation, and the military. It allows for safe practice of complex tasks. Example: Medical students can perform virtual surgeries to practice without any risk to real patients. Entertainment: - VR is popular in gaming, where it creates immersive experiences that traditional gaming setups can\u2019t match. Example: Playing a VR zombie game where you need to physically move and fight off zombies coming from all directions. Travel: - VR can provide virtual travel experiences, allowing people to visit places they might never go in real life. Example: A virtual tour of the Eiffel Tower, where you can look around and explore Paris from above. Therapy: - VR is used in therapy to treat conditions like PTSD, anxiety, and phobias. Example: A person afraid of heights can use VR to gradually and safely expose themselves to higher and higher places. Conclusion Virtual Reality is a fascinating and versatile technology. By understanding the basic techniques and applications, you can see how VR is changing the way we learn, work, and play. As technology advances, the possibilities for VR are endless, making it an exciting field for future exploration and innovation.","title":"Virtual Reality Techniques"},{"location":"contents/unit02/equity-inclusion.html","text":"Equity and inclusion in AI systems. Biases in AI Introduction Artificial intelligence (AI) is becoming increasingly important in our daily lives, from voice assistants to self-driving cars. However, it's important to understand that AI systems can also perpetuate and even amplify biases found in the data it is trained on. In this lesson, we will explore the concept of equity and inclusion in AI systems and the potential for biases in AI. What is equity and inclusion in AI systems? Equity and inclusion in AI systems refers to the idea that everyone should have access to the benefits of AI, regardless of their background or characteristics. This means that AI systems should be designed and implemented in a way that is fair and does not discriminate against certain groups of people. What are biases in AI systems? Biases in AI systems occur when the data used to train the AI is not representative of the population it will be used on. For example, if an AI system is trained on data mostly from one racial group, it may not be able to accurately recognize or make predictions about people from other racial groups. This can lead to unfair and harmful outcomes, such as denying certain people access to certain services or opportunities. How can we prevent biases in AI systems? There are several steps that can be taken to prevent biases in AI systems, including: Using diverse data sets to train AI systems: This can help ensure that the AI system is not just learning from one group of people. Regularly testing and evaluating AI systems: This can help identify and address any biases that may exist in the system. Involving diverse perspectives in the development and design of AI systems: This can help ensure that the needs and concerns of all groups are taken into account. Transparency and explainability in AI systems: This can help people understand how the system is making decisions and identify any potential biases. Conclusion AI has the potential to greatly benefit society, but it's important to ensure that it is developed and implemented in a way that is fair and inclusive. By understanding the concept of equity and inclusion and the potential for biases in AI systems, we can take steps to prevent these biases and create AI that truly benefits everyone.","title":"Equity and inclusion in AI systems. Biases in AI"},{"location":"contents/unit02/equity-inclusion.html#equity-and-inclusion-in-ai-systems-biases-in-ai","text":"","title":"Equity and inclusion in AI systems. Biases in AI"},{"location":"contents/unit02/equity-inclusion.html#introduction","text":"Artificial intelligence (AI) is becoming increasingly important in our daily lives, from voice assistants to self-driving cars. However, it's important to understand that AI systems can also perpetuate and even amplify biases found in the data it is trained on. In this lesson, we will explore the concept of equity and inclusion in AI systems and the potential for biases in AI.","title":"Introduction"},{"location":"contents/unit02/equity-inclusion.html#what-is-equity-and-inclusion-in-ai-systems","text":"Equity and inclusion in AI systems refers to the idea that everyone should have access to the benefits of AI, regardless of their background or characteristics. This means that AI systems should be designed and implemented in a way that is fair and does not discriminate against certain groups of people.","title":"What is equity and inclusion in AI systems?"},{"location":"contents/unit02/equity-inclusion.html#what-are-biases-in-ai-systems","text":"Biases in AI systems occur when the data used to train the AI is not representative of the population it will be used on. For example, if an AI system is trained on data mostly from one racial group, it may not be able to accurately recognize or make predictions about people from other racial groups. This can lead to unfair and harmful outcomes, such as denying certain people access to certain services or opportunities.","title":"What are biases in AI systems?"},{"location":"contents/unit02/equity-inclusion.html#how-can-we-prevent-biases-in-ai-systems","text":"There are several steps that can be taken to prevent biases in AI systems, including: Using diverse data sets to train AI systems: This can help ensure that the AI system is not just learning from one group of people. Regularly testing and evaluating AI systems: This can help identify and address any biases that may exist in the system. Involving diverse perspectives in the development and design of AI systems: This can help ensure that the needs and concerns of all groups are taken into account. Transparency and explainability in AI systems: This can help people understand how the system is making decisions and identify any potential biases.","title":"How can we prevent biases in AI systems?"},{"location":"contents/unit02/equity-inclusion.html#conclusion","text":"AI has the potential to greatly benefit society, but it's important to ensure that it is developed and implemented in a way that is fair and inclusive. By understanding the concept of equity and inclusion and the potential for biases in AI systems, we can take steps to prevent these biases and create AI that truly benefits everyone.","title":"Conclusion"},{"location":"contents/unit02/glossary-ud02.html","text":"Glossary","title":"Glossary"},{"location":"contents/unit02/glossary-ud02.html#glossary","text":"","title":"Glossary"},{"location":"contents/unit02/unit2.html","text":"Unit 2. Exploring AI: Ethics, Inclusion, and Virtual Reality","title":"Unit 2. Exploring AI: Ethics, Inclusion, and Virtual Reality"},{"location":"contents/unit02/unit2.html#unit-2-exploring-ai-ethics-inclusion-and-virtual-reality","text":"","title":"Unit 2. Exploring AI: Ethics, Inclusion, and Virtual Reality"},{"location":"contents/unit03/glossary-ud03.html","text":"Glossary","title":"Glossary"},{"location":"contents/unit03/glossary-ud03.html#glossary","text":"","title":"Glossary"},{"location":"contents/unit03/unit3.html","text":"Unit 3. Modeling, Algorithms, and Patterns in Programming","title":"Unit 3. Modeling, Algorithms, and Patterns in Programming"},{"location":"contents/unit03/unit3.html#unit-3-modeling-algorithms-and-patterns-in-programming","text":"","title":"Unit 3. Modeling, Algorithms, and Patterns in Programming"},{"location":"contents/unit04/glossary-ud04.html","text":"Glossary","title":"Glossary"},{"location":"contents/unit04/glossary-ud04.html#glossary","text":"","title":"Glossary"},{"location":"contents/unit04/unit4.html","text":"Unit 4. Programming Fundamentals: Languages, Flow Control, and Variables","title":"Unit 4. Programming Fundamentals: Languages, Flow Control, and Variables"},{"location":"contents/unit04/unit4.html#unit-4-programming-fundamentals-languages-flow-control-and-variables","text":"","title":"Unit 4. Programming Fundamentals: Languages, Flow Control, and Variables"},{"location":"contents/unit05/glossary-ud05.html","text":"Glossary","title":"Glossary"},{"location":"contents/unit05/glossary-ud05.html#glossary","text":"","title":"Glossary"},{"location":"contents/unit05/unit5.html","text":"Unit 5. Software Management: Applications and Maintenance","title":"Unit 5. Software Management: Applications and Maintenance"},{"location":"contents/unit05/unit5.html#unit-5-software-management-applications-and-maintenance","text":"","title":"Unit 5. Software Management: Applications and Maintenance"},{"location":"contents/unit06/glossary-ud06.html","text":"Glossary","title":"Glossary"},{"location":"contents/unit06/glossary-ud06.html#glossary","text":"","title":"Glossary"},{"location":"contents/unit06/unit6.html","text":"Unit 6. Robotics in Action: Assembly, Control, and Programming","title":"Unit 6. Robotics in Action: Assembly, Control, and Programming"},{"location":"contents/unit06/unit6.html#unit-6-robotics-in-action-assembly-control-and-programming","text":"","title":"Unit 6. Robotics in Action: Assembly, Control, and Programming"},{"location":"pd/curriculo/curriculo.html","text":"Elementos curriculares Competencias clave CCL : competencia en comunicaci\u00f3n ling\u00fc\u00edstica CP : competencia pluriling\u00fce CMCT : competencia matem\u00e1tica, ciencia y tecnol\u00f3gica CD : competencia digital CPSAA : competencia personal, social y de aprender a aprender CC : competencia ciudadana CE : competencia emprendedora CCEC : competencia en conciencia y expresi\u00f3n cultural Competencias espec\u00edficas CE1 . Identificar, investigar y emplear t\u00e9cnicas de inteligencia artificial y virtualizaci\u00f3n de la realidad en el abordaje y la b\u00fasqueda de soluciones a problemas b\u00e1sicos de la sociedad valorando los principios \u00e9ticos e inclusivos aplicados. CE2 . Aplicar el pensamiento computacional en el an\u00e1lisis y resoluci\u00f3n de problemas b\u00e1sicos y significativos para el alumnado mediante el desarrollo de software. CE3 . Montar sistemas rob\u00f3ticos sencillos, analizando las respuestas que proporcionan en su interacci\u00f3n con el entorno y valorando la eficacia de estas frente a los retos planteados. CE4 Afrontar retos tecnol\u00f3gicos sencillos y proponer soluciones mediante la programaci\u00f3n, la inteligencia Artificial y la rob\u00f3tica, analizando las posibilidades y valorando cr\u00edticamente las implicaciones \u00e9ticas y ecosociales. Relaciones o conexiones con las competencias clave CE1: CCL, CP, CMCT, CD, CPSAA CE2: CCL, CMCT, CD, CPSAA CE3: CMCT, CD, CPSAA CE4: CMCT, CD, CPSAA, CC, CE Saberes b\u00e1sicos Bloque 1. Inteligencia Artifical. CE1 Sensores, tipolog\u00eda y aplicaciones. T\u00e9cnicas iniciales de IA: sistemas expertos, redes neuronales y aprendizaje autom\u00e1tico. Procesado autom\u00e1tico de la informaci\u00f3n. Equidad e inclusi\u00f3n en sistemas de IA. Sesgos en IA. Implicaciones sociales y \u00e9ticas de la inteligencia artificial. T\u00e9cnicas de virtualizaci\u00f3n de la realidad. Bloque 2. Programaci\u00f3n. CE2 Interpretaci\u00f3n de la realidad mediante modelado de problemas. Abstracci\u00f3n, secuenciaci\u00f3n, algor\u00edtmica y su representaci\u00f3n con lenguaje natural y diagramas de flujo. Detecci\u00f3n y reutilizaci\u00f3n de patrones. Generalizaci\u00f3n. Sostenibilidad e inclusi\u00f3n como requisitos del dise\u00f1o del software. Estructuras de control del flujo del programa. Variables, constantes, condiciones y operadores. Introducci\u00f3n a la programaci\u00f3n en lenguajes de alto nivel. Tipos de lenguajes. Sintaxis y sem\u00e1ntica Programaci\u00f3n de aplicaciones para dispositivos m\u00f3viles. Evaluaci\u00f3n y mantenimiento de software. Licencias de software. El software libre y el software propietario. Simuladores de tarjetas controladoras. Iniciativa, autoconfianza y metacognici\u00f3n en el proceso de aprendizaje del desarrollo de software. Bloque 3. Rob\u00f3tica. CE3 Montaje de robots. Control de sistemas robotizados. Sensores, actuadores y controladores. Carga y ejecuci\u00f3n de los algoritmos en robots. Sistemas robotizados en la experimentaci\u00f3n con prototipos dise\u00f1ados. Situaciones de aprendizaje texto. Criterios de evaluaci\u00f3n Competencia espec\u00edfica 1 CE1 . Identificar, investigar y emplear t\u00e9cnicas de inteligencia artificial y virtualizaci\u00f3n de la realidad en el abordaje y la b\u00fasqueda de soluciones a problemas b\u00e1sicos de la sociedad valorando los principios \u00e9ticos e inclusivos aplicados. 1.1. Identificar el funcionamiento de t\u00e9cnicas de IA. 1.2. Investigar situaciones donde se aplican t\u00e9cnicas de IA. 1.3. Valorar criterios \u00e9ticos aplicados a las funciones de IA. 1.4. Emplear funciones de IA en aplicaciones sencillas siguiendo criterios \u00e9ticos e inclusivos para buscar soluciones a problemas b\u00e1sicos 1.5 Emplear t\u00e9cnicas sencillas de virtualizaci\u00f3n de la realidad. Competencia espec\u00edfica 2 CE2 . Aplicar el pensamiento computacional en el an\u00e1lisis y resoluci\u00f3n de problemas b\u00e1sicos y significativos para el alumnado mediante el desarrollo de software. 2.1. Analizar problemas b\u00e1sicos significativos para el alumnado, mediante el uso de las estructuras de control m\u00e1s adecuadas. 2.2. Evaluar y mantener las aplicaciones inform\u00e1ticas desarrolladas por el propio alumnado. 2.3. Planificar de forma aut\u00f3noma la soluci\u00f3n de problemas b\u00e1sicos, utilizando los algoritmos y las estructuras de datos m\u00e1s adecuados. 2.4. Programar aplicaciones sencillas multiplataforma de manera aut\u00f3noma para resolver problemas b\u00e1sicos. 2.5. Aplicar y respetar los derechos de autor\u00eda, licencias de derechos y explotaci\u00f3n durante la creaci\u00f3n de software. Competencia espec\u00edfica 3 CE3 . Montar sistemas rob\u00f3ticos sencillos, analizando las respuestas que proporcionan en su interacci\u00f3n con el entorno y valorando la eficacia de estas frente a los retos planteados. 3.1. Montar robots de mayor complejidad empleando sensores, actuadores y otros operadores. 3.2. Conectar, transferir y validar la ejecuci\u00f3n del programa de control seleccionado al robot. 3.3. Seleccionar los m\u00f3dulos de entrada y salida para montar robots sencillos, que sean capaces de realizar tareas de forma aut\u00f3noma. 3.4. Analizar y evaluar la eficacia de la interacci\u00f3n del robot con el entorno. 3.5. Programar instrucciones sencillas multiplataforma de manera aut\u00f3noma para controlar un robot programable. 3.6. Controlar el robot por parte del usuario en tiempo real y de forma remota. Competencia espec\u00edfica 4 CE4 Afrontar retos tecnol\u00f3gicos sencillos y proponer soluciones mediante la programaci\u00f3n, la inteligencia Artificial y la rob\u00f3tica, analizando las posibilidades y valorando cr\u00edticamente las implicaciones \u00e9ticas y ecosociales. 4.1. Planificar tareas sencillas, crear estructuras de equipos de trabajo, distribuir funciones y responsabilidades de las personas integrantes y colaborar proactivamente en el desarrollo de soluciones digitales y tecnol\u00f3gicas 4.2. Valorar la importancia de la Inteligencia Artificial, la programaci\u00f3n y la rob\u00f3tica como elementos disruptores de la transformaci\u00f3n social, cultural y cient\u00edfica actuales. 4.3. Dise\u00f1ar soluciones utilizando la programaci\u00f3n, la inteligencia artificial y la rob\u00f3tica eligiendo la opci\u00f3n que mejor se adapte a los retos planteados. 4.4. Gestionar situaciones de incertidumbre en entornos digitales y tecnol\u00f3gicos con una actitud positiva, y afrontarlas utilizando el conocimiento adquirido y sinti\u00e9ndose competente. 4.5. Aplicar la sostenibilidad e inclusi\u00f3n como requisitos del dise\u00f1o de soluciones tecnol\u00f3gicas","title":"Elementos curriculares"},{"location":"pd/curriculo/curriculo.html#elementos-curriculares","text":"","title":"Elementos curriculares"},{"location":"pd/curriculo/curriculo.html#competencias-clave","text":"CCL : competencia en comunicaci\u00f3n ling\u00fc\u00edstica CP : competencia pluriling\u00fce CMCT : competencia matem\u00e1tica, ciencia y tecnol\u00f3gica CD : competencia digital CPSAA : competencia personal, social y de aprender a aprender CC : competencia ciudadana CE : competencia emprendedora CCEC : competencia en conciencia y expresi\u00f3n cultural","title":"Competencias clave"},{"location":"pd/curriculo/curriculo.html#competencias-especificas","text":"CE1 . Identificar, investigar y emplear t\u00e9cnicas de inteligencia artificial y virtualizaci\u00f3n de la realidad en el abordaje y la b\u00fasqueda de soluciones a problemas b\u00e1sicos de la sociedad valorando los principios \u00e9ticos e inclusivos aplicados. CE2 . Aplicar el pensamiento computacional en el an\u00e1lisis y resoluci\u00f3n de problemas b\u00e1sicos y significativos para el alumnado mediante el desarrollo de software. CE3 . Montar sistemas rob\u00f3ticos sencillos, analizando las respuestas que proporcionan en su interacci\u00f3n con el entorno y valorando la eficacia de estas frente a los retos planteados. CE4 Afrontar retos tecnol\u00f3gicos sencillos y proponer soluciones mediante la programaci\u00f3n, la inteligencia Artificial y la rob\u00f3tica, analizando las posibilidades y valorando cr\u00edticamente las implicaciones \u00e9ticas y ecosociales.","title":"Competencias espec\u00edficas"},{"location":"pd/curriculo/curriculo.html#relaciones-o-conexiones-con-las-competencias-clave","text":"CE1: CCL, CP, CMCT, CD, CPSAA CE2: CCL, CMCT, CD, CPSAA CE3: CMCT, CD, CPSAA CE4: CMCT, CD, CPSAA, CC, CE","title":"Relaciones o conexiones con las competencias clave"},{"location":"pd/curriculo/curriculo.html#saberes-basicos","text":"","title":"Saberes b\u00e1sicos"},{"location":"pd/curriculo/curriculo.html#bloque-1-inteligencia-artifical-ce1","text":"Sensores, tipolog\u00eda y aplicaciones. T\u00e9cnicas iniciales de IA: sistemas expertos, redes neuronales y aprendizaje autom\u00e1tico. Procesado autom\u00e1tico de la informaci\u00f3n. Equidad e inclusi\u00f3n en sistemas de IA. Sesgos en IA. Implicaciones sociales y \u00e9ticas de la inteligencia artificial. T\u00e9cnicas de virtualizaci\u00f3n de la realidad.","title":"Bloque 1. Inteligencia Artifical. CE1"},{"location":"pd/curriculo/curriculo.html#bloque-2-programacion-ce2","text":"Interpretaci\u00f3n de la realidad mediante modelado de problemas. Abstracci\u00f3n, secuenciaci\u00f3n, algor\u00edtmica y su representaci\u00f3n con lenguaje natural y diagramas de flujo. Detecci\u00f3n y reutilizaci\u00f3n de patrones. Generalizaci\u00f3n. Sostenibilidad e inclusi\u00f3n como requisitos del dise\u00f1o del software. Estructuras de control del flujo del programa. Variables, constantes, condiciones y operadores. Introducci\u00f3n a la programaci\u00f3n en lenguajes de alto nivel. Tipos de lenguajes. Sintaxis y sem\u00e1ntica Programaci\u00f3n de aplicaciones para dispositivos m\u00f3viles. Evaluaci\u00f3n y mantenimiento de software. Licencias de software. El software libre y el software propietario. Simuladores de tarjetas controladoras. Iniciativa, autoconfianza y metacognici\u00f3n en el proceso de aprendizaje del desarrollo de software.","title":"Bloque 2. Programaci\u00f3n. CE2"},{"location":"pd/curriculo/curriculo.html#bloque-3-robotica-ce3","text":"Montaje de robots. Control de sistemas robotizados. Sensores, actuadores y controladores. Carga y ejecuci\u00f3n de los algoritmos en robots. Sistemas robotizados en la experimentaci\u00f3n con prototipos dise\u00f1ados.","title":"Bloque 3. Rob\u00f3tica. CE3"},{"location":"pd/curriculo/curriculo.html#situaciones-de-aprendizaje","text":"texto.","title":"Situaciones de aprendizaje"},{"location":"pd/curriculo/curriculo.html#criterios-de-evaluacion","text":"","title":"Criterios de evaluaci\u00f3n"},{"location":"pd/curriculo/curriculo.html#competencia-especifica-1","text":"CE1 . Identificar, investigar y emplear t\u00e9cnicas de inteligencia artificial y virtualizaci\u00f3n de la realidad en el abordaje y la b\u00fasqueda de soluciones a problemas b\u00e1sicos de la sociedad valorando los principios \u00e9ticos e inclusivos aplicados. 1.1. Identificar el funcionamiento de t\u00e9cnicas de IA. 1.2. Investigar situaciones donde se aplican t\u00e9cnicas de IA. 1.3. Valorar criterios \u00e9ticos aplicados a las funciones de IA. 1.4. Emplear funciones de IA en aplicaciones sencillas siguiendo criterios \u00e9ticos e inclusivos para buscar soluciones a problemas b\u00e1sicos 1.5 Emplear t\u00e9cnicas sencillas de virtualizaci\u00f3n de la realidad.","title":"Competencia espec\u00edfica 1"},{"location":"pd/curriculo/curriculo.html#competencia-especifica-2","text":"CE2 . Aplicar el pensamiento computacional en el an\u00e1lisis y resoluci\u00f3n de problemas b\u00e1sicos y significativos para el alumnado mediante el desarrollo de software. 2.1. Analizar problemas b\u00e1sicos significativos para el alumnado, mediante el uso de las estructuras de control m\u00e1s adecuadas. 2.2. Evaluar y mantener las aplicaciones inform\u00e1ticas desarrolladas por el propio alumnado. 2.3. Planificar de forma aut\u00f3noma la soluci\u00f3n de problemas b\u00e1sicos, utilizando los algoritmos y las estructuras de datos m\u00e1s adecuados. 2.4. Programar aplicaciones sencillas multiplataforma de manera aut\u00f3noma para resolver problemas b\u00e1sicos. 2.5. Aplicar y respetar los derechos de autor\u00eda, licencias de derechos y explotaci\u00f3n durante la creaci\u00f3n de software.","title":"Competencia espec\u00edfica 2"},{"location":"pd/curriculo/curriculo.html#competencia-especifica-3","text":"CE3 . Montar sistemas rob\u00f3ticos sencillos, analizando las respuestas que proporcionan en su interacci\u00f3n con el entorno y valorando la eficacia de estas frente a los retos planteados. 3.1. Montar robots de mayor complejidad empleando sensores, actuadores y otros operadores. 3.2. Conectar, transferir y validar la ejecuci\u00f3n del programa de control seleccionado al robot. 3.3. Seleccionar los m\u00f3dulos de entrada y salida para montar robots sencillos, que sean capaces de realizar tareas de forma aut\u00f3noma. 3.4. Analizar y evaluar la eficacia de la interacci\u00f3n del robot con el entorno. 3.5. Programar instrucciones sencillas multiplataforma de manera aut\u00f3noma para controlar un robot programable. 3.6. Controlar el robot por parte del usuario en tiempo real y de forma remota.","title":"Competencia espec\u00edfica 3"},{"location":"pd/curriculo/curriculo.html#competencia-especifica-4","text":"CE4 Afrontar retos tecnol\u00f3gicos sencillos y proponer soluciones mediante la programaci\u00f3n, la inteligencia Artificial y la rob\u00f3tica, analizando las posibilidades y valorando cr\u00edticamente las implicaciones \u00e9ticas y ecosociales. 4.1. Planificar tareas sencillas, crear estructuras de equipos de trabajo, distribuir funciones y responsabilidades de las personas integrantes y colaborar proactivamente en el desarrollo de soluciones digitales y tecnol\u00f3gicas 4.2. Valorar la importancia de la Inteligencia Artificial, la programaci\u00f3n y la rob\u00f3tica como elementos disruptores de la transformaci\u00f3n social, cultural y cient\u00edfica actuales. 4.3. Dise\u00f1ar soluciones utilizando la programaci\u00f3n, la inteligencia artificial y la rob\u00f3tica eligiendo la opci\u00f3n que mejor se adapte a los retos planteados. 4.4. Gestionar situaciones de incertidumbre en entornos digitales y tecnol\u00f3gicos con una actitud positiva, y afrontarlas utilizando el conocimiento adquirido y sinti\u00e9ndose competente. 4.5. Aplicar la sostenibilidad e inclusi\u00f3n como requisitos del dise\u00f1o de soluciones tecnol\u00f3gicas","title":"Competencia espec\u00edfica 4"}]}